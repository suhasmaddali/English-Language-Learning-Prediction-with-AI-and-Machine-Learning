{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f19d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2Model, GPT2Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d8f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4e8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['full_text', 'text_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d62ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute error (MAE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mae\n",
    "\n",
    "def calc_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the root mean squared error (RMSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calc_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute percentage error (MAPE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mape\n",
    "\n",
    "def calc_r2_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the R2 score between the true and predicted values\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccb2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print MSE\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    # Calculate and print MSE\n",
    "    mse = calc_mse(y_actual, y_predictions)\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    rmse = calc_rmse(y_actual, y_predictions)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    \n",
    "    # Calculate and print MAE\n",
    "    mae = calc_mae(y_actual, y_predictions)\n",
    "    print(\"MAE:\", mae)\n",
    "\n",
    "    # Calculate and print MAPE\n",
    "    mape = calc_mape(y_actual, y_predictions)\n",
    "    print(\"MAPE:\", mape)\n",
    "\n",
    "    # Calculate and print R2 score\n",
    "    r2 = calc_r2_score(y_actual, y_predictions)\n",
    "    print(\"R2 Score:\", r2)\n",
    "    \n",
    "    return mse, rmse, mae, mape, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc48d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohesion = df['cohesion']\n",
    "syntax = df['syntax']\n",
    "vocabulary = df['vocabulary']\n",
    "phraseology = df['phraseology']\n",
    "grammar = df['grammar']\n",
    "conventions = df['conventions']\n",
    "\n",
    "preprocessed_text = df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa2fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_text\n",
    "y_cohesion = cohesion\n",
    "y_syntax = syntax\n",
    "y_vocabulary = vocabulary\n",
    "y_phraseology = phraseology\n",
    "y_grammar = grammar\n",
    "y_conventions = conventions\n",
    "\n",
    "X_train, X_test, y_train_cohesion, y_test_cohesion = train_test_split(X, y_cohesion, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_syntax, y_test_syntax = train_test_split(X, y_syntax, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_vocabulary, y_test_vocabulary = train_test_split(X, y_vocabulary, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_phraseology, y_test_phraseology = train_test_split(X, y_phraseology, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_grammar, y_test_grammar = train_test_split(X, y_grammar, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_conventions, y_test_conventions = train_test_split(X, y_conventions, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bc841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input train data: (3128,)\n",
      "The shape of input test data: (783,)\n",
      "------------------------------------------\n",
      "The shape of output train data: (3128,)\n",
      "The shape of output test data: (783,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of input test data: {}\".format(X_test.shape))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"The shape of output train data: {}\".format(y_train_cohesion.shape))\n",
    "print(\"The shape of output test data: {}\".format(y_test_cohesion.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6eb5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 124439808\n"
     ]
    }
   ],
   "source": [
    "# This downloads the pre-trained weights from the huggingface website \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "gpt_model = TFGPT2Model.from_pretrained('gpt2')\n",
    "max_len = 512\n",
    "print(f\"Total number of parameters: {gpt_model.count_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b1f50",
   "metadata": {},
   "source": [
    "### GPT - 2 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bbd3d",
   "metadata": {},
   "source": [
    "#### Extracting GPT - 2 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7675a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "batch_size = 2\n",
    "\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=max_len, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train_cohesion)).batch(batch_size)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_len, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test_cohesion)).batch(batch_size)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in train_dataset:\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in test_dataset:\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ddfa8",
   "metadata": {},
   "source": [
    "#### Train and Evaluate XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f5cb6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4653183170267626\n",
      "RMSE: 0.6821424462872565\n",
      "MAE: 0.5260195558555282\n",
      "MAPE: 17.11389506369954\n",
      "R2 Score: -0.059919383206717525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4653183170267626,\n",
       " 0.6821424462872565,\n",
       " 0.5260195558555282,\n",
       " 17.11389506369954,\n",
       " -0.059919383206717525)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_xgb = embeddings_train.numpy()\n",
    "X_test_xgb = embeddings_test.numpy()\n",
    "\n",
    "model = xgb.XGBRegressor(objective = 'reg:absoluteerror', n_estimators = 10,\n",
    "                    learning_rate = 0.001, max_depth = 4)\n",
    "model.fit(X_train_xgb, y_train_cohesion)\n",
    "y_predictions = model.predict(X_test_xgb)\n",
    "\n",
    "print_metrics_function(y_test_cohesion, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721a72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
