{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hEpEmlr1esro"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZXvwOn8dQyg0"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install pyspellchecker\n",
        "# !pip install Keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from spellchecker import SpellChecker\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from prettytable import PrettyTable\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "7cJfhyvxQ6C4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/Preprocessed_df.csv')\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "jL4f_Iqjeymt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(y_true, y_pred, average='macro'):\n",
        "    \"\"\"\n",
        "    Calculates the precision score between the true and predicted values\n",
        "    \"\"\"\n",
        "    precision = precision_score(y_true, y_pred, average=average)\n",
        "    return precision\n",
        "\n",
        "def calc_recall(y_true, y_pred, average='macro'):\n",
        "    \"\"\"\n",
        "    Calculates the recall score between the true and predicted values\n",
        "    \"\"\"\n",
        "    recall = recall_score(y_true, y_pred, average=average)\n",
        "    return recall\n",
        "\n",
        "def calc_f1_score(y_true, y_pred, average='macro'):\n",
        "    \"\"\"\n",
        "    Calculates the f1-score between the true and predicted values\n",
        "    \"\"\"\n",
        "    f1 = f1_score(y_true, y_pred, average=average)\n",
        "    return f1\n",
        "\n",
        "def calc_cohen_kappa_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the cohen kappa score between the true and predicted values\n",
        "    \"\"\"\n",
        "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
        "    return kappa_score\n",
        "\n",
        "def calc_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the accuracy score between the true and predicted values\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "QPDhuwbwQ9Ys"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics_function(y_actual, y_predictions):\n",
        "    \n",
        "    # Calculate and print accuracy\n",
        "    accuracy = calc_accuracy(y_actual, y_predictions)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    \n",
        "    # Calculate and print precision\n",
        "    precision = calc_precision(y_actual, y_predictions)\n",
        "    print(\"Precision:\", precision)\n",
        "\n",
        "    # Calculate and print recall\n",
        "    recall = calc_recall(y_actual, y_predictions)\n",
        "    print(\"Recall:\", recall)\n",
        "\n",
        "    # Calculate and print f1-score\n",
        "    f1 = calc_f1_score(y_actual, y_predictions)\n",
        "    print(\"F1-Score:\", f1)\n",
        "\n",
        "    # Calculate and print Cohen Kappa Score\n",
        "    kappa_score = calc_cohen_kappa_score(y_actual, y_predictions)\n",
        "    print(\"Cohen Kappa Score:\", kappa_score)\n",
        "\n",
        "    return accuracy, precision, recall, f1, kappa_score"
      ],
      "metadata": {
        "id": "S_zfhJxmQ9bI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_classifiers(classifier_name = \"logistic_regression\"):\n",
        "    \"\"\"\n",
        "    Takes a regressor as input and returns a corresponding classifier object\n",
        "    \"\"\"\n",
        "    \n",
        "    if classifier_name == 'logistic_regression':\n",
        "        return LogisticRegression()\n",
        "    elif classifier_name == 'decision_tree_classifier':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier_name == 'random_forest_classifier':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier_name == 'gradient_boosting_classifier':\n",
        "        return GradientBoostingClassifier()\n",
        "    elif classifier_name == 'adaboost_classifier':\n",
        "        return AdaBoostClassifier()\n",
        "    elif classifier_name == 'k_neighbors_classifier':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier_name == 'support_vector_classifier':\n",
        "        return SVC()\n",
        "    elif classifier_name == 'xgboost_classifier':\n",
        "        return XGBClassifier()\n",
        "    elif classifier_name == 'gaussian_naive_bayes_classifier':\n",
        "        return GaussianNB()\n",
        "    else:\n",
        "        raise ValueError(f\"Classifier {classifier_name} not supported for this problem.\")"
      ],
      "metadata": {
        "id": "2RY2vG3JQ9dk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_preparation(data, target = 'domain1_score'):\n",
        "    \n",
        "    X = data.drop([target], axis = 1)\n",
        "    y = data[target]\n",
        "    \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "X2YCz2yQQ9ld"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_corrector(tokens):\n",
        "    spell_checker = SpellChecker()\n",
        "    correct_tokens = []\n",
        "    for token in tqdm(tokens):\n",
        "        if spell_checker.correction(token.lower()):\n",
        "            correct_tokens.append(spell_checker.correction(token.lower()))\n",
        "        else:\n",
        "            correct_tokens.append(token.lower())\n",
        "    \n",
        "    return ' '.join(correct_tokens)"
      ],
      "metadata": {
        "id": "jJWyh8_0Q9ny"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring some visualization methods to plot accuracy and model diagram\n",
        "def plot_accuracy_curve(history):\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['mae'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def plot_acrchitecture(filename, model):\n",
        "  from keras.utils import plot_model\n",
        "  plot_model(model, to_file=str(filename) + '.png')"
      ],
      "metadata": {
        "id": "AuhJ_lOGS7OK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "def get_model(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout=0.2, recurrent_dropout=0.2, input_size=768, activation='relu', bidirectional = False):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    if bidirectional:\n",
        "        model.add(Bidirectional(LSTM(Hidden_dim1,return_sequences=return_sequences , dropout=0.4, recurrent_dropout=recurrent_dropout), input_shape=[1, input_size]))\n",
        "        model.add(Bidirectional(LSTM(Hidden_dim2, recurrent_dropout=recurrent_dropout)))\n",
        "    else:\n",
        "        model.add(LSTM(Hidden_dim1, dropout=0.4, recurrent_dropout=recurrent_dropout, input_shape=[1, input_size], return_sequences=return_sequences))\n",
        "        model.add(LSTM(Hidden_dim2, recurrent_dropout=recurrent_dropout))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=activation))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_model_CNN(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout=0.5, recurrent_dropout=0.4, input_size=768,output_dims=10380, activation='relu', bidirectional = False):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    inputs = Input(shape=(768,1))\n",
        "    x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "    #Cuts the size of the output in half, maxing over every 2 inputs\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Conv1D(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = GlobalMaxPooling1D()(x) \n",
        "    outputs = Dense(output_dims, activation='relu')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "d8_PPZe8S0B0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_list(a, b):\n",
        "\n",
        "    if len(a) != len(b):\n",
        "        raise ValueError(\"Input lists must have the same length\")\n",
        "\n",
        "    max_list = []\n",
        "    for i in range(len(a)):\n",
        "        max_list.append(max(a[i], b[i]))\n",
        "\n",
        "    return max_list\n"
      ],
      "metadata": {
        "id": "xbk4hcexTBLK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Preprocessed_df.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "MWqu3UnoQ9pX",
        "outputId": "26ae5589-aa3f-49ac-b4a7-591c8336cdaa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0               4               4             NaN              8   \n",
              "1               5               4             NaN              9   \n",
              "2               4               3             NaN              7   \n",
              "3               5               5             NaN             10   \n",
              "4               4               4             NaN              8   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  word_len  chars_len  \\\n",
              "0             NaN             NaN            NaN  ...       386       1875   \n",
              "1             NaN             NaN            NaN  ...       464       2288   \n",
              "2             NaN             NaN            NaN  ...       313       1541   \n",
              "3             NaN             NaN            NaN  ...       611       3165   \n",
              "4             NaN             NaN            NaN  ...       517       2569   \n",
              "\n",
              "   avg_word_length  avg_sentence_length  \\\n",
              "0         3.984456                  1.0   \n",
              "1         4.030172                  1.0   \n",
              "2         4.035144                  1.0   \n",
              "3         4.328969                  1.0   \n",
              "4         4.071567                  1.0   \n",
              "\n",
              "                                          pos_ratios  num_sentences  \\\n",
              "0  {'NNP': 0.031088082901554404, 'JJ': 0.05181347...             16   \n",
              "1  {'NNP': 0.03879310344827586, ',': 0.0258620689...             20   \n",
              "2  {'NNP': 0.04153354632587859, ',': 0.0287539936...             14   \n",
              "3  {'NNP': 0.11620294599018004, ',': 0.0212765957...             27   \n",
              "4  {'NNP': 0.017408123791102514, ',': 0.025145067...             30   \n",
              "\n",
              "   num_paragraphs  sentiment_polariy  sentiment_subjectivity  \\\n",
              "0               1           0.310471                0.385613   \n",
              "1               1           0.274000                0.613167   \n",
              "2               1           0.340393                0.498657   \n",
              "3               1           0.266828                0.441795   \n",
              "4               1           0.199684                0.485814   \n",
              "\n",
              "                                   preprocessed_text  \n",
              "0  dear local newspaper think effect computer peo...  \n",
              "1  dear believe using computer benefit u many way...  \n",
              "2  dear people use computer everyone agrees benef...  \n",
              "3  dear local newspaper found many expert say com...  \n",
              "4  dear know computer positive effect people comp...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb7f5c4b-3435-4a96-a21c-97213f143935\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>word_len</th>\n",
              "      <th>chars_len</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>pos_ratios</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>num_paragraphs</th>\n",
              "      <th>sentiment_polariy</th>\n",
              "      <th>sentiment_subjectivity</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>386</td>\n",
              "      <td>1875</td>\n",
              "      <td>3.984456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'NNP': 0.031088082901554404, 'JJ': 0.05181347...</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0.310471</td>\n",
              "      <td>0.385613</td>\n",
              "      <td>dear local newspaper think effect computer peo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>464</td>\n",
              "      <td>2288</td>\n",
              "      <td>4.030172</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'NNP': 0.03879310344827586, ',': 0.0258620689...</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>0.613167</td>\n",
              "      <td>dear believe using computer benefit u many way...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>313</td>\n",
              "      <td>1541</td>\n",
              "      <td>4.035144</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'NNP': 0.04153354632587859, ',': 0.0287539936...</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.340393</td>\n",
              "      <td>0.498657</td>\n",
              "      <td>dear people use computer everyone agrees benef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>611</td>\n",
              "      <td>3165</td>\n",
              "      <td>4.328969</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'NNP': 0.11620294599018004, ',': 0.0212765957...</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0.266828</td>\n",
              "      <td>0.441795</td>\n",
              "      <td>dear local newspaper found many expert say com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>517</td>\n",
              "      <td>2569</td>\n",
              "      <td>4.071567</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'NNP': 0.017408123791102514, ',': 0.025145067...</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.199684</td>\n",
              "      <td>0.485814</td>\n",
              "      <td>dear know computer positive effect people comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb7f5c4b-3435-4a96-a21c-97213f143935')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb7f5c4b-3435-4a96-a21c-97213f143935 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb7f5c4b-3435-4a96-a21c-97213f143935');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(axis = 1, how = 'any')\n",
        "drop_columns = ['essay_id', 'pos_ratios', 'essay', 'rater1_domain1', 'rater2_domain1']\n",
        "df.drop(drop_columns, axis = 1, inplace = True)\n"
      ],
      "metadata": {
        "id": "uq-YzoKIQ9si"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFGPT2Model, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "eghAevBje9zG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = TFGPT2Model.from_pretrained('gpt2')\n",
        "# df_essay_set = df[df.essay_set == 1]\n",
        "# X, y = dataset_preparation(df_essay_set)\n",
        "X_main, y_main = dataset_preparation(df)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 101, test_size = 0.2,)\n",
        "X_main.shape\n"
      ],
      "metadata": {
        "id": "rNjdM-IbQ9uY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05078b48-c8be-4551-fe32-8bf717d2019a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2Model.\n",
            "\n",
            "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12976, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LENGTH = 300\n",
        "\n",
        "train_encodings = tokenizer(list(X_main['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_main)).batch(BATCH_SIZE)\n",
        "\n",
        "embeddings_train = []\n",
        "for batch in tqdm(train_dataset):\n",
        "    embeddings_train.append(model(batch[0]['input_ids'])[0][:, -1, :])\n",
        "embeddings_train = tf.concat(embeddings_train, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwDEX14lOvym",
        "outputId": "c954cca5-a571-4055-8f33-193515d295a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 811/811 [06:21<00:00,  2.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d867BB3NRYIL",
        "outputId": "0fe4b73d-08f3-44aa-a19d-74f352aba288"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12976, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_emb = pd.DataFrame(embeddings_train.numpy()).copy()\n",
        "# y = output_data.copy()"
      ],
      "metadata": {
        "id": "aQS3p5cWSJsM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNY-AOgdWxce"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_lstm=[]\n",
        "final_bilstm=[]\n",
        "final_cnn=[]\n",
        "final_logistic_reg=[]\n",
        "final_random_forest=[]\n",
        "final_adaboost=[]\n",
        "final_k_neighbors=[]\n",
        "final_svc=[]\n",
        "for sets in range(1,9):\n",
        "  X_set = X_emb[df.essay_set == sets]\n",
        "  y_set= y_main[df.essay_set == sets]\n",
        "  X=X_main[df.essay_set == sets]\n",
        "  \n",
        "  # X, y = dataset_preparation(df_essay_set)\n",
        "\n",
        "  # X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 101, test_size = 0.2,)\n",
        "  print(\" -------------------------------------------------\")\n",
        "  print(\" -------------------------------------------------\")\n",
        "  print(\"\\n--------SET {}--------\\n\".format(sets))\n",
        "  print(\" -------------------------------------------------\")\n",
        "  print(\" -------------------------------------------------\")\n",
        "  \n",
        "  start_time = time.time()\n",
        "\n",
        "  cv = KFold(n_splits=5, shuffle=True)\n",
        "  cv_data = cv.split(X_set)\n",
        "  fold_count =1\n",
        "\n",
        "  lstm= [-2 for _ in range(5)]\n",
        "  bilstm= [-2 for _ in range(5)]\n",
        "  cnn= [-2 for _ in range(5)]\n",
        "  logistic_reg= [-2 for _ in range(5)]\n",
        "  random_forest= [-2 for _ in range(5)]\n",
        "  adaboost= [-2 for _ in range(5)]\n",
        "  k_neighbors= [-2 for _ in range(5)]\n",
        "  svc= [-2 for _ in range(5)]\n",
        "\n",
        "\n",
        "  for traincv, testcv in cv_data:\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n",
        "    # tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    # tokenizer.pad_token = tokenizer.eos_token\n",
        "    # model = TFGPT2Model.from_pretrained('gpt2')\n",
        "    X_train, X_test, y_train, y_test = X_set.iloc[traincv], X_set.iloc[testcv], y_set.iloc[traincv], y_set.iloc[testcv]\n",
        "    X_train_temp, X_test_temp=X_main.iloc[traincv],X_main.iloc[testcv]\n",
        "\n",
        "    embeddings_train=tf.constant(X_train.values)\n",
        "    embeddings_test=tf.constant(X_test.values)\n",
        "    \n",
        "    temp_lstm=[]\n",
        "    temp_bilstm=[]\n",
        "    temp_cnn=[]\n",
        "    temp_logistic_reg=[]\n",
        "    temp_random_forest=[]\n",
        "    temp_adaboost=[]\n",
        "    temp_k_neighbors=[]\n",
        "    temp_svc=[]\n",
        "\n",
        "    #LSTM (N,1,L)\n",
        "    print(\"-----------------------LSTM-----------------------\")\n",
        "\n",
        "    trainDataVectors=tf.reshape(embeddings_train,[embeddings_train.shape[0],1,embeddings_train.shape[1]])\n",
        "    testDataVectors=tf.reshape(embeddings_test,[embeddings_test.shape[0],1,embeddings_test.shape[1]]) \n",
        "    lstm_model = get_model(bidirectional=False)\n",
        "    history= lstm_model.fit(trainDataVectors, y_train, batch_size=128, epochs=50)\n",
        "    y_pred = lstm_model.predict(testDataVectors)\n",
        "    y_pred = np.around(y_pred)\n",
        "    np.nan_to_num(y_pred)\n",
        "    # plot_accuracy_curve(history)\n",
        "    temp_lstm =list(print_metrics_function(y_test, y_pred))\n",
        "    lstm= max_list(lstm, temp_lstm)\n",
        "    \n",
        "    \n",
        "    #BiLSTM\n",
        "    print(\"-----------------------BiLSTM-----------------------\")\n",
        "\n",
        "    Hidden_dim1=300\n",
        "    Hidden_dim2=100\n",
        "    return_sequences = True\n",
        "    dropout=0.2\n",
        "    recurrent_dropout=0.2\n",
        "    input_size=768\n",
        "    activation='relu'\n",
        "    bidirectional = True\n",
        "    batch_size = 64\n",
        "    epoch = 50\n",
        "    lstm_model = get_model(Hidden_dim1=Hidden_dim1, Hidden_dim2=Hidden_dim2, return_sequences=return_sequences,\n",
        "                                dropout=dropout, recurrent_dropout=recurrent_dropout, input_size=input_size,\n",
        "                                activation=activation, bidirectional=bidirectional)\n",
        "    history = lstm_model.fit(trainDataVectors, y_train, batch_size=batch_size, epochs=epoch)\n",
        "    y_pred = lstm_model.predict(testDataVectors)\n",
        "    y_pred = np.around(y_pred)\n",
        "    np.nan_to_num(y_pred)\n",
        "    # plot_accuracy_curve(history)\n",
        "    temp_bilstm =list(print_metrics_function(y_test, y_pred))\n",
        "    bilstm= max_list(bilstm, temp_bilstm)\n",
        "    \n",
        "\n",
        "    #CNN\n",
        "    print(\"-----------------------CNN-----------------------\")\n",
        "\n",
        "    trainDataVectors_=tf.reshape(trainDataVectors,[trainDataVectors.shape[0],trainDataVectors.shape[2],1])\n",
        "    testDataVectors_=tf.reshape(testDataVectors,[testDataVectors.shape[0],testDataVectors.shape[2],1])  \n",
        "    cnn_model = get_model_CNN(output_dims=1)\n",
        "    history=cnn_model.fit(trainDataVectors_, y_train, batch_size=128, epochs=100)\n",
        "    y_pred = cnn_model.predict(testDataVectors_)\n",
        "    y_pred = np.around(y_pred)\n",
        "    np.nan_to_num(y_pred)\n",
        "    # plot_accuracy_curve(history)\n",
        "    temp_cnn =list(print_metrics_function(y_test, y_pred))\n",
        "    cnn= max_list(cnn, temp_cnn)\n",
        "    \n",
        "    #New features from feature engineering\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_temp.drop(['preprocessed_text'], axis = 1))\n",
        "    X_test_scaled = scaler.transform(X_test_temp.drop(['preprocessed_text'], axis = 1))\n",
        "    X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
        "    X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
        "\n",
        "    embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
        "    embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)\n",
        "    print()\n",
        "    print(\"-----------------------Logistic Regression-----------------------\")\n",
        "    model = choose_classifiers(\"logistic_regression\")\n",
        "    model.fit(embeddings_train, y_train)\n",
        "    y_predictions = model.predict(embeddings_test)\n",
        "    temp_logistic_reg =list(print_metrics_function(y_test, y_predictions))\n",
        "    logistic_reg= max_list(logistic_reg, temp_logistic_reg)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"-----------------------Random Forest Classifier-----------------------\")\n",
        "    model = choose_classifiers(\"random_forest_classifier\")\n",
        "    model.fit(embeddings_train, y_train)\n",
        "    y_predictions = model.predict(embeddings_test)\n",
        "    temp_random_forest =list(print_metrics_function(y_test, y_predictions))\n",
        "    random_forest= max_list(random_forest, temp_random_forest)\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    print(\"-----------------------Adaboost Classifier-----------------------\")\n",
        "    model = choose_classifiers(\"adaboost_classifier\")\n",
        "    model.fit(embeddings_train, y_train)\n",
        "    y_predictions = model.predict(embeddings_test)\n",
        "    temp_adaboost =list(print_metrics_function(y_test, y_predictions))\n",
        "    adaboost= max_list(adaboost, temp_adaboost)\n",
        "    \n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
        "    model = choose_classifiers(\"k_neighbors_classifier\")\n",
        "    model.fit(embeddings_train, y_train)\n",
        "    y_predictions = model.predict(embeddings_test)\n",
        "    temp_k_neighbors =list(print_metrics_function(y_test, y_predictions))\n",
        "    k_neighbors= max_list(k_neighbors, temp_k_neighbors)\n",
        "    \n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"-----------------------Support Vector Classifier-----------------------\")\n",
        "    model = choose_classifiers(\"support_vector_classifier\")\n",
        "    model.fit(embeddings_train, y_train)\n",
        "    y_predictions = model.predict(embeddings_test)\n",
        "    temp_svc =list(print_metrics_function(y_test, y_predictions))\n",
        "    svc= max_list(svc, temp_svc)\n",
        "\n",
        "    fold_count+=1\n",
        "\n",
        "  end_time = time.time()\n",
        "  time_taken = end_time - start_time\n",
        "\n",
        "  print(\"Time taken: {:.5f} seconds\".format(time_taken))\n",
        "\n",
        "  \n",
        "  # Define the metric names and their corresponding values\n",
        "  metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Kappa Score\"]\n",
        "\n",
        "  metrics_list=[lstm, bilstm, cnn, logistic_reg, random_forest, adaboost, k_neighbors, svc]\n",
        "  # Define the ML model names\n",
        "  model_names = [\"LSTM\",\"BiLSTM\",\"CNN\",\"Logistic Regression\", \"Random Forest Classifier\", \"Adaboost Classifier\", \n",
        "                \"K Neighbors Classifier\", \"Support Vector Classifier\"]\n",
        "\n",
        "  # Create a PrettyTable object with the metric names as column headers\n",
        "  table = PrettyTable([\"Model\"] + metric_names)\n",
        "\n",
        "  # Add the metric values for each model as rows to the table\n",
        "  for i, model_name in enumerate(model_names):\n",
        "      row = [model_name]\n",
        "      for j in range(len(metric_names)):\n",
        "          value = metrics_list[i][j]\n",
        "\n",
        "          # Format the value with three decimal places\n",
        "          value_formatted = f\"{value:.3f}\"\n",
        "          row.append(value_formatted)\n",
        "\n",
        "      table.add_row(row)\n",
        "\n",
        "  # Print the formatted table\n",
        "  print(table.get_string())\n",
        "  final_lstm.append(lstm[4])\n",
        "  final_bilstm.append(bilstm[4])\n",
        "  final_cnn.append(cnn[4])\n",
        "  final_logistic_reg.append(logistic_reg[4])\n",
        "  final_random_forest.append(random_forest[4])\n",
        "  final_adaboost.append(adaboost[4])\n",
        "  final_k_neighbors.append(k_neighbors[4])\n",
        "  final_svc.append(svc[4])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaeUM0n8PREG",
        "outputId": "dcacc309-a84c-4787-a0f6-50b14d12bbba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 1--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 18ms/step - loss: 23.5425 - mae: 3.7956\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 3.0898 - mae: 1.3268\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.7360 - mae: 1.2553\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 2.5309 - mae: 1.2049\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 2.5767 - mae: 1.2032\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.5047 - mae: 1.1838\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2.3732 - mae: 1.1488\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2.2912 - mae: 1.1273\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2.3234 - mae: 1.1353\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2.2475 - mae: 1.1182\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2.1246 - mae: 1.0888\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1.9700 - mae: 1.0540\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1.9515 - mae: 1.0581\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1.7707 - mae: 1.0112\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.6701 - mae: 0.9671\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1.7581 - mae: 1.0197\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.7833 - mae: 1.0322\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.5508 - mae: 0.9548\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1.5141 - mae: 0.9478\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.4969 - mae: 0.9511\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.5534 - mae: 0.9487\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.5935 - mae: 0.9711\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3092 - mae: 0.8757\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.6663 - mae: 1.0062\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4132 - mae: 0.9261\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.4611 - mae: 0.9296\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4531 - mae: 0.9387\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5478 - mae: 0.9760\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3688 - mae: 0.9016\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2573 - mae: 0.8531\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.5840 - mae: 0.9858\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2911 - mae: 0.8892\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2766 - mae: 0.8788\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3465 - mae: 0.9065\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2439 - mae: 0.8764\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4396 - mae: 0.9459\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3197 - mae: 0.9069\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3060 - mae: 0.8923\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2140 - mae: 0.8627\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3533 - mae: 0.9067\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1691 - mae: 0.8387\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2301 - mae: 0.8698\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1884 - mae: 0.8557\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2484 - mae: 0.8782\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3259 - mae: 0.9138\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1553 - mae: 0.8311\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1996 - mae: 0.8535\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2440 - mae: 0.8744\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1590 - mae: 0.8393\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2184 - mae: 0.8591\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45938375350140054\n",
            "Precision: 0.43254285751572574\n",
            "Recall: 0.4684844622800828\n",
            "F1-Score: 0.39473295363143257\n",
            "Cohen Kappa Score: 0.7797129719938694\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 1, 600)           2565600   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 200)              560800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 12s 26ms/step - loss: 10.3367 - mae: 2.1677\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 2.6684 - mae: 1.2309\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 2.4611 - mae: 1.1851\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 2.3925 - mae: 1.1612\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 2.4043 - mae: 1.1516\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 2.1414 - mae: 1.0959\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 2.0432 - mae: 1.0651\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 2.0396 - mae: 1.0729\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.7617 - mae: 1.0008\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 1.8003 - mae: 1.0171\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 1.5274 - mae: 0.9394\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 1.5183 - mae: 0.9595\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 1.6700 - mae: 0.9967\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.4628 - mae: 0.9325\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.5151 - mae: 0.9493\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.4212 - mae: 0.9225\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.3854 - mae: 0.9140\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.3783 - mae: 0.9094\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.3606 - mae: 0.9128\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.2597 - mae: 0.8712\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.3814 - mae: 0.9331\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.2757 - mae: 0.8811\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.3727 - mae: 0.9138\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1990 - mae: 0.8528\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.2810 - mae: 0.8837\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1991 - mae: 0.8545\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.1455 - mae: 0.8301\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 1.1754 - mae: 0.8486\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 1.1261 - mae: 0.8398\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 1.0827 - mae: 0.8223\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 1.2062 - mae: 0.8666\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0639 - mae: 0.8006\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 1.1645 - mae: 0.8443\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1007 - mae: 0.8315\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.1278 - mae: 0.8305\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.1502 - mae: 0.8414\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0997 - mae: 0.8251\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0896 - mae: 0.8225\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0208 - mae: 0.8024\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1402 - mae: 0.8290\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.0601 - mae: 0.8057\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.0179 - mae: 0.7929\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.0756 - mae: 0.8151\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0212 - mae: 0.7904\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0366 - mae: 0.8032\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0335 - mae: 0.7907\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0824 - mae: 0.8119\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.9544 - mae: 0.7758\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.0179 - mae: 0.7846\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.0126 - mae: 0.7912\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.4257703081232493\n",
            "Precision: 0.34167336245297264\n",
            "Recall: 0.4207360360645032\n",
            "F1-Score: 0.33271392712108594\n",
            "Cohen Kappa Score: 0.708102044925077\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.7118 - mae: 8.5014 - mse: 74.7118\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.4649859943977591\n",
            "Precision: 0.16270649269596082\n",
            "Recall: 0.18509811356526684\n",
            "F1-Score: 0.1683094320575845\n",
            "Cohen Kappa Score: 0.5790577763836336\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.5322128851540616\n",
            "Precision: 0.3331330528381949\n",
            "Recall: 0.3436785301748805\n",
            "F1-Score: 0.33187551639571805\n",
            "Cohen Kappa Score: 0.7590571444790893\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.45938375350140054\n",
            "Precision: 0.10122215238494309\n",
            "Recall: 0.17958521608156644\n",
            "F1-Score: 0.12687005572381066\n",
            "Cohen Kappa Score: 0.5819827357862347\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.46218487394957986\n",
            "Precision: 0.25644517933520494\n",
            "Recall: 0.28039352510155424\n",
            "F1-Score: 0.26515599771421194\n",
            "Cohen Kappa Score: 0.6931536354964769\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4117647058823529\n",
            "Precision: 0.09105873550317994\n",
            "Recall: 0.12776039856331828\n",
            "F1-Score: 0.08991613746685603\n",
            "Cohen Kappa Score: 0.22092970169559623\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 33ms/step - loss: 22.5171 - mae: 3.6367\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2.9388 - mae: 1.3113\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2.6331 - mae: 1.2362\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2.5473 - mae: 1.2041\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2.3005 - mae: 1.1641\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2.3224 - mae: 1.1655\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2.3436 - mae: 1.1476\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2.1848 - mae: 1.1124\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2.2202 - mae: 1.1215\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.0220 - mae: 1.0531\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.1045 - mae: 1.1005\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.9047 - mae: 1.0402\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.8707 - mae: 1.0377\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6227 - mae: 0.9522\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.7128 - mae: 0.9944\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.7754 - mae: 1.0190\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6348 - mae: 0.9874\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3801 - mae: 0.8984\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.7184 - mae: 1.0152\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.6178 - mae: 0.9988\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4719 - mae: 0.9384\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3805 - mae: 0.9202\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.4352 - mae: 0.9182\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3595 - mae: 0.9094\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.4124 - mae: 0.9337\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4998 - mae: 0.9536\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5288 - mae: 0.9607\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3312 - mae: 0.8902\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3390 - mae: 0.9032\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4755 - mae: 0.9625\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2250 - mae: 0.8651\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4294 - mae: 0.9497\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1935 - mae: 0.8514\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3071 - mae: 0.9053\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.2401 - mae: 0.8685\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2681 - mae: 0.8830\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2543 - mae: 0.8712\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2074 - mae: 0.8555\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2405 - mae: 0.8732\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2369 - mae: 0.8832\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.1985 - mae: 0.8638\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3111 - mae: 0.9070\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1348 - mae: 0.8374\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2972 - mae: 0.8850\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3114 - mae: 0.8998\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1734 - mae: 0.8503\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1473 - mae: 0.8261\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2200 - mae: 0.8689\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2002 - mae: 0.8552\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2347 - mae: 0.8601\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.36694677871148457\n",
            "Precision: 0.2167686542847833\n",
            "Recall: 0.20743778887622924\n",
            "F1-Score: 0.19326955486708128\n",
            "Cohen Kappa Score: 0.7363301787592008\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 1, 600)           2565600   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 200)              560800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 55ms/step - loss: 10.4114 - mae: 2.2105\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 2.5186 - mae: 1.2103\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 2.2739 - mae: 1.1411\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 2.2691 - mae: 1.1328\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 2.2005 - mae: 1.1105\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 2.0916 - mae: 1.0959\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 2.0511 - mae: 1.1015\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.8607 - mae: 1.0272\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.7025 - mae: 0.9900\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.5704 - mae: 0.9522\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.7171 - mae: 1.0026\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.4579 - mae: 0.9403\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.5070 - mae: 0.9433\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.4139 - mae: 0.9313\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.4165 - mae: 0.9323\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.3568 - mae: 0.9085\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.3749 - mae: 0.9191\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 1.3095 - mae: 0.8845\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 1.3959 - mae: 0.9124\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 1.2785 - mae: 0.8868\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.2201 - mae: 0.8687\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.2753 - mae: 0.8834\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.1423 - mae: 0.8294\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.2366 - mae: 0.8597\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.1739 - mae: 0.8513\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.2272 - mae: 0.8708\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 1.1183 - mae: 0.8346\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.2552 - mae: 0.8730\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1172 - mae: 0.8211\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1732 - mae: 0.8525\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0873 - mae: 0.8052\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.1736 - mae: 0.8571\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1031 - mae: 0.8289\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0966 - mae: 0.8163\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0717 - mae: 0.8123\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0674 - mae: 0.8089\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0604 - mae: 0.8074\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 1.0317 - mae: 0.7969\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 1.0305 - mae: 0.7949\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 1.0249 - mae: 0.8010\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.0363 - mae: 0.7994\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.9949 - mae: 0.7769\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0109 - mae: 0.7879\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0210 - mae: 0.7955\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.9928 - mae: 0.7817\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0277 - mae: 0.7901\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.9941 - mae: 0.7784\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0428 - mae: 0.8041\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.9965 - mae: 0.7778\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.9709 - mae: 0.7752\n",
            "12/12 [==============================] - 1s 3ms/step\n",
            "Accuracy: 0.34173669467787116\n",
            "Precision: 0.2091020017226377\n",
            "Recall: 0.18814562289183215\n",
            "F1-Score: 0.17303398954787175\n",
            "Cohen Kappa Score: 0.7357740495701719\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9088 - mae: 8.5203 - mse: 74.9088\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.484593837535014\n",
            "Precision: 0.23634947876938725\n",
            "Recall: 0.18239551668595635\n",
            "F1-Score: 0.17267548812743322\n",
            "Cohen Kappa Score: 0.5920682730923694\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.5154061624649859\n",
            "Precision: 0.4268524730334122\n",
            "Recall: 0.41652935710543576\n",
            "F1-Score: 0.4066128566683475\n",
            "Cohen Kappa Score: 0.7861079786627472\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.48739495798319327\n",
            "Precision: 0.16979496286729093\n",
            "Recall: 0.2687096774193548\n",
            "F1-Score: 0.2038569059464582\n",
            "Cohen Kappa Score: 0.654312188168211\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.47058823529411764\n",
            "Precision: 0.29551288839203954\n",
            "Recall: 0.28682177978530654\n",
            "F1-Score: 0.28505316351045573\n",
            "Cohen Kappa Score: 0.7547545249301649\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0796472184531886\n",
            "Recall: 0.1129032258064516\n",
            "F1-Score: 0.07946428571428571\n",
            "Cohen Kappa Score: 0.19090479341968425\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 40ms/step - loss: 23.6409 - mae: 3.7935\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3.0839 - mae: 1.3222\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.7274 - mae: 1.2495\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.4908 - mae: 1.1976\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.4498 - mae: 1.1747\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.4063 - mae: 1.1609\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.2361 - mae: 1.1132\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.3542 - mae: 1.1701\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.0777 - mae: 1.0749\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.0111 - mae: 1.0690\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.9734 - mae: 1.0744\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.1829 - mae: 1.1324\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.7985 - mae: 1.0170\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.8448 - mae: 1.0471\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.7297 - mae: 0.9984\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.6314 - mae: 0.9761\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6650 - mae: 0.9938\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.5604 - mae: 0.9728\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5461 - mae: 0.9462\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6206 - mae: 0.9900\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.5651 - mae: 0.9708\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.4616 - mae: 0.9300\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5877 - mae: 0.9793\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2530 - mae: 0.8774\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.5134 - mae: 0.9532\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4268 - mae: 0.9338\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3639 - mae: 0.9175\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3251 - mae: 0.8986\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3977 - mae: 0.9215\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3930 - mae: 0.9282\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3592 - mae: 0.9178\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.2375 - mae: 0.8854\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5078 - mae: 0.9588\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1819 - mae: 0.8547\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3762 - mae: 0.9276\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3021 - mae: 0.8950\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2731 - mae: 0.8870\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2154 - mae: 0.8722\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3184 - mae: 0.9051\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.0998 - mae: 0.8142\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.2858 - mae: 0.9030\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2241 - mae: 0.8664\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2214 - mae: 0.8629\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2228 - mae: 0.8726\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2363 - mae: 0.8678\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.1563 - mae: 0.8493\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2362 - mae: 0.8739\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1989 - mae: 0.8548\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1612 - mae: 0.8517\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1941 - mae: 0.8436\n",
            "12/12 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45098039215686275\n",
            "Precision: 0.257671864443518\n",
            "Recall: 0.23233334157332589\n",
            "F1-Score: 0.22890764844730177\n",
            "Cohen Kappa Score: 0.7386410824486151\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (None, 1, 600)           2565600   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 200)              560800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 10s 28ms/step - loss: 10.9888 - mae: 2.2548\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 2.7269 - mae: 1.2551\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 2.4487 - mae: 1.1806\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 2.3238 - mae: 1.1425\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 2.1536 - mae: 1.1100\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 2.1049 - mae: 1.0808\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 2.0305 - mae: 1.0752\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 1.9215 - mae: 1.0438\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 1.7037 - mae: 0.9736\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.8036 - mae: 1.0386\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.5926 - mae: 0.9627\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.5818 - mae: 0.9697\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.5108 - mae: 0.9450\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.5180 - mae: 0.9692\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.3930 - mae: 0.9179\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.4389 - mae: 0.9376\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.3633 - mae: 0.9125\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.3414 - mae: 0.9023\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.4003 - mae: 0.9192\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.3612 - mae: 0.9101\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.2397 - mae: 0.8749\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 1.2776 - mae: 0.8940\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 1.1610 - mae: 0.8461\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.3082 - mae: 0.9009\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 1.1039 - mae: 0.8258\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 1.2987 - mae: 0.8965\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 1.1752 - mae: 0.8518\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 1.2189 - mae: 0.8725\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.1330 - mae: 0.8390\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1648 - mae: 0.8427\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.1954 - mae: 0.8592\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1337 - mae: 0.8387\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0745 - mae: 0.8165\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0463 - mae: 0.8061\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0431 - mae: 0.7990\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.1337 - mae: 0.8324\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1094 - mae: 0.8346\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0420 - mae: 0.7947\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0785 - mae: 0.8198\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1179 - mae: 0.8285\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.9939 - mae: 0.7839\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0798 - mae: 0.8090\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0018 - mae: 0.7883\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0338 - mae: 0.7957\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 1.0574 - mae: 0.8108\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 1.0389 - mae: 0.8050\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.9866 - mae: 0.7774\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.9961 - mae: 0.7813\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0360 - mae: 0.7981\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0107 - mae: 0.7844\n",
            "12/12 [==============================] - 1s 3ms/step\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.2903797136519459\n",
            "Recall: 0.26112113338350573\n",
            "F1-Score: 0.2581684856708785\n",
            "Cohen Kappa Score: 0.7608978529603123\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 33.5373 - mae: 4.7596 - mse: 33.5373\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.1551 - mae: 2.5096 - mse: 9.1551\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1790 - mae: 1.6431 - mse: 4.1790\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.6889 - mae: 1.2281 - mse: 2.6889\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5845 - mae: 1.2042 - mse: 2.5845\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4659 - mae: 1.1805 - mse: 2.4659\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7000 - mae: 1.2168 - mse: 2.7000\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.4862 - mae: 1.1799 - mse: 2.4862\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4487 - mae: 1.1733 - mse: 2.4487\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5147 - mae: 1.1603 - mse: 2.5147\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4546 - mae: 1.1592 - mse: 2.4546\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4481 - mae: 1.1634 - mse: 2.4481\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.5783 - mae: 1.2033 - mse: 2.5783\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4148 - mae: 1.1642 - mse: 2.4148\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5090 - mae: 1.1881 - mse: 2.5090\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5562 - mae: 1.1992 - mse: 2.5562\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4433 - mae: 1.1662 - mse: 2.4433\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.4039 - mae: 1.1494 - mse: 2.4039\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4175 - mae: 1.1707 - mse: 2.4175\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.5064 - mae: 1.1994 - mse: 2.5064\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.3283 - mae: 1.1420 - mse: 2.3283\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5522 - mae: 1.2041 - mse: 2.5522\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.0969 - mae: 1.3546 - mse: 3.0969\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.2414 - mae: 1.4132 - mse: 3.2414\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8179 - mae: 1.2682 - mse: 2.8179\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8216 - mae: 1.2773 - mse: 2.8216\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5378 - mae: 1.4870 - mse: 3.5378\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5102 - mae: 1.1885 - mse: 2.5102\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7916 - mae: 1.3065 - mse: 2.7916\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7329 - mae: 1.5651 - mse: 3.7329\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7798 - mae: 1.2802 - mse: 2.7798\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8344 - mae: 1.3139 - mse: 2.8344\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3534 - mae: 1.4416 - mse: 3.3534\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7698 - mae: 1.2974 - mse: 2.7698\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4717 - mae: 1.1861 - mse: 2.4717\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.3080 - mae: 1.1410 - mse: 2.3080\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6665 - mae: 1.2496 - mse: 2.6665\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2846 - mae: 1.1347 - mse: 2.2846\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.1934 - mae: 1.0941 - mse: 2.1934\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.1263 - mae: 1.0874 - mse: 2.1263\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4810 - mae: 1.1812 - mse: 2.4810\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.4487 - mae: 1.1849 - mse: 2.4487\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.6503 - mae: 1.2639 - mse: 2.6503\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.2475 - mae: 1.1155 - mse: 2.2475\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.4164 - mae: 1.1838 - mse: 2.4164\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.7023 - mae: 1.2684 - mse: 2.7023\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4846 - mae: 1.1969 - mse: 2.4846\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7513 - mae: 1.2808 - mse: 2.7513\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.2082 - mae: 1.1040 - mse: 2.2082\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.3230 - mae: 1.1403 - mse: 2.3230\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.0653 - mae: 1.0677 - mse: 2.0653\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1545 - mae: 1.1051 - mse: 2.1545\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.2520 - mae: 1.1216 - mse: 2.2520\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1219 - mae: 1.0767 - mse: 2.1219\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0025 - mae: 1.0492 - mse: 2.0025\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9991 - mae: 1.0401 - mse: 1.9991\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9934 - mae: 1.0465 - mse: 1.9934\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9810 - mae: 1.0427 - mse: 1.9810\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0619 - mae: 1.0658 - mse: 2.0619\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.5290 - mae: 1.2464 - mse: 2.5290\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0828 - mae: 1.0572 - mse: 2.0828\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9694 - mae: 1.0364 - mse: 1.9694\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9843 - mae: 1.0409 - mse: 1.9843\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0895 - mae: 1.0785 - mse: 2.0895\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1563 - mae: 1.0942 - mse: 2.1563\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9559 - mae: 1.0391 - mse: 1.9559\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.8894 - mae: 1.0228 - mse: 1.8894\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6704 - mae: 1.2549 - mse: 2.6704\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9722 - mae: 1.0289 - mse: 1.9722\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.4037 - mae: 1.1988 - mse: 2.4037\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.7490 - mae: 1.2672 - mse: 2.7490\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0662 - mae: 1.0841 - mse: 2.0662\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9186 - mae: 1.0347 - mse: 1.9186\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9332 - mae: 1.0288 - mse: 1.9332\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.1852 - mae: 1.1265 - mse: 2.1852\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9775 - mae: 1.0488 - mse: 1.9775\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.8423 - mae: 1.0007 - mse: 1.8423\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2511 - mae: 1.1414 - mse: 2.2511\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.9649 - mae: 1.0465 - mse: 1.9649\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.8105 - mae: 1.0021 - mse: 1.8105\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.8997 - mae: 1.0321 - mse: 1.8997\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.4460 - mae: 1.2220 - mse: 2.4460\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.9625 - mae: 1.0615 - mse: 1.9625\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.0385 - mae: 1.0753 - mse: 2.0385\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2485 - mae: 1.1708 - mse: 2.2485\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.1185 - mae: 1.1234 - mse: 2.1185\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8800 - mae: 1.3747 - mse: 2.8800\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2852 - mae: 1.1652 - mse: 2.2852\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.3687 - mae: 1.2014 - mse: 2.3687\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.3869 - mae: 1.2127 - mse: 2.3869\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.8474 - mae: 1.0085 - mse: 1.8474\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6968 - mae: 0.9544 - mse: 1.6968\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6813 - mae: 0.9516 - mse: 1.6813\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.9831 - mae: 1.0814 - mse: 1.9831\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.8635 - mae: 1.0243 - mse: 1.8635\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.1564 - mae: 1.1410 - mse: 2.1564\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.7585 - mae: 0.9958 - mse: 1.7585\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6363 - mae: 0.9422 - mse: 1.6363\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6534 - mae: 0.9446 - mse: 1.6534\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.5917 - mae: 0.9268 - mse: 1.5917\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.4257703081232493\n",
            "Precision: 0.1906806310627865\n",
            "Recall: 0.16341772916792555\n",
            "F1-Score: 0.14639429020989175\n",
            "Cohen Kappa Score: 0.45019221126525155\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.4565826330532213\n",
            "Precision: 0.1596848924022837\n",
            "Recall: 0.1615911974906476\n",
            "F1-Score: 0.1526348956163675\n",
            "Cohen Kappa Score: 0.49303016453382076\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.49019607843137253\n",
            "Precision: 0.4457742345022641\n",
            "Recall: 0.42223500641803857\n",
            "F1-Score: 0.4265264747870165\n",
            "Cohen Kappa Score: 0.7659940884774166\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.49019607843137253\n",
            "Precision: 0.19484413656605643\n",
            "Recall: 0.26689280868385346\n",
            "F1-Score: 0.2201708207993124\n",
            "Cohen Kappa Score: 0.5956611138386456\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.4649859943977591\n",
            "Precision: 0.39751461035538865\n",
            "Recall: 0.30365552619676733\n",
            "F1-Score: 0.3214135213513082\n",
            "Cohen Kappa Score: 0.6897319166096972\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42016806722689076\n",
            "Precision: 0.07875169606512891\n",
            "Recall: 0.11124099780816199\n",
            "F1-Score: 0.07739175403131024\n",
            "Cohen Kappa Score: 0.17757493264046287\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 18ms/step - loss: 23.6456 - mae: 3.7776\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.0925 - mae: 1.3074\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.5555 - mae: 1.2015\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.4800 - mae: 1.2010\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.4266 - mae: 1.1775\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.3982 - mae: 1.1719\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.3151 - mae: 1.1479\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.1404 - mae: 1.0998\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.1432 - mae: 1.1067\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.9636 - mae: 1.0456\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 2.1298 - mae: 1.1092\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.8317 - mae: 1.0209\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.8106 - mae: 1.0183\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.8017 - mae: 1.0223\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.7573 - mae: 1.0262\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6494 - mae: 0.9828\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.5523 - mae: 0.9509\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.6980 - mae: 1.0073\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5596 - mae: 0.9689\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.5667 - mae: 0.9562\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.3396 - mae: 0.8831\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1.4319 - mae: 0.9221\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.5288 - mae: 0.9532\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.3904 - mae: 0.9112\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1.3685 - mae: 0.9027\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.4175 - mae: 0.9193\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.4149 - mae: 0.9202\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1.5156 - mae: 0.9508\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1.2076 - mae: 0.8456\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1.3251 - mae: 0.9009\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1.3036 - mae: 0.9037\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.3126 - mae: 0.8982\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.3498 - mae: 0.9118\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.2805 - mae: 0.8763\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2899 - mae: 0.8950\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4153 - mae: 0.9252\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3628 - mae: 0.9067\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1740 - mae: 0.8428\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2832 - mae: 0.8937\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2816 - mae: 0.8816\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2092 - mae: 0.8619\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2115 - mae: 0.8648\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2442 - mae: 0.8706\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1836 - mae: 0.8500\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1300 - mae: 0.8313\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1783 - mae: 0.8540\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.0822 - mae: 0.8211\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2563 - mae: 0.8909\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.1251 - mae: 0.8240\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.1252 - mae: 0.8306\n",
            "12/12 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2752808988764045\n",
            "Precision: 0.14554621848739496\n",
            "Recall: 0.1365483077878413\n",
            "F1-Score: 0.12461638653949843\n",
            "Cohen Kappa Score: 0.6751548461747889\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 26ms/step - loss: 11.3186 - mae: 2.2935\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 2.4971 - mae: 1.1972\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.4493 - mae: 1.1702\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 2.2880 - mae: 1.1439\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 2.2540 - mae: 1.1200\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 1.9858 - mae: 1.0559\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.9559 - mae: 1.0725\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.8263 - mae: 1.0193\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.9322 - mae: 1.0463\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.6316 - mae: 0.9772\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.7081 - mae: 0.9780\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.4629 - mae: 0.9340\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.5594 - mae: 0.9689\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.3834 - mae: 0.9137\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.4170 - mae: 0.9279\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.4347 - mae: 0.9116\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.2999 - mae: 0.8916\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.3953 - mae: 0.9295\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.1671 - mae: 0.8352\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.3300 - mae: 0.9032\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.2722 - mae: 0.8683\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 1.2297 - mae: 0.8653\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.2529 - mae: 0.8757\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.3227 - mae: 0.9089\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.0865 - mae: 0.8116\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1939 - mae: 0.8640\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.1810 - mae: 0.8489\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1244 - mae: 0.8211\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 1.0892 - mae: 0.8178\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1191 - mae: 0.8325\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.1278 - mae: 0.8377\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0893 - mae: 0.8115\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0949 - mae: 0.8219\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0395 - mae: 0.8066\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.0082 - mae: 0.7916\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0777 - mae: 0.8161\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0042 - mae: 0.7814\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0666 - mae: 0.8072\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 1.0676 - mae: 0.8178\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0628 - mae: 0.8022\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.9617 - mae: 0.7650\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 1.0125 - mae: 0.7797\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 1.0052 - mae: 0.7807\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.9526 - mae: 0.7626\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.9500 - mae: 0.7573\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0158 - mae: 0.7818\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.9905 - mae: 0.7893\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.9725 - mae: 0.7744\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.9718 - mae: 0.7700\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.0043 - mae: 0.7777\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.4044943820224719\n",
            "Precision: 0.41510866919299066\n",
            "Recall: 0.4558641646485546\n",
            "F1-Score: 0.3983297495157662\n",
            "Cohen Kappa Score: 0.7978473391561376\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 24ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 74.9236 - mae: 8.5186 - mse: 74.9236\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.49157303370786515\n",
            "Precision: 0.19723024858722518\n",
            "Recall: 0.1934224547786151\n",
            "F1-Score: 0.18483274280268444\n",
            "Cohen Kappa Score: 0.6766480629145073\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.4803370786516854\n",
            "Precision: 0.41686611125970396\n",
            "Recall: 0.3821947671977576\n",
            "F1-Score: 0.3783992255745032\n",
            "Cohen Kappa Score: 0.7796174685234347\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4157303370786517\n",
            "Precision: 0.16350142597873996\n",
            "Recall: 0.2351226076555024\n",
            "F1-Score: 0.18608510990592259\n",
            "Cohen Kappa Score: 0.5854988092087854\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.45224719101123595\n",
            "Precision: 0.28493786343328675\n",
            "Recall: 0.24378931522322667\n",
            "F1-Score: 0.2515088640325707\n",
            "Cohen Kappa Score: 0.7231444797613846\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.38202247191011235\n",
            "Precision: 0.07175731182263573\n",
            "Recall: 0.10455293062200957\n",
            "F1-Score: 0.07069378645903387\n",
            "Cohen Kappa Score: 0.15313826222917126\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_24 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 15ms/step - loss: 23.1869 - mae: 3.7296\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.7797 - mae: 1.2756\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.5819 - mae: 1.2265\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 2.3153 - mae: 1.1668\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2.3666 - mae: 1.1751\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2.2730 - mae: 1.1439\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2.2319 - mae: 1.1343\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 2.2091 - mae: 1.1363\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2.0655 - mae: 1.0906\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.9331 - mae: 1.0502\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2.0501 - mae: 1.0875\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.8387 - mae: 1.0181\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.8033 - mae: 1.0125\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.8796 - mae: 1.0584\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.4274 - mae: 0.9068\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.8980 - mae: 1.0559\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.7415 - mae: 1.0382\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4724 - mae: 0.9381\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.5462 - mae: 0.9626\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.5637 - mae: 0.9719\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4754 - mae: 0.9352\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2998 - mae: 0.8890\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5421 - mae: 0.9698\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4027 - mae: 0.9557\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3490 - mae: 0.9044\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5883 - mae: 0.9836\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1396 - mae: 0.8304\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.4247 - mae: 0.9296\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3920 - mae: 0.9339\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3973 - mae: 0.9237\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.3275 - mae: 0.9035\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1589 - mae: 0.8392\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2878 - mae: 0.8877\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.2684 - mae: 0.8743\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2642 - mae: 0.8956\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1570 - mae: 0.8258\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3665 - mae: 0.9309\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3207 - mae: 0.9041\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2094 - mae: 0.8727\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1961 - mae: 0.8615\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2825 - mae: 0.8778\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.2133 - mae: 0.8648\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1145 - mae: 0.8206\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1963 - mae: 0.8588\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1436 - mae: 0.8432\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.1046 - mae: 0.8264\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2059 - mae: 0.8717\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.2362 - mae: 0.8702\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.1809 - mae: 0.8464\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2056 - mae: 0.8534\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3258426966292135\n",
            "Precision: 0.2069193033904409\n",
            "Recall: 0.29184683972743675\n",
            "F1-Score: 0.2119554476501157\n",
            "Cohen Kappa Score: 0.7324564386468436\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 13s 28ms/step - loss: 10.3186 - mae: 2.2103\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 2.4180 - mae: 1.1781\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 2.3078 - mae: 1.1570\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 2.2274 - mae: 1.1240\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 2.1207 - mae: 1.1067\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 2.1430 - mae: 1.1167\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 1.8940 - mae: 1.0385\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 1.8415 - mae: 1.0528\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.7276 - mae: 1.0129\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 1.5892 - mae: 0.9712\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.6131 - mae: 0.9845\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.3955 - mae: 0.9237\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.5220 - mae: 0.9540\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.3261 - mae: 0.8994\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.3658 - mae: 0.9140\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 1.4089 - mae: 0.9225\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.2722 - mae: 0.8839\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.2405 - mae: 0.8634\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.3172 - mae: 0.8969\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.2685 - mae: 0.8850\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.2716 - mae: 0.8871\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.1866 - mae: 0.8659\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.1840 - mae: 0.8605\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.2013 - mae: 0.8625\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.1401 - mae: 0.8282\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 1.2507 - mae: 0.8715\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 1.0090 - mae: 0.7861\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 1.1775 - mae: 0.8569\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 1.1398 - mae: 0.8515\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0938 - mae: 0.8230\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.1681 - mae: 0.8497\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.0142 - mae: 0.7936\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.0901 - mae: 0.8272\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9832 - mae: 0.7779\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0527 - mae: 0.8109\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0736 - mae: 0.8048\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0369 - mae: 0.8155\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0842 - mae: 0.8199\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0540 - mae: 0.8094\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.9822 - mae: 0.7769\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.0371 - mae: 0.8062\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0073 - mae: 0.7831\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 1.0338 - mae: 0.8034\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.9922 - mae: 0.7847\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.0003 - mae: 0.7951\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.9550 - mae: 0.7655\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.9864 - mae: 0.7873\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.9911 - mae: 0.7818\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 1.0224 - mae: 0.7896\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 1.0224 - mae: 0.7938\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.3539325842696629\n",
            "Precision: 0.1921640366212735\n",
            "Recall: 0.2019874702412016\n",
            "F1-Score: 0.17868212877890297\n",
            "Cohen Kappa Score: 0.7305255558338613\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 75.8367 - mae: 8.5753 - mse: 75.8367\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.4438202247191011\n",
            "Precision: 0.19099662497518363\n",
            "Recall: 0.17886963533978456\n",
            "F1-Score: 0.17436902218668104\n",
            "Cohen Kappa Score: 0.598822233836046\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.4803370786516854\n",
            "Precision: 0.48075883530877617\n",
            "Recall: 0.4152462910224104\n",
            "F1-Score: 0.40021712119095837\n",
            "Cohen Kappa Score: 0.7599047195396691\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4606741573033708\n",
            "Precision: 0.18806426674733623\n",
            "Recall: 0.24726368159203985\n",
            "F1-Score: 0.20323887807340107\n",
            "Cohen Kappa Score: 0.6258683373368824\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.43258426966292135\n",
            "Precision: 0.24924412019056189\n",
            "Recall: 0.24149966496642206\n",
            "F1-Score: 0.2384275199404631\n",
            "Cohen Kappa Score: 0.7301538396902199\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3960674157303371\n",
            "Precision: 0.08070449418705536\n",
            "Recall: 0.11166666666666666\n",
            "F1-Score: 0.0748414376321353\n",
            "Cohen Kappa Score: 0.15572956093868273\n",
            "Time taken: 574.01607 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.459   |   0.433   | 0.468  |  0.395   |    0.780    |\n",
            "|           BiLSTM          |  0.476   |   0.415   | 0.456  |  0.398   |    0.798    |\n",
            "|            CNN            |  0.426   |   0.191   | 0.163  |  0.146   |    0.450    |\n",
            "|    Logistic Regression    |  0.492   |   0.236   | 0.193  |  0.185   |    0.677    |\n",
            "|  Random Forest Classifier |  0.532   |   0.481   | 0.422  |  0.427   |    0.786    |\n",
            "|    Adaboost Classifier    |  0.490   |   0.195   | 0.269  |  0.220   |    0.654    |\n",
            "|   K Neighbors Classifier  |  0.471   |   0.398   | 0.304  |  0.321   |    0.755    |\n",
            "| Support Vector Classifier |  0.429   |   0.091   | 0.128  |  0.090   |    0.221    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 2--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_28 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 7s 40ms/step - loss: 2.7390 - mae: 1.2375\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6827 - mae: 0.6730\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6539 - mae: 0.6535\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6312 - mae: 0.6338\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6060 - mae: 0.6262\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6286 - mae: 0.6365\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6171 - mae: 0.6304\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5745 - mae: 0.6129\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5451 - mae: 0.5968\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5947 - mae: 0.6168\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6093 - mae: 0.6274\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5235 - mae: 0.5886\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5700 - mae: 0.6063\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5816 - mae: 0.6007\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5134 - mae: 0.5767\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5314 - mae: 0.5799\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4912 - mae: 0.5584\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5312 - mae: 0.5709\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4765 - mae: 0.5547\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4820 - mae: 0.5443\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4958 - mae: 0.5647\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5104 - mae: 0.5619\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4250 - mae: 0.5204\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4985 - mae: 0.5565\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4087 - mae: 0.5033\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4980 - mae: 0.5614\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4568 - mae: 0.5332\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4560 - mae: 0.5374\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4039 - mae: 0.5078\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4759 - mae: 0.5498\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.3863 - mae: 0.4913\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4351 - mae: 0.5264\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4290 - mae: 0.5297\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4254 - mae: 0.5223\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3821 - mae: 0.4908\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4488 - mae: 0.5325\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3973 - mae: 0.5024\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3702 - mae: 0.4781\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4295 - mae: 0.5146\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4108 - mae: 0.5062\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.3817 - mae: 0.4904\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4239 - mae: 0.5205\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3897 - mae: 0.4989\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3621 - mae: 0.4798\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4061 - mae: 0.5048\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4235 - mae: 0.5175\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3503 - mae: 0.4702\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3984 - mae: 0.4943\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.3672 - mae: 0.4809\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3831 - mae: 0.4942\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6166666666666667\n",
            "Precision: 0.30373304338821583\n",
            "Recall: 0.3116077409914675\n",
            "F1-Score: 0.3056114136759298\n",
            "Cohen Kappa Score: 0.5916824196597353\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_14 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 28ms/step - loss: 1.5408 - mae: 0.9031\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6390 - mae: 0.6481\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6354 - mae: 0.6371\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.6079 - mae: 0.6312\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5816 - mae: 0.6114\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5880 - mae: 0.6158\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.5831 - mae: 0.6120\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5523 - mae: 0.5978\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5331 - mae: 0.5851\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5337 - mae: 0.5809\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4773 - mae: 0.5534\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.5185 - mae: 0.5692\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.4442 - mae: 0.5278\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.4391 - mae: 0.5292\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.4599 - mae: 0.5429\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4500 - mae: 0.5386\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4451 - mae: 0.5398\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4256 - mae: 0.5221\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4172 - mae: 0.5119\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4239 - mae: 0.5150\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4139 - mae: 0.5160\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3983 - mae: 0.5037\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4018 - mae: 0.5095\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3669 - mae: 0.4870\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4128 - mae: 0.5162\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3515 - mae: 0.4738\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.3980 - mae: 0.5039\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3841 - mae: 0.4922\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.3666 - mae: 0.4837\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3849 - mae: 0.4977\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.3703 - mae: 0.4849\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.3542 - mae: 0.4707\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 0.3872 - mae: 0.4932\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.3588 - mae: 0.4767\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3481 - mae: 0.4678\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.3566 - mae: 0.4726\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3588 - mae: 0.4735\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.3684 - mae: 0.4770\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3437 - mae: 0.4625\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3668 - mae: 0.4776\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3273 - mae: 0.4497\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3423 - mae: 0.4593\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3523 - mae: 0.4679\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3393 - mae: 0.4595\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3417 - mae: 0.4585\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3439 - mae: 0.4652\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3399 - mae: 0.4567\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3432 - mae: 0.4639\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3308 - mae: 0.4511\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.3445 - mae: 0.4536\n",
            "12/12 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.6305555555555555\n",
            "Precision: 0.34214133311726896\n",
            "Recall: 0.3243815147989307\n",
            "F1-Score: 0.32563932260752143\n",
            "Cohen Kappa Score: 0.6244766032468962\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_6 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 21ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2799 - mae: 3.4188 - mse: 12.2799\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5777777777777777\n",
            "Precision: 0.20229389231512374\n",
            "Recall: 0.2257527677878852\n",
            "F1-Score: 0.21216941117764468\n",
            "Cohen Kappa Score: 0.42108225456299764\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.7027777777777777\n",
            "Precision: 0.47536650891363913\n",
            "Recall: 0.3992355843331621\n",
            "F1-Score: 0.42448522005859046\n",
            "Cohen Kappa Score: 0.6934145804272813\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.6666666666666666\n",
            "Precision: 0.3173861606064996\n",
            "Recall: 0.321133250475989\n",
            "F1-Score: 0.3182908086372113\n",
            "Cohen Kappa Score: 0.6333182435491173\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5916666666666667\n",
            "Precision: 0.2817204117419325\n",
            "Recall: 0.2714543226852831\n",
            "F1-Score: 0.27332681646658563\n",
            "Cohen Kappa Score: 0.5379388448471121\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4666666666666667\n",
            "Precision: 0.19753086419753085\n",
            "Recall: 0.18967632748043153\n",
            "F1-Score: 0.145439350269471\n",
            "Cohen Kappa Score: 0.14726027397260277\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_32 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_33 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 17ms/step - loss: 2.6556 - mae: 1.2227\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6910 - mae: 0.6634\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6816 - mae: 0.6631\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6711 - mae: 0.6546\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6072 - mae: 0.6320\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6367 - mae: 0.6413\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5955 - mae: 0.6228\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6367 - mae: 0.6441\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5945 - mae: 0.6163\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6033 - mae: 0.6207\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6131 - mae: 0.6239\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5998 - mae: 0.6137\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5481 - mae: 0.6015\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5633 - mae: 0.5952\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.5395 - mae: 0.5850\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.5605 - mae: 0.5949\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5339 - mae: 0.5807\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5452 - mae: 0.5824\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5172 - mae: 0.5712\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5056 - mae: 0.5635\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5000 - mae: 0.5571\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4721 - mae: 0.5413\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5089 - mae: 0.5608\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4649 - mae: 0.5426\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4015 - mae: 0.4978\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4423 - mae: 0.5231\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4433 - mae: 0.5297\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4581 - mae: 0.5352\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4535 - mae: 0.5338\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4052 - mae: 0.5073\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3901 - mae: 0.4948\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4569 - mae: 0.5390\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4457 - mae: 0.5321\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4050 - mae: 0.5068\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3683 - mae: 0.4852\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4305 - mae: 0.5174\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3771 - mae: 0.4827\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4437 - mae: 0.5288\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4083 - mae: 0.5088\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3854 - mae: 0.4929\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3900 - mae: 0.5016\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3687 - mae: 0.4824\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4034 - mae: 0.5074\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3801 - mae: 0.4902\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3856 - mae: 0.4906\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3711 - mae: 0.4855\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4001 - mae: 0.5111\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3576 - mae: 0.4780\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.3714 - mae: 0.4866\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3839 - mae: 0.4892\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6361111111111111\n",
            "Precision: 0.292641923486289\n",
            "Recall: 0.3359956370209564\n",
            "F1-Score: 0.3099126864690867\n",
            "Cohen Kappa Score: 0.6099589889764695\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_16 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 30ms/step - loss: 1.5806 - mae: 0.9186\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.6816 - mae: 0.6618\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6329 - mae: 0.6371\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.6451 - mae: 0.6436\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.6117 - mae: 0.6257\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5914 - mae: 0.6124\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5942 - mae: 0.6160\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5842 - mae: 0.6116\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.5928 - mae: 0.6144\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.5469 - mae: 0.5877\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5423 - mae: 0.5843\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.5274 - mae: 0.5720\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4922 - mae: 0.5543\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4755 - mae: 0.5499\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4549 - mae: 0.5336\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4427 - mae: 0.5268\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4310 - mae: 0.5229\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4390 - mae: 0.5250\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4230 - mae: 0.5122\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3889 - mae: 0.4910\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4153 - mae: 0.5098\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4001 - mae: 0.5086\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3922 - mae: 0.4961\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4127 - mae: 0.5104\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3926 - mae: 0.4962\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3730 - mae: 0.4824\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.3853 - mae: 0.4887\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3927 - mae: 0.4991\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3667 - mae: 0.4768\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3919 - mae: 0.5016\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3589 - mae: 0.4778\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3647 - mae: 0.4849\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3734 - mae: 0.4900\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3552 - mae: 0.4751\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3517 - mae: 0.4706\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3672 - mae: 0.4848\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3564 - mae: 0.4781\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3544 - mae: 0.4741\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3496 - mae: 0.4726\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3527 - mae: 0.4707\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3484 - mae: 0.4715\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3481 - mae: 0.4680\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3539 - mae: 0.4745\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3362 - mae: 0.4597\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.3495 - mae: 0.4723\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.3467 - mae: 0.4675\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3482 - mae: 0.4669\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.3314 - mae: 0.4610\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.3415 - mae: 0.4630\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3341 - mae: 0.4625\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6388888888888888\n",
            "Precision: 0.46840659340659335\n",
            "Recall: 0.3492206480182414\n",
            "F1-Score: 0.3489606700117058\n",
            "Cohen Kappa Score: 0.6042576419213974\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_14 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_7 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 11.8524 - mae: 3.3405 - mse: 11.8524\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2632 - mae: 3.4146 - mse: 12.2632\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6333333333333333\n",
            "Precision: 0.3883830845771145\n",
            "Recall: 0.28513382453122604\n",
            "F1-Score: 0.2958340846531557\n",
            "Cohen Kappa Score: 0.47174188106284265\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6666666666666666\n",
            "Precision: 0.37782039053225497\n",
            "Recall: 0.3698329339396024\n",
            "F1-Score: 0.37179893277454257\n",
            "Cohen Kappa Score: 0.6396997497914929\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.6305555555555555\n",
            "Precision: 0.2998675145733969\n",
            "Recall: 0.319955811347407\n",
            "F1-Score: 0.3088533440375112\n",
            "Cohen Kappa Score: 0.5959183673469388\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.6027777777777777\n",
            "Precision: 0.5782210292484264\n",
            "Recall: 0.3565681054306495\n",
            "F1-Score: 0.3989402678402807\n",
            "Cohen Kappa Score: 0.5304005498968944\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.49166666666666664\n",
            "Precision: 0.1750899506317463\n",
            "Recall: 0.18773576997233632\n",
            "F1-Score: 0.14534215066129957\n",
            "Cohen Kappa Score: 0.22569852428653936\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_36 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 17ms/step - loss: 2.9624 - mae: 1.3024\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6777 - mae: 0.6529\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6835 - mae: 0.6509\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.6600 - mae: 0.6480\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.5910 - mae: 0.6236\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6286 - mae: 0.6358\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6118 - mae: 0.6244\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6281 - mae: 0.6316\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5799 - mae: 0.6116\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5934 - mae: 0.6154\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5943 - mae: 0.6147\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5631 - mae: 0.5978\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5454 - mae: 0.5938\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5509 - mae: 0.5849\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5406 - mae: 0.5834\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5585 - mae: 0.5957\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4859 - mae: 0.5570\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4970 - mae: 0.5611\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4536 - mae: 0.5378\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5171 - mae: 0.5652\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5096 - mae: 0.5637\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4509 - mae: 0.5370\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4308 - mae: 0.5162\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4867 - mae: 0.5571\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4284 - mae: 0.5231\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4598 - mae: 0.5402\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4657 - mae: 0.5459\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4280 - mae: 0.5318\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4419 - mae: 0.5298\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4018 - mae: 0.5056\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4352 - mae: 0.5240\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3774 - mae: 0.4878\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4142 - mae: 0.5137\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4288 - mae: 0.5155\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3629 - mae: 0.4793\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4233 - mae: 0.5148\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4059 - mae: 0.5075\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4436 - mae: 0.5313\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3755 - mae: 0.4890\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3678 - mae: 0.4883\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4198 - mae: 0.5142\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3862 - mae: 0.4944\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4058 - mae: 0.5053\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3939 - mae: 0.5006\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3579 - mae: 0.4782\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3785 - mae: 0.4942\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3941 - mae: 0.5020\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3962 - mae: 0.5082\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3513 - mae: 0.4704\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3835 - mae: 0.4966\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6277777777777778\n",
            "Precision: 0.4024098440545809\n",
            "Recall: 0.3663799968147794\n",
            "F1-Score: 0.37242254108753464\n",
            "Cohen Kappa Score: 0.5773617125083856\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_18 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 19s 84ms/step - loss: 1.5828 - mae: 0.9100\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.7035 - mae: 0.6810\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.6516 - mae: 0.6464\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.6296 - mae: 0.6364\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.6464 - mae: 0.6465\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.6088 - mae: 0.6309\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 0.6266 - mae: 0.6347\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 0.5917 - mae: 0.6229\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5679 - mae: 0.6059\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5792 - mae: 0.6092\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5614 - mae: 0.5931\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5179 - mae: 0.5761\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5009 - mae: 0.5598\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4784 - mae: 0.5524\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5056 - mae: 0.5672\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4644 - mae: 0.5414\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4379 - mae: 0.5269\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4293 - mae: 0.5224\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4310 - mae: 0.5225\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4164 - mae: 0.5093\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4304 - mae: 0.5234\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3865 - mae: 0.4935\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3750 - mae: 0.4926\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.3972 - mae: 0.5043\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3943 - mae: 0.4963\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3871 - mae: 0.4949\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.3831 - mae: 0.4992\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3873 - mae: 0.4908\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3796 - mae: 0.4901\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3806 - mae: 0.4947\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3543 - mae: 0.4768\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3847 - mae: 0.4903\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3551 - mae: 0.4756\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3713 - mae: 0.4855\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3610 - mae: 0.4645\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3690 - mae: 0.4841\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3628 - mae: 0.4807\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3513 - mae: 0.4736\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3679 - mae: 0.4799\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3485 - mae: 0.4725\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3603 - mae: 0.4753\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.3510 - mae: 0.4694\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3598 - mae: 0.4766\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.3444 - mae: 0.4660\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.3239 - mae: 0.4600\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3375 - mae: 0.4595\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3464 - mae: 0.4588\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3264 - mae: 0.4516\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3374 - mae: 0.4639\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3346 - mae: 0.4533\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6888888888888889\n",
            "Precision: 0.4189829258265012\n",
            "Recall: 0.37742873068960026\n",
            "F1-Score: 0.39312748499414535\n",
            "Cohen Kappa Score: 0.6194565538037956\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_8 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 17ms/step - loss: 30.1348 - mae: 4.2494 - mse: 30.1348\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2597 - mae: 3.4125 - mse: 12.2597\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6138888888888889\n",
            "Precision: 0.20835329309445494\n",
            "Recall: 0.23232866167648777\n",
            "F1-Score: 0.2196082612223624\n",
            "Cohen Kappa Score: 0.3660547021356313\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6722222222222223\n",
            "Precision: 0.34988385598141697\n",
            "Recall: 0.34016828582045977\n",
            "F1-Score: 0.3434813962104372\n",
            "Cohen Kappa Score: 0.5906747970218644\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.7055555555555556\n",
            "Precision: 0.3697967700961713\n",
            "Recall: 0.3635730211817168\n",
            "F1-Score: 0.36558190616046066\n",
            "Cohen Kappa Score: 0.6013155245318478\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.6222222222222222\n",
            "Precision: 0.371298616912652\n",
            "Recall: 0.3491798057015449\n",
            "F1-Score: 0.3559957873335782\n",
            "Cohen Kappa Score: 0.5551161641127039\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.48333333333333334\n",
            "Precision: 0.19635685599541022\n",
            "Recall: 0.18523384827732656\n",
            "F1-Score: 0.140464625437303\n",
            "Cohen Kappa Score: 0.1592324524490828\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_40 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 17ms/step - loss: 2.6281 - mae: 1.2006\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6929 - mae: 0.6724\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5894 - mae: 0.6218\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6490 - mae: 0.6458\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6158 - mae: 0.6287\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6028 - mae: 0.6236\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5943 - mae: 0.6193\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6014 - mae: 0.6241\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5813 - mae: 0.6165\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6063 - mae: 0.6209\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5495 - mae: 0.5982\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5488 - mae: 0.5936\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5486 - mae: 0.5919\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5813 - mae: 0.6055\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5235 - mae: 0.5758\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4956 - mae: 0.5587\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4972 - mae: 0.5615\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5331 - mae: 0.5747\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4876 - mae: 0.5553\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4761 - mae: 0.5440\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4807 - mae: 0.5535\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4342 - mae: 0.5255\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5069 - mae: 0.5636\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4445 - mae: 0.5302\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4488 - mae: 0.5371\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4360 - mae: 0.5204\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4073 - mae: 0.5116\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4494 - mae: 0.5379\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4356 - mae: 0.5189\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4111 - mae: 0.5140\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4131 - mae: 0.5109\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4503 - mae: 0.5335\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4004 - mae: 0.4999\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4148 - mae: 0.5119\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4070 - mae: 0.5085\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4022 - mae: 0.5019\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3956 - mae: 0.4926\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4357 - mae: 0.5268\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3629 - mae: 0.4830\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4026 - mae: 0.5060\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3980 - mae: 0.5032\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3898 - mae: 0.4971\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3862 - mae: 0.4942\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3808 - mae: 0.4931\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.3779 - mae: 0.4915\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3884 - mae: 0.4979\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.3931 - mae: 0.4973\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.3921 - mae: 0.4953\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3614 - mae: 0.4794\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.3563 - mae: 0.4751\n",
            "12/12 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5611111111111111\n",
            "Precision: 0.28097069597069596\n",
            "Recall: 0.32454417349761994\n",
            "F1-Score: 0.2886808156471078\n",
            "Cohen Kappa Score: 0.5980453972257251\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_20 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_21 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 12s 50ms/step - loss: 1.4709 - mae: 0.8818\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.6306 - mae: 0.6309\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 0.6113 - mae: 0.6271\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.5952 - mae: 0.6161\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.5869 - mae: 0.6122\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5737 - mae: 0.6035\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5344 - mae: 0.5884\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5882 - mae: 0.6126\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5154 - mae: 0.5725\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5201 - mae: 0.5678\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4910 - mae: 0.5514\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4730 - mae: 0.5456\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4867 - mae: 0.5554\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4282 - mae: 0.5220\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4632 - mae: 0.5338\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4289 - mae: 0.5215\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.4221 - mae: 0.5172\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4189 - mae: 0.5063\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4028 - mae: 0.4996\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.4185 - mae: 0.5120\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3942 - mae: 0.4978\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3924 - mae: 0.5000\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.3883 - mae: 0.4997\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4063 - mae: 0.5048\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3676 - mae: 0.4772\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3835 - mae: 0.4885\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3754 - mae: 0.4871\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3673 - mae: 0.4805\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3661 - mae: 0.4819\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3471 - mae: 0.4682\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3598 - mae: 0.4798\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3783 - mae: 0.4871\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3793 - mae: 0.4879\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3599 - mae: 0.4793\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3622 - mae: 0.4826\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3400 - mae: 0.4645\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3695 - mae: 0.4843\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.3609 - mae: 0.4819\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3339 - mae: 0.4578\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3582 - mae: 0.4750\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3508 - mae: 0.4687\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3230 - mae: 0.4517\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3573 - mae: 0.4709\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3409 - mae: 0.4673\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3465 - mae: 0.4670\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3384 - mae: 0.4601\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3279 - mae: 0.4566\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3306 - mae: 0.4579\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3392 - mae: 0.4633\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3304 - mae: 0.4576\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6194444444444445\n",
            "Precision: 0.37314352314352317\n",
            "Recall: 0.34079239057586225\n",
            "F1-Score: 0.3477274054051185\n",
            "Cohen Kappa Score: 0.6328626444159178\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 384, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_9 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 30.5094 - mae: 4.3177 - mse: 30.5094\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2292 - mae: 3.4125 - mse: 12.2292\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6055555555555555\n",
            "Precision: 0.32894152310395963\n",
            "Recall: 0.29528921998247154\n",
            "F1-Score: 0.2988128897848668\n",
            "Cohen Kappa Score: 0.4835007173601148\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6472222222222223\n",
            "Precision: 0.4096683893195521\n",
            "Recall: 0.34369819502443105\n",
            "F1-Score: 0.35931012328174156\n",
            "Cohen Kappa Score: 0.6465696465696466\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.625\n",
            "Precision: 0.29808017680107274\n",
            "Recall: 0.3047155058342355\n",
            "F1-Score: 0.2999542420901644\n",
            "Cohen Kappa Score: 0.5829082747967006\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.575\n",
            "Precision: 0.28092072207866786\n",
            "Recall: 0.28108728153838225\n",
            "F1-Score: 0.2789517280330862\n",
            "Cohen Kappa Score: 0.52832674571805\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42777777777777776\n",
            "Precision: 0.16566983691211556\n",
            "Recall: 0.180309669880222\n",
            "F1-Score: 0.12758739439767292\n",
            "Cohen Kappa Score: 0.15390988005618988\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_44 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_45 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 15ms/step - loss: 2.9190 - mae: 1.2690\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7061 - mae: 0.6793\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7190 - mae: 0.6754\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6035 - mae: 0.6298\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6473 - mae: 0.6422\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5856 - mae: 0.6173\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6162 - mae: 0.6286\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6086 - mae: 0.6262\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5881 - mae: 0.6193\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6020 - mae: 0.6142\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5705 - mae: 0.6064\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5636 - mae: 0.5998\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5634 - mae: 0.5997\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5481 - mae: 0.5866\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5363 - mae: 0.5764\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5270 - mae: 0.5734\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5231 - mae: 0.5711\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5016 - mae: 0.5631\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5185 - mae: 0.5689\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4550 - mae: 0.5339\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4790 - mae: 0.5482\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4483 - mae: 0.5350\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5069 - mae: 0.5709\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4148 - mae: 0.5157\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4782 - mae: 0.5490\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4477 - mae: 0.5366\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4418 - mae: 0.5227\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4451 - mae: 0.5300\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4486 - mae: 0.5321\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4001 - mae: 0.5068\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4196 - mae: 0.5167\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4247 - mae: 0.5247\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3955 - mae: 0.4981\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4236 - mae: 0.5235\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4114 - mae: 0.5101\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.3684 - mae: 0.4853\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.4146 - mae: 0.5136\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3920 - mae: 0.5016\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4050 - mae: 0.5115\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3895 - mae: 0.5033\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.3963 - mae: 0.5076\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.3576 - mae: 0.4783\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.4035 - mae: 0.5081\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3537 - mae: 0.4754\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 0.3959 - mae: 0.5039\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.3507 - mae: 0.4781\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.3816 - mae: 0.4960\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.3868 - mae: 0.5024\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3744 - mae: 0.4923\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3589 - mae: 0.4802\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5916666666666667\n",
            "Precision: 0.4462387139001713\n",
            "Recall: 0.40378774680603946\n",
            "F1-Score: 0.40413613835649675\n",
            "Cohen Kappa Score: 0.5871559633027523\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_22 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_23 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 67ms/step - loss: 1.5218 - mae: 0.8991\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.6632 - mae: 0.6452\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.6462 - mae: 0.6429\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6404 - mae: 0.6393\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.6157 - mae: 0.6276\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.6185 - mae: 0.6271\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6116 - mae: 0.6302\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5990 - mae: 0.6244\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5739 - mae: 0.6059\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5571 - mae: 0.5988\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5425 - mae: 0.5901\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5233 - mae: 0.5723\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5003 - mae: 0.5649\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4767 - mae: 0.5473\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4356 - mae: 0.5260\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4542 - mae: 0.5356\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4457 - mae: 0.5252\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4375 - mae: 0.5255\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4250 - mae: 0.5169\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.4173 - mae: 0.5146\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.4321 - mae: 0.5224\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3925 - mae: 0.5024\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4072 - mae: 0.5056\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4098 - mae: 0.5128\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3869 - mae: 0.4980\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3975 - mae: 0.5019\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3860 - mae: 0.5006\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3927 - mae: 0.5002\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3539 - mae: 0.4754\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3627 - mae: 0.4756\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3709 - mae: 0.4869\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.3680 - mae: 0.4834\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3674 - mae: 0.4847\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3529 - mae: 0.4764\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3484 - mae: 0.4745\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3493 - mae: 0.4639\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.3474 - mae: 0.4694\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3646 - mae: 0.4843\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.3458 - mae: 0.4700\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3442 - mae: 0.4727\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3404 - mae: 0.4706\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3546 - mae: 0.4734\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3526 - mae: 0.4752\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3436 - mae: 0.4695\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3444 - mae: 0.4705\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3160 - mae: 0.4492\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3337 - mae: 0.4599\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3242 - mae: 0.4582\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3414 - mae: 0.4714\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3304 - mae: 0.4591\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.5527777777777778\n",
            "Precision: 0.45613712983500887\n",
            "Recall: 0.3796878629500581\n",
            "F1-Score: 0.3811061170570889\n",
            "Cohen Kappa Score: 0.5328542094455851\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_10 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 24.7795 - mae: 4.1452 - mse: 24.7795\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 12.2958 - mae: 3.4194 - mse: 12.2958\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6138888888888889\n",
            "Precision: 0.2984743305833802\n",
            "Recall: 0.2581312911343399\n",
            "F1-Score: 0.25531400696438605\n",
            "Cohen Kappa Score: 0.43830570902394106\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6694444444444444\n",
            "Precision: 0.5909099312852433\n",
            "Recall: 0.4527729384436701\n",
            "F1-Score: 0.4843597262952102\n",
            "Cohen Kappa Score: 0.6074498567335244\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.6527777777777778\n",
            "Precision: 0.3870992444353686\n",
            "Recall: 0.35884146341463413\n",
            "F1-Score: 0.36135069863722613\n",
            "Cohen Kappa Score: 0.564958283671037\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5972222222222222\n",
            "Precision: 0.6408809020436927\n",
            "Recall: 0.4067392566782811\n",
            "F1-Score: 0.4286294852688295\n",
            "Cohen Kappa Score: 0.48374215630347983\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5083333333333333\n",
            "Precision: 0.23396411412883616\n",
            "Recall: 0.22756097560975608\n",
            "F1-Score: 0.18056296928934915\n",
            "Cohen Kappa Score: 0.1794310722100656\n",
            "Time taken: 672.69677 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.636   |   0.446   | 0.404  |  0.404   |    0.610    |\n",
            "|           BiLSTM          |  0.689   |   0.468   | 0.380  |  0.393   |    0.633    |\n",
            "|            CNN            |  0.000   |   0.000   | 0.000  |  0.000   |    0.000    |\n",
            "|    Logistic Regression    |  0.633   |   0.388   | 0.295  |  0.299   |    0.484    |\n",
            "|  Random Forest Classifier |  0.703   |   0.591   | 0.453  |  0.484   |    0.693    |\n",
            "|    Adaboost Classifier    |  0.706   |   0.387   | 0.364  |  0.366   |    0.633    |\n",
            "|   K Neighbors Classifier  |  0.622   |   0.641   | 0.407  |  0.429   |    0.555    |\n",
            "| Support Vector Classifier |  0.508   |   0.234   | 0.228  |  0.181   |    0.226    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 3--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_48 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_49 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11/11 [==============================] - 6s 19ms/step - loss: 1.1628 - mae: 0.8634\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.7311 - mae: 0.7231\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.7051 - mae: 0.7048\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.6935 - mae: 0.7023\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.7124 - mae: 0.7058\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6952 - mae: 0.7022\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6893 - mae: 0.6949\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.7010 - mae: 0.7057\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6723 - mae: 0.6893\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6884 - mae: 0.6976\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6473 - mae: 0.6786\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.6576 - mae: 0.6746\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6595 - mae: 0.6845\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.5837 - mae: 0.6438\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5947 - mae: 0.6423\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5860 - mae: 0.6302\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5763 - mae: 0.6402\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.5165 - mae: 0.5991\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5488 - mae: 0.6108\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.5046 - mae: 0.5913\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4772 - mae: 0.5659\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.5041 - mae: 0.5804\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4589 - mae: 0.5503\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4751 - mae: 0.5590\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4471 - mae: 0.5373\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4780 - mae: 0.5634\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4237 - mae: 0.5257\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4534 - mae: 0.5402\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4201 - mae: 0.5179\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4445 - mae: 0.5347\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4498 - mae: 0.5406\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4329 - mae: 0.5213\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.3858 - mae: 0.4969\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.4269 - mae: 0.5275\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.3907 - mae: 0.5015\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4460 - mae: 0.5308\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.3865 - mae: 0.4954\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.4477 - mae: 0.5258\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.3970 - mae: 0.4995\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.4167 - mae: 0.5099\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.4227 - mae: 0.5237\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.3946 - mae: 0.5067\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.4333 - mae: 0.5254\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.4111 - mae: 0.5139\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.4321 - mae: 0.5264\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.3846 - mae: 0.4937\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3791 - mae: 0.4905\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4142 - mae: 0.5138\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4107 - mae: 0.5080\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3736 - mae: 0.4934\n",
            "11/11 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5895953757225434\n",
            "Precision: 0.5197811292851379\n",
            "Recall: 0.4354244025296657\n",
            "F1-Score: 0.4280932300349776\n",
            "Cohen Kappa Score: 0.6122779653830428\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_24 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_25 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 12s 63ms/step - loss: 0.9421 - mae: 0.7889\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 1s 53ms/step - loss: 0.7363 - mae: 0.7254\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.7232 - mae: 0.7163\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7152 - mae: 0.7098\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7077 - mae: 0.7094\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6925 - mae: 0.6982\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7056 - mae: 0.7064\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6732 - mae: 0.6946\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.6420 - mae: 0.6727\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6548 - mae: 0.6797\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5821 - mae: 0.6389\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5299 - mae: 0.6024\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5191 - mae: 0.5863\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5225 - mae: 0.5879\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.4548 - mae: 0.5465\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.4648 - mae: 0.5455\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 0.4738 - mae: 0.5554\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 0.4317 - mae: 0.5239\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.4362 - mae: 0.5285\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4544 - mae: 0.5384\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.4207 - mae: 0.5150\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4294 - mae: 0.5250\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4248 - mae: 0.5203\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4011 - mae: 0.5084\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4134 - mae: 0.5089\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.4135 - mae: 0.5144\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4249 - mae: 0.5167\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3952 - mae: 0.5033\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3998 - mae: 0.5033\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4109 - mae: 0.5116\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3968 - mae: 0.5056\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3957 - mae: 0.5009\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3953 - mae: 0.5017\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3892 - mae: 0.4934\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 1s 39ms/step - loss: 0.3820 - mae: 0.4877\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3990 - mae: 0.5031\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.3827 - mae: 0.4892\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.3893 - mae: 0.4967\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 1s 56ms/step - loss: 0.3895 - mae: 0.4914\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3854 - mae: 0.4993\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3964 - mae: 0.4967\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3927 - mae: 0.4950\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3764 - mae: 0.4911\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3879 - mae: 0.4928\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3885 - mae: 0.4906\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3933 - mae: 0.4936\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3736 - mae: 0.4861\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3669 - mae: 0.4858\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3754 - mae: 0.4828\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3925 - mae: 0.4994\n",
            "11/11 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.653179190751445\n",
            "Precision: 0.49230834439038773\n",
            "Recall: 0.499892236734342\n",
            "F1-Score: 0.4959624651758151\n",
            "Cohen Kappa Score: 0.6925222166028466\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_11 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 2s 32ms/step - loss: 5.4509 - mae: 2.0650 - mse: 5.4509\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0891 - mae: 1.8471 - mse: 4.0891\n",
            "11/11 [==============================] - 0s 7ms/step\n",
            "Accuracy: 0.02023121387283237\n",
            "Precision: 0.0050578034682080926\n",
            "Recall: 0.25\n",
            "F1-Score: 0.009915014164305949\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6445086705202312\n",
            "Precision: 0.48388285020717603\n",
            "Recall: 0.49894738381580483\n",
            "F1-Score: 0.4906493174231533\n",
            "Cohen Kappa Score: 0.6792651582185143\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6560693641618497\n",
            "Precision: 0.4914437606028327\n",
            "Recall: 0.5067579113631746\n",
            "F1-Score: 0.4986447456835653\n",
            "Cohen Kappa Score: 0.6916349862834384\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5520231213872833\n",
            "Precision: 0.4248713108219922\n",
            "Recall: 0.4604227860806808\n",
            "F1-Score: 0.4128613322161709\n",
            "Cohen Kappa Score: 0.5868872222286622\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5289017341040463\n",
            "Precision: 0.46024339868390163\n",
            "Recall: 0.4406224406224406\n",
            "F1-Score: 0.44529902977480523\n",
            "Cohen Kappa Score: 0.5288426008293531\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4277456647398844\n",
            "Precision: 0.1069364161849711\n",
            "Recall: 0.25\n",
            "F1-Score: 0.14979757085020245\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_52 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_53 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11/11 [==============================] - 6s 41ms/step - loss: 1.1840 - mae: 0.8683\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.7330 - mae: 0.7194\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.7108 - mae: 0.7040\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.7085 - mae: 0.7043\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6989 - mae: 0.6980\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.7075 - mae: 0.7064\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.6677 - mae: 0.6804\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.6732 - mae: 0.6820\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6658 - mae: 0.6843\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6716 - mae: 0.6842\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.6687 - mae: 0.6805\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6491 - mae: 0.6761\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6198 - mae: 0.6563\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6194 - mae: 0.6588\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.6386 - mae: 0.6725\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.5911 - mae: 0.6393\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.5858 - mae: 0.6419\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.5208 - mae: 0.6087\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.5815 - mae: 0.6337\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4954 - mae: 0.5830\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4849 - mae: 0.5693\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5219 - mae: 0.5935\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4714 - mae: 0.5624\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4845 - mae: 0.5654\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4569 - mae: 0.5520\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4890 - mae: 0.5609\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4506 - mae: 0.5440\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4233 - mae: 0.5269\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4467 - mae: 0.5418\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4215 - mae: 0.5216\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4596 - mae: 0.5485\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4310 - mae: 0.5198\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4081 - mae: 0.5134\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4206 - mae: 0.5220\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4545 - mae: 0.5481\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4037 - mae: 0.5117\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3939 - mae: 0.5016\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4399 - mae: 0.5298\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3839 - mae: 0.4934\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4025 - mae: 0.5065\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3878 - mae: 0.4957\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4122 - mae: 0.5134\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4097 - mae: 0.5026\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3850 - mae: 0.4918\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.3902 - mae: 0.4965\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.3722 - mae: 0.4888\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4121 - mae: 0.5142\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.3771 - mae: 0.4890\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3781 - mae: 0.4890\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4220 - mae: 0.5134\n",
            "11/11 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5130434782608696\n",
            "Precision: 0.4156742915968733\n",
            "Recall: 0.4160068926974665\n",
            "F1-Score: 0.3543978447648173\n",
            "Cohen Kappa Score: 0.4790268456375839\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_26 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_27 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 13s 29ms/step - loss: 0.9275 - mae: 0.7846\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6927 - mae: 0.6961\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.7161 - mae: 0.7074\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.6991 - mae: 0.7000\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.7098 - mae: 0.7038\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6880 - mae: 0.6978\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6639 - mae: 0.6790\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6537 - mae: 0.6759\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6540 - mae: 0.6770\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.5983 - mae: 0.6459\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.5663 - mae: 0.6292\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5018 - mae: 0.5832\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.5146 - mae: 0.5882\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 0.4673 - mae: 0.5509\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4729 - mae: 0.5601\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4680 - mae: 0.5521\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4315 - mae: 0.5289\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4085 - mae: 0.5103\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4312 - mae: 0.5234\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.3905 - mae: 0.5033\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.4034 - mae: 0.5111\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3771 - mae: 0.4969\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.4025 - mae: 0.5069\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3879 - mae: 0.4964\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4010 - mae: 0.4992\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3875 - mae: 0.5034\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3927 - mae: 0.5010\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3866 - mae: 0.4967\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3802 - mae: 0.4940\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3843 - mae: 0.4947\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3975 - mae: 0.5093\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3991 - mae: 0.5066\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.3922 - mae: 0.5028\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.3891 - mae: 0.5090\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.3719 - mae: 0.4899\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.3884 - mae: 0.5025\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3921 - mae: 0.5009\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3628 - mae: 0.4833\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3792 - mae: 0.4951\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3785 - mae: 0.4842\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3818 - mae: 0.4936\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3795 - mae: 0.4878\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3604 - mae: 0.4743\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3923 - mae: 0.4996\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3765 - mae: 0.4874\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3535 - mae: 0.4737\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3763 - mae: 0.4882\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3720 - mae: 0.4899\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3576 - mae: 0.4783\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3708 - mae: 0.4849\n",
            "11/11 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.6347826086956522\n",
            "Precision: 0.4783467441030467\n",
            "Recall: 0.5062494178464978\n",
            "F1-Score: 0.480909155032745\n",
            "Cohen Kappa Score: 0.6524083075563412\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_12 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 2s 29ms/step - loss: 7.7846 - mae: 2.2903 - mse: 7.7846\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0666 - mae: 1.8450 - mse: 4.0666\n",
            "11/11 [==============================] - 0s 7ms/step\n",
            "Accuracy: 0.020289855072463767\n",
            "Precision: 0.005072463768115942\n",
            "Recall: 0.25\n",
            "F1-Score: 0.009943181818181818\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6550724637681159\n",
            "Precision: 0.49398943927583605\n",
            "Recall: 0.5098442157228018\n",
            "F1-Score: 0.5014574145008928\n",
            "Cohen Kappa Score: 0.6761063312627802\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6579710144927536\n",
            "Precision: 0.5018197181461089\n",
            "Recall: 0.5099257172131147\n",
            "F1-Score: 0.5058284330681426\n",
            "Cohen Kappa Score: 0.6936816953268832\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.591304347826087\n",
            "Precision: 0.4431633545806774\n",
            "Recall: 0.4702344914307005\n",
            "F1-Score: 0.447561832686142\n",
            "Cohen Kappa Score: 0.6161642638706859\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5507246376811594\n",
            "Precision: 0.42214907881657016\n",
            "Recall: 0.4186324049925484\n",
            "F1-Score: 0.4189359867428263\n",
            "Cohen Kappa Score: 0.5689043788373083\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3710144927536232\n",
            "Precision: 0.0927536231884058\n",
            "Recall: 0.25\n",
            "F1-Score: 0.13530655391120508\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_56 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_57 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11/11 [==============================] - 6s 18ms/step - loss: 1.1354 - mae: 0.8544\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.7225 - mae: 0.7114\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.6942 - mae: 0.6953\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6845 - mae: 0.6903\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6939 - mae: 0.6965\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.7063 - mae: 0.6977\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6798 - mae: 0.6848\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6947 - mae: 0.6978\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6725 - mae: 0.6807\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6729 - mae: 0.6825\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6466 - mae: 0.6686\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6152 - mae: 0.6494\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.6536 - mae: 0.6746\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.6167 - mae: 0.6572\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5544 - mae: 0.6281\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.5904 - mae: 0.6426\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.5619 - mae: 0.6256\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.5168 - mae: 0.6026\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.5459 - mae: 0.6101\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4706 - mae: 0.5623\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4653 - mae: 0.5570\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4533 - mae: 0.5506\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4274 - mae: 0.5302\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4630 - mae: 0.5535\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4392 - mae: 0.5287\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4716 - mae: 0.5610\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4062 - mae: 0.5208\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3961 - mae: 0.5103\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4448 - mae: 0.5366\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4119 - mae: 0.5196\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3950 - mae: 0.5072\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4590 - mae: 0.5462\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3767 - mae: 0.4935\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4125 - mae: 0.5219\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4043 - mae: 0.5106\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3724 - mae: 0.4918\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3978 - mae: 0.5031\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3838 - mae: 0.4926\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3807 - mae: 0.4940\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3915 - mae: 0.4996\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.3750 - mae: 0.4931\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3908 - mae: 0.4945\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3953 - mae: 0.4975\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.3568 - mae: 0.4805\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.4132 - mae: 0.5183\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3622 - mae: 0.4842\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3882 - mae: 0.4972\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.3644 - mae: 0.4910\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3783 - mae: 0.4875\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.4067 - mae: 0.5174\n",
            "11/11 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6260869565217392\n",
            "Precision: 0.47279345091845093\n",
            "Recall: 0.48654878618113906\n",
            "F1-Score: 0.47595430884904566\n",
            "Cohen Kappa Score: 0.5953641620848389\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_28 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_29 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 13s 32ms/step - loss: 0.9204 - mae: 0.7826\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7143 - mae: 0.7111\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7160 - mae: 0.7082\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6870 - mae: 0.6893\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6675 - mae: 0.6786\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6935 - mae: 0.6974\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6783 - mae: 0.6914\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 1s 54ms/step - loss: 0.6710 - mae: 0.6840\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.6513 - mae: 0.6727\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.5925 - mae: 0.6456\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.5718 - mae: 0.6299\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5430 - mae: 0.6110\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4996 - mae: 0.5815\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.4732 - mae: 0.5649\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.4550 - mae: 0.5510\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4553 - mae: 0.5456\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4327 - mae: 0.5306\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4435 - mae: 0.5332\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3923 - mae: 0.5038\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4207 - mae: 0.5266\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3957 - mae: 0.4995\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3914 - mae: 0.4994\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3900 - mae: 0.4968\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.3901 - mae: 0.5043\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3993 - mae: 0.5012\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4083 - mae: 0.5091\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.3726 - mae: 0.4856\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.3683 - mae: 0.4797\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.3740 - mae: 0.4933\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3838 - mae: 0.4999\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3972 - mae: 0.5063\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3625 - mae: 0.4778\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3722 - mae: 0.4882\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3673 - mae: 0.4816\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3807 - mae: 0.4942\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3617 - mae: 0.4769\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3708 - mae: 0.4858\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3617 - mae: 0.4760\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3703 - mae: 0.4830\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3576 - mae: 0.4766\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3595 - mae: 0.4757\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3397 - mae: 0.4636\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3604 - mae: 0.4763\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 1s 41ms/step - loss: 0.3533 - mae: 0.4726\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.3532 - mae: 0.4694\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3529 - mae: 0.4750\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.3509 - mae: 0.4696\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 1s 54ms/step - loss: 0.3503 - mae: 0.4729\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3548 - mae: 0.4729\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3654 - mae: 0.4857\n",
            "11/11 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6173913043478261\n",
            "Precision: 0.4687703414403219\n",
            "Recall: 0.4479458450046685\n",
            "F1-Score: 0.4466485456655434\n",
            "Cohen Kappa Score: 0.5762589408279749\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_13 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 16ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.1665 - mae: 1.8726 - mse: 4.1665\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.03188405797101449\n",
            "Precision: 0.007971014492753623\n",
            "Recall: 0.25\n",
            "F1-Score: 0.01544943820224719\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6144927536231884\n",
            "Precision: 0.45715558950853064\n",
            "Recall: 0.47388538748832865\n",
            "F1-Score: 0.4652736972735091\n",
            "Cohen Kappa Score: 0.5936503922755977\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6260869565217392\n",
            "Precision: 0.7117790478782519\n",
            "Recall: 0.49468688990747817\n",
            "F1-Score: 0.5082208689219759\n",
            "Cohen Kappa Score: 0.5898350423539902\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5420289855072464\n",
            "Precision: 0.46413794012228543\n",
            "Recall: 0.47265724471606824\n",
            "F1-Score: 0.4418186604931166\n",
            "Cohen Kappa Score: 0.545587044534413\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5826086956521739\n",
            "Precision: 0.4294905782162828\n",
            "Recall: 0.4333274976657329\n",
            "F1-Score: 0.429966981331409\n",
            "Cohen Kappa Score: 0.5338765096804724\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3652173913043478\n",
            "Precision: 0.09130434782608696\n",
            "Recall: 0.25\n",
            "F1-Score: 0.1337579617834395\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_60 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_61 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11/11 [==============================] - 5s 18ms/step - loss: 1.0890 - mae: 0.8344\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.7228 - mae: 0.7138\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.7112 - mae: 0.7017\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6702 - mae: 0.6822\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.7304 - mae: 0.7043\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6819 - mae: 0.6845\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.6799 - mae: 0.6967\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.6834 - mae: 0.6908\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6658 - mae: 0.6805\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6940 - mae: 0.6930\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6334 - mae: 0.6627\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.6422 - mae: 0.6671\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6467 - mae: 0.6684\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6126 - mae: 0.6512\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6065 - mae: 0.6540\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5504 - mae: 0.6177\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5490 - mae: 0.6201\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5241 - mae: 0.6021\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.5123 - mae: 0.5920\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4934 - mae: 0.5757\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4393 - mae: 0.5512\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4664 - mae: 0.5470\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4441 - mae: 0.5424\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4651 - mae: 0.5488\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4412 - mae: 0.5338\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4461 - mae: 0.5360\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4402 - mae: 0.5325\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4500 - mae: 0.5385\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3995 - mae: 0.5081\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4400 - mae: 0.5277\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4031 - mae: 0.5101\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4386 - mae: 0.5366\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4294 - mae: 0.5253\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3877 - mae: 0.5044\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4343 - mae: 0.5214\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4113 - mae: 0.5148\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4195 - mae: 0.5232\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4168 - mae: 0.5159\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3774 - mae: 0.4945\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3990 - mae: 0.5071\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4300 - mae: 0.5172\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3726 - mae: 0.4925\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4208 - mae: 0.5161\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3721 - mae: 0.4902\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4264 - mae: 0.5132\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3957 - mae: 0.5051\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4158 - mae: 0.5128\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3956 - mae: 0.5048\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3680 - mae: 0.4917\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3920 - mae: 0.5015\n",
            "11/11 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6608695652173913\n",
            "Precision: 0.5214961961115807\n",
            "Recall: 0.4873167871799883\n",
            "F1-Score: 0.48968786619793325\n",
            "Cohen Kappa Score: 0.6897157557884168\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_30 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_31 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 10s 64ms/step - loss: 0.9136 - mae: 0.7767\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.7304 - mae: 0.7129\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.7165 - mae: 0.7057\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.6871 - mae: 0.6875\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6856 - mae: 0.6870\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.7109 - mae: 0.7042\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.6808 - mae: 0.6884\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6832 - mae: 0.6853\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6569 - mae: 0.6718\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6531 - mae: 0.6746\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6445 - mae: 0.6694\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5751 - mae: 0.6327\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5224 - mae: 0.6023\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4739 - mae: 0.5666\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5167 - mae: 0.5796\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4458 - mae: 0.5390\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.4458 - mae: 0.5394\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4510 - mae: 0.5411\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 1s 38ms/step - loss: 0.4189 - mae: 0.5186\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.4354 - mae: 0.5306\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4464 - mae: 0.5396\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4370 - mae: 0.5310\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.3886 - mae: 0.4979\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4080 - mae: 0.5131\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4157 - mae: 0.5198\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3932 - mae: 0.5032\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4157 - mae: 0.5140\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4017 - mae: 0.5064\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3969 - mae: 0.5039\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4008 - mae: 0.5029\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3873 - mae: 0.4941\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.4042 - mae: 0.5072\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3764 - mae: 0.4865\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3784 - mae: 0.4872\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3838 - mae: 0.4913\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3893 - mae: 0.4939\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3722 - mae: 0.4818\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 1s 56ms/step - loss: 0.3997 - mae: 0.5024\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.3842 - mae: 0.4936\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.3950 - mae: 0.5069\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 1s 58ms/step - loss: 0.3845 - mae: 0.4891\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 1s 53ms/step - loss: 0.3777 - mae: 0.4849\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3806 - mae: 0.4849\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3734 - mae: 0.4844\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3779 - mae: 0.4902\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3784 - mae: 0.4845\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3718 - mae: 0.4848\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3737 - mae: 0.4877\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3793 - mae: 0.4884\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3700 - mae: 0.4850\n",
            "11/11 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.672463768115942\n",
            "Precision: 0.5198625099039123\n",
            "Recall: 0.5066917464660283\n",
            "F1-Score: 0.5043065955031831\n",
            "Cohen Kappa Score: 0.6979023720839052\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_14 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 15ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.0869 - mae: 1.8494 - mse: 4.0869\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.014492753623188406\n",
            "Precision: 0.0036231884057971015\n",
            "Recall: 0.25\n",
            "F1-Score: 0.007142857142857143\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.672463768115942\n",
            "Precision: 0.5115514242226571\n",
            "Recall: 0.508202505808525\n",
            "F1-Score: 0.5081487570095166\n",
            "Cohen Kappa Score: 0.7094022277477915\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6608695652173913\n",
            "Precision: 0.6247252747252747\n",
            "Recall: 0.5496080602783748\n",
            "F1-Score: 0.5708607510492052\n",
            "Cohen Kappa Score: 0.6774610625982138\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5768115942028985\n",
            "Precision: 0.6849177475482442\n",
            "Recall: 0.5080271643541138\n",
            "F1-Score: 0.5141898063573255\n",
            "Cohen Kappa Score: 0.6140405508269324\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5884057971014492\n",
            "Precision: 0.46639306736429037\n",
            "Recall: 0.43366664495255464\n",
            "F1-Score: 0.4384838001545782\n",
            "Cohen Kappa Score: 0.597274376608582\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3652173913043478\n",
            "Precision: 0.09130434782608696\n",
            "Recall: 0.25\n",
            "F1-Score: 0.1337579617834395\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_64 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11/11 [==============================] - 11s 18ms/step - loss: 1.1949 - mae: 0.8722\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.6959 - mae: 0.6999\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6919 - mae: 0.6962\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6901 - mae: 0.6988\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6832 - mae: 0.6906\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6812 - mae: 0.6917\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6809 - mae: 0.6910\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6872 - mae: 0.6969\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.6484 - mae: 0.6750\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6561 - mae: 0.6778\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6415 - mae: 0.6706\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.6684 - mae: 0.6825\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.6358 - mae: 0.6672\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 0.6123 - mae: 0.6536\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.6408 - mae: 0.6750\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5715 - mae: 0.6316\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.5843 - mae: 0.6400\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.5509 - mae: 0.6212\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 0.5480 - mae: 0.6150\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.4945 - mae: 0.5893\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.4912 - mae: 0.5766\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4715 - mae: 0.5653\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.5055 - mae: 0.5902\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4753 - mae: 0.5649\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4445 - mae: 0.5491\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4233 - mae: 0.5259\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4767 - mae: 0.5597\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.4213 - mae: 0.5294\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4272 - mae: 0.5250\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4649 - mae: 0.5441\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.3950 - mae: 0.5093\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4383 - mae: 0.5328\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.3904 - mae: 0.5056\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4298 - mae: 0.5270\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.4058 - mae: 0.5133\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3939 - mae: 0.4983\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.4038 - mae: 0.5076\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3840 - mae: 0.4953\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.3895 - mae: 0.4947\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4024 - mae: 0.5017\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3837 - mae: 0.4932\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.3928 - mae: 0.4990\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3699 - mae: 0.4837\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.3902 - mae: 0.4986\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3912 - mae: 0.4969\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.4021 - mae: 0.5039\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3411 - mae: 0.4628\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.3722 - mae: 0.4886\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.4015 - mae: 0.5044\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.3684 - mae: 0.4800\n",
            "11/11 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6521739130434783\n",
            "Precision: 0.5216052863593847\n",
            "Recall: 0.49253208010577276\n",
            "F1-Score: 0.49180202417735425\n",
            "Cohen Kappa Score: 0.6456692913385828\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_32 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_33 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 11s 32ms/step - loss: 0.8845 - mae: 0.7748\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.7033 - mae: 0.6969\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.7028 - mae: 0.7073\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6983 - mae: 0.6985\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6880 - mae: 0.6971\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6763 - mae: 0.6871\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6432 - mae: 0.6700\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6603 - mae: 0.6802\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 1s 39ms/step - loss: 0.6363 - mae: 0.6713\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 1s 58ms/step - loss: 0.5894 - mae: 0.6450\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.5874 - mae: 0.6397\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5049 - mae: 0.5888\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.4842 - mae: 0.5700\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.4674 - mae: 0.5546\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.4599 - mae: 0.5504\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.4363 - mae: 0.5365\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.4222 - mae: 0.5255\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.4039 - mae: 0.5115\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 3s 139ms/step - loss: 0.4113 - mae: 0.5119\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.4103 - mae: 0.5074\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.3980 - mae: 0.5057\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 1s 70ms/step - loss: 0.3978 - mae: 0.5039\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.3820 - mae: 0.4875\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.3724 - mae: 0.4827\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.4021 - mae: 0.5072\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.3740 - mae: 0.4925\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.3849 - mae: 0.4954\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.3911 - mae: 0.5025\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.3586 - mae: 0.4783\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.3890 - mae: 0.4970\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 1s 41ms/step - loss: 0.3684 - mae: 0.4858\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.3614 - mae: 0.4732\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3622 - mae: 0.4799\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3595 - mae: 0.4789\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3778 - mae: 0.4850\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.3605 - mae: 0.4756\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3637 - mae: 0.4747\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.3553 - mae: 0.4725\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.3617 - mae: 0.4783\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.3598 - mae: 0.4788\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.3527 - mae: 0.4708\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.3754 - mae: 0.4856\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.3639 - mae: 0.4719\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3706 - mae: 0.4845\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3561 - mae: 0.4704\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3604 - mae: 0.4779\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3735 - mae: 0.4857\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3593 - mae: 0.4784\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3612 - mae: 0.4750\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3408 - mae: 0.4612\n",
            "11/11 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6811594202898551\n",
            "Precision: 0.520557016916947\n",
            "Recall: 0.5224236717221524\n",
            "F1-Score: 0.5197010869565217\n",
            "Cohen Kappa Score: 0.6840891621829361\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_30 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_15 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 2s 17ms/step - loss: 3.7590 - mae: 1.7539 - mse: 3.7590\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.9906 - mae: 1.8269 - mse: 3.9906\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.02608695652173913\n",
            "Precision: 0.006521739130434782\n",
            "Recall: 0.25\n",
            "F1-Score: 0.01271186440677966\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6434782608695652\n",
            "Precision: 0.4949782059157059\n",
            "Recall: 0.49510453458685055\n",
            "F1-Score: 0.4892035660418014\n",
            "Cohen Kappa Score: 0.6642302421196893\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6405797101449275\n",
            "Precision: 0.49298020527859243\n",
            "Recall: 0.4905732784774748\n",
            "F1-Score: 0.4882074316165049\n",
            "Cohen Kappa Score: 0.6480186480186481\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.553623188405797\n",
            "Precision: 0.5552711278804175\n",
            "Recall: 0.45960438518621494\n",
            "F1-Score: 0.4695169219940527\n",
            "Cohen Kappa Score: 0.5660639777468706\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5594202898550724\n",
            "Precision: 0.5049293143092781\n",
            "Recall: 0.45619309078779746\n",
            "F1-Score: 0.46203170726980247\n",
            "Cohen Kappa Score: 0.5553403843289141\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3739130434782609\n",
            "Precision: 0.09347826086956522\n",
            "Recall: 0.25\n",
            "F1-Score: 0.1360759493670886\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 634.25022 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.661   |   0.522   | 0.493  |  0.492   |    0.690    |\n",
            "|           BiLSTM          |  0.681   |   0.521   | 0.522  |  0.520   |    0.698    |\n",
            "|            CNN            |  0.032   |   0.008   | 0.250  |  0.015   |    0.000    |\n",
            "|    Logistic Regression    |  0.672   |   0.512   | 0.510  |  0.508   |    0.709    |\n",
            "|  Random Forest Classifier |  0.661   |   0.712   | 0.550  |  0.571   |    0.694    |\n",
            "|    Adaboost Classifier    |  0.591   |   0.685   | 0.508  |  0.514   |    0.616    |\n",
            "|   K Neighbors Classifier  |  0.588   |   0.505   | 0.456  |  0.462   |    0.597    |\n",
            "| Support Vector Classifier |  0.428   |   0.107   | 0.250  |  0.150   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 4--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_68 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_69 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 19ms/step - loss: 1.2021 - mae: 0.9000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9370 - mae: 0.8204\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9262 - mae: 0.8192\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9274 - mae: 0.8183\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9284 - mae: 0.8160\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9220 - mae: 0.8098\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.9092 - mae: 0.8172\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9214 - mae: 0.8153\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8797 - mae: 0.7990\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.8812 - mae: 0.7952\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.8638 - mae: 0.7836\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.8367 - mae: 0.7591\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.8194 - mae: 0.7537\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.8073 - mae: 0.7417\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.7454 - mae: 0.7080\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.7936 - mae: 0.7186\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6641 - mae: 0.6613\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6838 - mae: 0.6613\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6689 - mae: 0.6689\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6710 - mae: 0.6477\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5998 - mae: 0.6155\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5574 - mae: 0.5870\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5444 - mae: 0.5872\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.5342 - mae: 0.5803\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.5473 - mae: 0.5836\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5352 - mae: 0.5718\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5330 - mae: 0.5741\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5003 - mae: 0.5635\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5127 - mae: 0.5723\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5317 - mae: 0.5758\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4357 - mae: 0.5211\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4517 - mae: 0.5344\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4886 - mae: 0.5562\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4802 - mae: 0.5517\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4780 - mae: 0.5533\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4494 - mae: 0.5273\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4900 - mae: 0.5600\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4388 - mae: 0.5228\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4558 - mae: 0.5354\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4789 - mae: 0.5498\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4198 - mae: 0.5101\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4487 - mae: 0.5263\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4631 - mae: 0.5401\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4683 - mae: 0.5472\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4496 - mae: 0.5349\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3978 - mae: 0.5002\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4502 - mae: 0.5309\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4364 - mae: 0.5293\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4401 - mae: 0.5284\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4432 - mae: 0.5319\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4915254237288136\n",
            "Precision: 0.36179421948978874\n",
            "Recall: 0.4264616515291123\n",
            "F1-Score: 0.38879539135860897\n",
            "Cohen Kappa Score: 0.6104695262005234\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_34 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_35 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 13s 31ms/step - loss: 1.0834 - mae: 0.8581\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9222 - mae: 0.8126\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9330 - mae: 0.8102\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9171 - mae: 0.8152\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9167 - mae: 0.8098\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9029 - mae: 0.8011\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.8713 - mae: 0.7866\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.8625 - mae: 0.7753\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.8130 - mae: 0.7476\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.7495 - mae: 0.7047\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.6729 - mae: 0.6633\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.6476 - mae: 0.6467\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5747 - mae: 0.6030\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5598 - mae: 0.6010\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5419 - mae: 0.5848\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5450 - mae: 0.5838\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5457 - mae: 0.5926\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5072 - mae: 0.5628\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4797 - mae: 0.5498\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4963 - mae: 0.5566\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4912 - mae: 0.5617\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4439 - mae: 0.5268\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.4795 - mae: 0.5536\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4517 - mae: 0.5377\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4732 - mae: 0.5428\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.4722 - mae: 0.5481\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4471 - mae: 0.5305\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4463 - mae: 0.5251\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4640 - mae: 0.5373\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4500 - mae: 0.5348\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4540 - mae: 0.5398\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4244 - mae: 0.5185\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4461 - mae: 0.5346\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4372 - mae: 0.5222\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4261 - mae: 0.5244\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4221 - mae: 0.5233\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4334 - mae: 0.5262\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4241 - mae: 0.5248\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4214 - mae: 0.5263\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4312 - mae: 0.5236\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.4221 - mae: 0.5230\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.4276 - mae: 0.5212\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.4373 - mae: 0.5295\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4234 - mae: 0.5193\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4417 - mae: 0.5292\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4083 - mae: 0.5102\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4099 - mae: 0.5124\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4116 - mae: 0.5129\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4344 - mae: 0.5283\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4181 - mae: 0.5135\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.5819209039548022\n",
            "Precision: 0.4303263940829386\n",
            "Recall: 0.5256830181504395\n",
            "F1-Score: 0.4695891543717631\n",
            "Cohen Kappa Score: 0.6775261155011265\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_33 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_16 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 20ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9788 - mae: 1.4435 - mse: 2.9788\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.1694915254237288\n",
            "Precision: 0.0423728813559322\n",
            "Recall: 0.25\n",
            "F1-Score: 0.07246376811594203\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6045197740112994\n",
            "Precision: 0.6237802922640652\n",
            "Recall: 0.5492593933277756\n",
            "F1-Score: 0.5671820903809165\n",
            "Cohen Kappa Score: 0.6867291291025541\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6016949152542372\n",
            "Precision: 0.6037860315975817\n",
            "Recall: 0.5416365012504936\n",
            "F1-Score: 0.5552238179912702\n",
            "Cohen Kappa Score: 0.6916274941652147\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5423728813559322\n",
            "Precision: 0.5236037520243129\n",
            "Recall: 0.5446179412926155\n",
            "F1-Score: 0.5308818309874825\n",
            "Cohen Kappa Score: 0.6904283228604142\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5028248587570622\n",
            "Precision: 0.46902008022219716\n",
            "Recall: 0.44853889693299986\n",
            "F1-Score: 0.453763397856343\n",
            "Cohen Kappa Score: 0.5791883389914972\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4011299435028249\n",
            "Precision: 0.10028248587570622\n",
            "Recall: 0.25\n",
            "F1-Score: 0.1431451612903226\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_72 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_73 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 19ms/step - loss: 1.1561 - mae: 0.8791\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9412 - mae: 0.8104\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9075 - mae: 0.8062\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9073 - mae: 0.8080\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9024 - mae: 0.8107\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8930 - mae: 0.7967\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9073 - mae: 0.8007\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 0.8766 - mae: 0.7926\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.8714 - mae: 0.7883\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 0.8692 - mae: 0.7848\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.8360 - mae: 0.7650\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.8232 - mae: 0.7592\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.8355 - mae: 0.7528\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.7326 - mae: 0.7066\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7834 - mae: 0.7224\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6465 - mae: 0.6506\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6721 - mae: 0.6638\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5966 - mae: 0.6172\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6713 - mae: 0.6565\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5484 - mae: 0.5897\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5556 - mae: 0.5821\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5448 - mae: 0.5896\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5575 - mae: 0.5953\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4666 - mae: 0.5437\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5069 - mae: 0.5630\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4666 - mae: 0.5464\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4745 - mae: 0.5522\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5431 - mae: 0.5801\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5178 - mae: 0.5741\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4336 - mae: 0.5253\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4636 - mae: 0.5374\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4916 - mae: 0.5592\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4383 - mae: 0.5278\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5051 - mae: 0.5679\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3876 - mae: 0.4951\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5031 - mae: 0.5588\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4405 - mae: 0.5326\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4381 - mae: 0.5260\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4562 - mae: 0.5401\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4029 - mae: 0.5107\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4506 - mae: 0.5346\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5112 - mae: 0.5773\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3952 - mae: 0.4982\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4489 - mae: 0.5381\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4337 - mae: 0.5270\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4221 - mae: 0.5167\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4901 - mae: 0.5616\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4414 - mae: 0.5310\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4552 - mae: 0.5441\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4128 - mae: 0.5191\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2514124293785311\n",
            "Precision: 0.18560755085387887\n",
            "Recall: 0.30078973092555433\n",
            "F1-Score: 0.20165280681334904\n",
            "Cohen Kappa Score: 0.43580143891382306\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_36 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_37 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 13s 34ms/step - loss: 1.0691 - mae: 0.8523\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9159 - mae: 0.8059\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9067 - mae: 0.8036\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.8935 - mae: 0.7947\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.8937 - mae: 0.7892\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.8658 - mae: 0.7783\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.8355 - mae: 0.7561\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.7559 - mae: 0.7156\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.7209 - mae: 0.6821\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6383 - mae: 0.6427\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6165 - mae: 0.6310\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5686 - mae: 0.6020\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5305 - mae: 0.5773\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5104 - mae: 0.5662\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5014 - mae: 0.5651\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5132 - mae: 0.5688\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4686 - mae: 0.5405\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5292 - mae: 0.5820\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4373 - mae: 0.5305\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4378 - mae: 0.5265\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4959 - mae: 0.5601\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.4669 - mae: 0.5440\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.4438 - mae: 0.5313\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.4428 - mae: 0.5282\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.4416 - mae: 0.5374\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.4422 - mae: 0.5365\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4215 - mae: 0.5214\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4618 - mae: 0.5403\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4242 - mae: 0.5245\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4379 - mae: 0.5296\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4226 - mae: 0.5215\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4302 - mae: 0.5272\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4293 - mae: 0.5223\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4210 - mae: 0.5180\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4256 - mae: 0.5235\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4360 - mae: 0.5327\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4206 - mae: 0.5213\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4086 - mae: 0.5169\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.4229 - mae: 0.5199\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4022 - mae: 0.5091\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.4378 - mae: 0.5282\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4031 - mae: 0.5062\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.4115 - mae: 0.5189\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3948 - mae: 0.5034\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3977 - mae: 0.5148\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4129 - mae: 0.5120\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4268 - mae: 0.5221\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3975 - mae: 0.5103\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4041 - mae: 0.5131\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4085 - mae: 0.5076\n",
            "12/12 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.403954802259887\n",
            "Precision: 0.3017302910840731\n",
            "Recall: 0.37272855893399187\n",
            "F1-Score: 0.32821866082229595\n",
            "Cohen Kappa Score: 0.5488484529721748\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_34 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_35 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_17 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 15ms/step - loss: 6.2160 - mae: 1.8508 - mse: 6.2160\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8701 - mae: 1.4124 - mse: 2.8701\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.1553672316384181\n",
            "Precision: 0.03884180790960452\n",
            "Recall: 0.25\n",
            "F1-Score: 0.06723716381418093\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6186440677966102\n",
            "Precision: 0.6481265359747165\n",
            "Recall: 0.5738261782286107\n",
            "F1-Score: 0.5925850655412961\n",
            "Cohen Kappa Score: 0.6670476036367682\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6073446327683616\n",
            "Precision: 0.6121959080856465\n",
            "Recall: 0.5691253246090564\n",
            "F1-Score: 0.5792929760903164\n",
            "Cohen Kappa Score: 0.661712345379578\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4915254237288136\n",
            "Precision: 0.48421685405037085\n",
            "Recall: 0.5088777045131939\n",
            "F1-Score: 0.48884205999800456\n",
            "Cohen Kappa Score: 0.6584212952473221\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.4519774011299435\n",
            "Precision: 0.471776107768311\n",
            "Recall: 0.41362062341807115\n",
            "F1-Score: 0.42706693598254186\n",
            "Cohen Kappa Score: 0.5210709120069268\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3502824858757062\n",
            "Precision: 0.08757062146892655\n",
            "Recall: 0.25\n",
            "F1-Score: 0.12970711297071127\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_76 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_77 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 18ms/step - loss: 1.1478 - mae: 0.8734\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9210 - mae: 0.8024\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8880 - mae: 0.7972\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.9020 - mae: 0.7997\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9029 - mae: 0.8025\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8889 - mae: 0.7938\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8802 - mae: 0.7938\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9007 - mae: 0.8036\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8523 - mae: 0.7787\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8718 - mae: 0.7764\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8432 - mae: 0.7568\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.8174 - mae: 0.7488\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8111 - mae: 0.7380\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6917 - mae: 0.6763\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7105 - mae: 0.6822\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6893 - mae: 0.6627\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6557 - mae: 0.6532\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5952 - mae: 0.6142\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5859 - mae: 0.6100\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5708 - mae: 0.5938\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5702 - mae: 0.6001\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5789 - mae: 0.6077\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5450 - mae: 0.5810\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5521 - mae: 0.5953\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5725 - mae: 0.6012\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4909 - mae: 0.5598\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5130 - mae: 0.5668\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4614 - mae: 0.5385\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5131 - mae: 0.5639\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5226 - mae: 0.5701\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5277 - mae: 0.5739\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4672 - mae: 0.5471\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4691 - mae: 0.5464\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4903 - mae: 0.5667\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5182 - mae: 0.5793\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4430 - mae: 0.5270\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4733 - mae: 0.5516\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4666 - mae: 0.5458\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4531 - mae: 0.5342\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4867 - mae: 0.5567\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4473 - mae: 0.5351\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4588 - mae: 0.5380\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4502 - mae: 0.5349\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4527 - mae: 0.5394\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4433 - mae: 0.5301\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4766 - mae: 0.5489\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4696 - mae: 0.5483\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4066 - mae: 0.5069\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4638 - mae: 0.5466\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4437 - mae: 0.5287\n",
            "12/12 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5988700564971752\n",
            "Precision: 0.48984375\n",
            "Recall: 0.5248867889048503\n",
            "F1-Score: 0.48861049309256477\n",
            "Cohen Kappa Score: 0.6548484311292324\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_38 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_39 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 35ms/step - loss: 1.0932 - mae: 0.8649\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9333 - mae: 0.8129\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.9023 - mae: 0.8039\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8916 - mae: 0.7909\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.8892 - mae: 0.7912\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.8552 - mae: 0.7750\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.8339 - mae: 0.7548\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.7650 - mae: 0.7194\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.6976 - mae: 0.6702\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6538 - mae: 0.6434\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5735 - mae: 0.6010\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5935 - mae: 0.6202\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5273 - mae: 0.5695\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5168 - mae: 0.5719\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4921 - mae: 0.5459\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5245 - mae: 0.5747\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4846 - mae: 0.5558\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4927 - mae: 0.5519\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4826 - mae: 0.5500\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4608 - mae: 0.5390\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4694 - mae: 0.5382\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4760 - mae: 0.5505\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.4597 - mae: 0.5386\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 74ms/step - loss: 0.4393 - mae: 0.5296\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 74ms/step - loss: 0.4717 - mae: 0.5438\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.4236 - mae: 0.5166\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4436 - mae: 0.5334\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4699 - mae: 0.5477\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4506 - mae: 0.5327\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4627 - mae: 0.5434\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4326 - mae: 0.5263\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4431 - mae: 0.5288\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4413 - mae: 0.5287\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4144 - mae: 0.5066\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4279 - mae: 0.5192\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4503 - mae: 0.5419\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4486 - mae: 0.5371\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4232 - mae: 0.5222\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4217 - mae: 0.5166\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4409 - mae: 0.5300\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.4351 - mae: 0.5283\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.4365 - mae: 0.5264\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.4313 - mae: 0.5203\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4153 - mae: 0.5098\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4365 - mae: 0.5253\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4303 - mae: 0.5221\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4078 - mae: 0.5050\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4244 - mae: 0.5202\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4325 - mae: 0.5248\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4087 - mae: 0.5101\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.5706214689265536\n",
            "Precision: 0.4823191666214922\n",
            "Recall: 0.48500319056456037\n",
            "F1-Score: 0.44885792292547466\n",
            "Cohen Kappa Score: 0.609431365986091\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_36 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_37 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_18 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 15ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9506 - mae: 1.4407 - mse: 2.9506\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.2033898305084746\n",
            "Precision: 0.05084745762711865\n",
            "Recall: 0.25\n",
            "F1-Score: 0.08450704225352114\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6016949152542372\n",
            "Precision: 0.6052194004152529\n",
            "Recall: 0.5742281077263383\n",
            "F1-Score: 0.5640252728302725\n",
            "Cohen Kappa Score: 0.7002122126909167\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6214689265536724\n",
            "Precision: 0.6129490071951487\n",
            "Recall: 0.6108083243079574\n",
            "F1-Score: 0.6076482987052092\n",
            "Cohen Kappa Score: 0.7294685990338164\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4717514124293785\n",
            "Precision: 0.4708117658485306\n",
            "Recall: 0.4962832406134378\n",
            "F1-Score: 0.4715369053604347\n",
            "Cohen Kappa Score: 0.6820786811882092\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5423728813559322\n",
            "Precision: 0.5411113652854901\n",
            "Recall: 0.4966902602322416\n",
            "F1-Score: 0.5083627689014202\n",
            "Cohen Kappa Score: 0.633160621761658\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.327683615819209\n",
            "Precision: 0.08192090395480225\n",
            "Recall: 0.25\n",
            "F1-Score: 0.12340425531914893\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_80 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_81 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 35ms/step - loss: 1.1823 - mae: 0.8876\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.9483 - mae: 0.8288\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.9182 - mae: 0.8151\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.9272 - mae: 0.8095\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.9281 - mae: 0.8127\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 0.9263 - mae: 0.8176\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.9181 - mae: 0.8160\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.9018 - mae: 0.8049\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 0.8902 - mae: 0.8014\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.8881 - mae: 0.7986\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.8807 - mae: 0.7927\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8565 - mae: 0.7761\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8317 - mae: 0.7610\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7877 - mae: 0.7293\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7543 - mae: 0.7173\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7507 - mae: 0.7078\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6582 - mae: 0.6550\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6644 - mae: 0.6570\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6361 - mae: 0.6397\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6081 - mae: 0.6288\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5653 - mae: 0.6009\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5371 - mae: 0.5865\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5489 - mae: 0.5861\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5951 - mae: 0.6136\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5283 - mae: 0.5775\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5128 - mae: 0.5653\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5341 - mae: 0.5852\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4899 - mae: 0.5520\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5348 - mae: 0.5856\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5235 - mae: 0.5735\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4797 - mae: 0.5578\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4962 - mae: 0.5602\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4711 - mae: 0.5513\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4688 - mae: 0.5416\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4891 - mae: 0.5588\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4545 - mae: 0.5336\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4325 - mae: 0.5250\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4576 - mae: 0.5388\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4555 - mae: 0.5338\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4770 - mae: 0.5537\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4740 - mae: 0.5449\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4671 - mae: 0.5429\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4206 - mae: 0.5124\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4740 - mae: 0.5457\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4429 - mae: 0.5333\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4711 - mae: 0.5461\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4313 - mae: 0.5274\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4367 - mae: 0.5234\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4262 - mae: 0.5170\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4332 - mae: 0.5207\n",
            "12/12 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4830508474576271\n",
            "Precision: 0.3695409996119713\n",
            "Recall: 0.47346907993966814\n",
            "F1-Score: 0.3950283686247791\n",
            "Cohen Kappa Score: 0.5808734044660799\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_40 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_41 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 32ms/step - loss: 1.0636 - mae: 0.8581\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9470 - mae: 0.8197\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9448 - mae: 0.8190\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.9339 - mae: 0.8220\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.9080 - mae: 0.8053\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.8982 - mae: 0.8024\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.9115 - mae: 0.7994\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.8411 - mae: 0.7624\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.7986 - mae: 0.7396\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.7582 - mae: 0.7093\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6653 - mae: 0.6568\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6050 - mae: 0.6185\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6155 - mae: 0.6301\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5255 - mae: 0.5782\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5810 - mae: 0.6085\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5139 - mae: 0.5737\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4864 - mae: 0.5544\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4977 - mae: 0.5710\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4890 - mae: 0.5603\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4815 - mae: 0.5515\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.4719 - mae: 0.5512\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.4627 - mae: 0.5386\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.4984 - mae: 0.5693\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.4580 - mae: 0.5376\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.4715 - mae: 0.5445\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4500 - mae: 0.5395\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4585 - mae: 0.5464\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4595 - mae: 0.5439\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4479 - mae: 0.5268\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4324 - mae: 0.5277\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4324 - mae: 0.5270\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4451 - mae: 0.5367\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4179 - mae: 0.5169\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4123 - mae: 0.5125\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4391 - mae: 0.5328\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4335 - mae: 0.5271\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4370 - mae: 0.5316\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4276 - mae: 0.5202\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.4235 - mae: 0.5170\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.4354 - mae: 0.5284\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.4153 - mae: 0.5134\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.4304 - mae: 0.5270\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4430 - mae: 0.5262\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4105 - mae: 0.5196\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4250 - mae: 0.5279\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4295 - mae: 0.5282\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4161 - mae: 0.5162\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4279 - mae: 0.5294\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4216 - mae: 0.5215\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4162 - mae: 0.5146\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6299435028248588\n",
            "Precision: 0.5308302005012531\n",
            "Recall: 0.4577752639517345\n",
            "F1-Score: 0.41865411187792406\n",
            "Cohen Kappa Score: 0.6111408212525475\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_20 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_38 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_39 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_19 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 14ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.8983 - mae: 1.4138 - mse: 2.8983\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.13559322033898305\n",
            "Precision: 0.03389830508474576\n",
            "Recall: 0.25\n",
            "F1-Score: 0.05970149253731343\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6271186440677966\n",
            "Precision: 0.6032991747835498\n",
            "Recall: 0.5417053167420816\n",
            "F1-Score: 0.5573442423973782\n",
            "Cohen Kappa Score: 0.6922298871475492\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6497175141242938\n",
            "Precision: 0.614756435021489\n",
            "Recall: 0.5797060708898945\n",
            "F1-Score: 0.5914985059071081\n",
            "Cohen Kappa Score: 0.7142365109946291\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4858757062146893\n",
            "Precision: 0.48763326650882133\n",
            "Recall: 0.5062829939668175\n",
            "F1-Score: 0.4750810796174385\n",
            "Cohen Kappa Score: 0.6533627506879198\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5056497175141242\n",
            "Precision: 0.4760595052759038\n",
            "Recall: 0.43097228506787333\n",
            "F1-Score: 0.4390282087309486\n",
            "Cohen Kappa Score: 0.5575724499263222\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3672316384180791\n",
            "Precision: 0.09180790960451977\n",
            "Recall: 0.25\n",
            "F1-Score: 0.13429752066115702\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_84 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_85 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 18ms/step - loss: 1.1921 - mae: 0.8971\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9109 - mae: 0.8035\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9020 - mae: 0.8136\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8965 - mae: 0.7996\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8865 - mae: 0.7966\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.8757 - mae: 0.7962\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.8684 - mae: 0.7946\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.8687 - mae: 0.7898\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.8598 - mae: 0.7843\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.8600 - mae: 0.7880\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.8363 - mae: 0.7675\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.8003 - mae: 0.7485\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.7810 - mae: 0.7297\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.7124 - mae: 0.6893\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.7647 - mae: 0.7076\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6822 - mae: 0.6666\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6401 - mae: 0.6397\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.5903 - mae: 0.6145\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6449 - mae: 0.6439\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5786 - mae: 0.5979\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5704 - mae: 0.6057\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5690 - mae: 0.5894\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5214 - mae: 0.5649\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5084 - mae: 0.5640\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4935 - mae: 0.5557\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5221 - mae: 0.5745\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5361 - mae: 0.5834\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5444 - mae: 0.5819\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4717 - mae: 0.5451\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5294 - mae: 0.5789\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4398 - mae: 0.5192\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4593 - mae: 0.5382\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4970 - mae: 0.5531\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4579 - mae: 0.5319\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5015 - mae: 0.5625\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4513 - mae: 0.5272\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4800 - mae: 0.5483\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4749 - mae: 0.5432\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4687 - mae: 0.5383\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4534 - mae: 0.5290\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4616 - mae: 0.5355\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4706 - mae: 0.5390\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4519 - mae: 0.5283\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4829 - mae: 0.5474\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4456 - mae: 0.5294\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4549 - mae: 0.5232\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4541 - mae: 0.5319\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4468 - mae: 0.5307\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4541 - mae: 0.5373\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4484 - mae: 0.5278\n",
            "12/12 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.384180790960452\n",
            "Precision: 0.2921725104483891\n",
            "Recall: 0.3580766432209556\n",
            "F1-Score: 0.3087626573617953\n",
            "Cohen Kappa Score: 0.5709071132946805\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_42 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_43 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 14s 68ms/step - loss: 1.0619 - mae: 0.8450\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.9219 - mae: 0.8074\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.9017 - mae: 0.7996\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8983 - mae: 0.8032\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.8762 - mae: 0.7935\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.8692 - mae: 0.7877\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.8618 - mae: 0.7819\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8209 - mae: 0.7565\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.8020 - mae: 0.7384\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.7522 - mae: 0.7087\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6893 - mae: 0.6717\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.6327 - mae: 0.6367\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6165 - mae: 0.6277\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5626 - mae: 0.5948\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5408 - mae: 0.5837\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5342 - mae: 0.5771\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5347 - mae: 0.5788\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4752 - mae: 0.5454\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 0.5207 - mae: 0.5678\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4723 - mae: 0.5354\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5012 - mae: 0.5563\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4633 - mae: 0.5313\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4691 - mae: 0.5355\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4660 - mae: 0.5367\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4372 - mae: 0.5212\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4573 - mae: 0.5285\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4607 - mae: 0.5375\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4561 - mae: 0.5318\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4405 - mae: 0.5214\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4282 - mae: 0.5121\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4362 - mae: 0.5207\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4286 - mae: 0.5151\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.4406 - mae: 0.5205\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4374 - mae: 0.5141\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.4324 - mae: 0.5137\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.4157 - mae: 0.5114\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4397 - mae: 0.5212\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4484 - mae: 0.5220\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4302 - mae: 0.5137\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4002 - mae: 0.4943\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4227 - mae: 0.5138\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4317 - mae: 0.5177\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4379 - mae: 0.5245\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4281 - mae: 0.5170\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4242 - mae: 0.5142\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4085 - mae: 0.5017\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4209 - mae: 0.5131\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4127 - mae: 0.5064\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4240 - mae: 0.5188\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.4189 - mae: 0.5079\n",
            "12/12 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.556497175141243\n",
            "Precision: 0.42489276365937495\n",
            "Recall: 0.5136657888962036\n",
            "F1-Score: 0.4627455084597942\n",
            "Cohen Kappa Score: 0.6587057898873461\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_40 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_41 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_20 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 17ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.9718 - mae: 1.4506 - mse: 2.9718\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.21468926553672316\n",
            "Precision: 0.05367231638418079\n",
            "Recall: 0.25\n",
            "F1-Score: 0.08837209302325581\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5847457627118644\n",
            "Precision: 0.6289673561732385\n",
            "Recall: 0.5476684222075927\n",
            "F1-Score: 0.5529769158785193\n",
            "Cohen Kappa Score: 0.7060247308669982\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6129943502824858\n",
            "Precision: 0.6279042470870103\n",
            "Recall: 0.5803887599182288\n",
            "F1-Score: 0.5910592185592185\n",
            "Cohen Kappa Score: 0.7380131590255827\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5649717514124294\n",
            "Precision: 0.5716492170867998\n",
            "Recall: 0.6033259993301225\n",
            "F1-Score: 0.581448966968769\n",
            "Cohen Kappa Score: 0.7635692928979149\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.519774011299435\n",
            "Precision: 0.5493565525383708\n",
            "Recall: 0.48914870702100877\n",
            "F1-Score: 0.5044652380820676\n",
            "Cohen Kappa Score: 0.6484624942520865\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3502824858757062\n",
            "Precision: 0.08757062146892655\n",
            "Recall: 0.25\n",
            "F1-Score: 0.12970711297071127\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 603.36520 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.599   |   0.490   | 0.525  |  0.489   |    0.655    |\n",
            "|           BiLSTM          |  0.630   |   0.531   | 0.526  |  0.470   |    0.678    |\n",
            "|            CNN            |  0.215   |   0.054   | 0.250  |  0.088   |    0.000    |\n",
            "|    Logistic Regression    |  0.627   |   0.648   | 0.574  |  0.593   |    0.706    |\n",
            "|  Random Forest Classifier |  0.650   |   0.628   | 0.611  |  0.608   |    0.738    |\n",
            "|    Adaboost Classifier    |  0.565   |   0.572   | 0.603  |  0.581   |    0.764    |\n",
            "|   K Neighbors Classifier  |  0.542   |   0.549   | 0.497  |  0.508   |    0.648    |\n",
            "| Support Vector Classifier |  0.401   |   0.100   | 0.250  |  0.143   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 5--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_88 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_89 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 19ms/step - loss: 1.7938 - mae: 1.0538\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9808 - mae: 0.8206\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.0153 - mae: 0.8286\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9996 - mae: 0.8250\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9332 - mae: 0.8011\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9632 - mae: 0.8174\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9106 - mae: 0.7885\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9019 - mae: 0.7683\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7866 - mae: 0.7192\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7414 - mae: 0.6947\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7084 - mae: 0.6793\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6861 - mae: 0.6678\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6745 - mae: 0.6608\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5740 - mae: 0.6035\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5255 - mae: 0.5811\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5955 - mae: 0.6163\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5872 - mae: 0.6162\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5593 - mae: 0.6016\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5115 - mae: 0.5714\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5354 - mae: 0.5854\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4710 - mae: 0.5475\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4812 - mae: 0.5550\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5329 - mae: 0.5808\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4976 - mae: 0.5660\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4879 - mae: 0.5683\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4903 - mae: 0.5608\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5024 - mae: 0.5696\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4582 - mae: 0.5502\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4728 - mae: 0.5508\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4245 - mae: 0.5156\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5166 - mae: 0.5765\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4321 - mae: 0.5315\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4488 - mae: 0.5338\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4857 - mae: 0.5570\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4432 - mae: 0.5320\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.4580 - mae: 0.5450\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3964 - mae: 0.5075\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.4852 - mae: 0.5595\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.4221 - mae: 0.5252\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4281 - mae: 0.5259\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4524 - mae: 0.5437\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4005 - mae: 0.5095\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4443 - mae: 0.5294\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3860 - mae: 0.5014\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.4196 - mae: 0.5169\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4144 - mae: 0.5144\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4385 - mae: 0.5297\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4459 - mae: 0.5353\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4308 - mae: 0.5298\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4157 - mae: 0.5197\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.44321329639889195\n",
            "Precision: 0.26715750073844335\n",
            "Recall: 0.3647809709330298\n",
            "F1-Score: 0.2938017319400729\n",
            "Cohen Kappa Score: 0.6407077471278491\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_44 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_45 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 14s 60ms/step - loss: 1.3698 - mae: 0.9394\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 1.0172 - mae: 0.8274\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.0054 - mae: 0.8271\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9703 - mae: 0.8070\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9467 - mae: 0.7997\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8783 - mae: 0.7645\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8374 - mae: 0.7397\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6980 - mae: 0.6773\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6404 - mae: 0.6480\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5734 - mae: 0.6098\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5259 - mae: 0.5797\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5280 - mae: 0.5869\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5306 - mae: 0.5886\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4875 - mae: 0.5575\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.4423 - mae: 0.5361\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4528 - mae: 0.5371\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.4592 - mae: 0.5440\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.4731 - mae: 0.5481\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4730 - mae: 0.5492\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4749 - mae: 0.5564\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4899 - mae: 0.5615\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.4430 - mae: 0.5362\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4372 - mae: 0.5293\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4638 - mae: 0.5492\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4403 - mae: 0.5350\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4260 - mae: 0.5267\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4021 - mae: 0.5090\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4450 - mae: 0.5332\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4046 - mae: 0.5067\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4319 - mae: 0.5238\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.3792 - mae: 0.4974\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4481 - mae: 0.5368\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.4134 - mae: 0.5210\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4169 - mae: 0.5095\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4212 - mae: 0.5226\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4090 - mae: 0.5084\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3943 - mae: 0.5036\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3884 - mae: 0.5024\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4018 - mae: 0.5083\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4138 - mae: 0.5122\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3919 - mae: 0.4953\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3893 - mae: 0.5030\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3769 - mae: 0.4868\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3798 - mae: 0.4945\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3868 - mae: 0.4937\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3828 - mae: 0.4860\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3645 - mae: 0.4803\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.3907 - mae: 0.4869\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3999 - mae: 0.5021\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.3722 - mae: 0.4814\n",
            "12/12 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.6094182825484764\n",
            "Precision: 0.494917921613657\n",
            "Recall: 0.5071404288572224\n",
            "F1-Score: 0.4835674229562176\n",
            "Cohen Kappa Score: 0.7619218211869305\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_42 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_43 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_21 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 26ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.6544 - mae: 2.3885 - mse: 6.6544\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Accuracy: 0.008310249307479225\n",
            "Precision: 0.001662049861495845\n",
            "Recall: 0.2\n",
            "F1-Score: 0.0032967032967032976\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6565096952908587\n",
            "Precision: 0.5416376124974887\n",
            "Recall: 0.5086186333017364\n",
            "F1-Score: 0.5208394460530549\n",
            "Cohen Kappa Score: 0.7696148359486448\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6952908587257618\n",
            "Precision: 0.7565467568573695\n",
            "Recall: 0.6206900900924394\n",
            "F1-Score: 0.653503086878733\n",
            "Cohen Kappa Score: 0.8125395460872828\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5595567867036011\n",
            "Precision: 0.22449194874499706\n",
            "Recall: 0.32417710081321804\n",
            "F1-Score: 0.2651038062283737\n",
            "Cohen Kappa Score: 0.5701812409048816\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5844875346260388\n",
            "Precision: 0.48282167329073805\n",
            "Recall: 0.4626386579968612\n",
            "F1-Score: 0.47058549055946586\n",
            "Cohen Kappa Score: 0.7166507280633696\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3379501385041551\n",
            "Precision: 0.06759002770083103\n",
            "Recall: 0.2\n",
            "F1-Score: 0.1010351966873706\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_92 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_93 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 21ms/step - loss: 1.8366 - mae: 1.0700\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9707 - mae: 0.8120\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9854 - mae: 0.8184\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9730 - mae: 0.8127\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9538 - mae: 0.8084\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9224 - mae: 0.7953\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8974 - mae: 0.7735\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8887 - mae: 0.7716\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8419 - mae: 0.7496\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7938 - mae: 0.7245\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.7149 - mae: 0.6798\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.7765 - mae: 0.7016\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5607 - mae: 0.5953\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6113 - mae: 0.6252\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6058 - mae: 0.6242\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5687 - mae: 0.5969\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6071 - mae: 0.6242\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4848 - mae: 0.5508\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5673 - mae: 0.6044\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5536 - mae: 0.6010\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4713 - mae: 0.5490\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5279 - mae: 0.5885\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4758 - mae: 0.5529\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4911 - mae: 0.5663\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4853 - mae: 0.5614\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4572 - mae: 0.5479\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4502 - mae: 0.5396\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4552 - mae: 0.5421\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.4684 - mae: 0.5474\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4088 - mae: 0.5142\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.3750 - mae: 0.4887\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.4508 - mae: 0.5328\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4292 - mae: 0.5282\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4566 - mae: 0.5418\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 0.4224 - mae: 0.5259\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 0.4436 - mae: 0.5349\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 0.4236 - mae: 0.5173\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 0.4350 - mae: 0.5297\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4255 - mae: 0.5245\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.4753 - mae: 0.5497\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3747 - mae: 0.4881\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4232 - mae: 0.5167\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4151 - mae: 0.5152\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4330 - mae: 0.5276\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4002 - mae: 0.5099\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4352 - mae: 0.5284\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4206 - mae: 0.5234\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3949 - mae: 0.5036\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4067 - mae: 0.5140\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4105 - mae: 0.5088\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45706371191135736\n",
            "Precision: 0.275474945420767\n",
            "Recall: 0.3739468210921252\n",
            "F1-Score: 0.3112763596004439\n",
            "Cohen Kappa Score: 0.6423736089555196\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_46 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_47 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 12s 33ms/step - loss: 1.3314 - mae: 0.9328\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9757 - mae: 0.8187\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.9893 - mae: 0.8207\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9615 - mae: 0.8046\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.9223 - mae: 0.7854\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9491 - mae: 0.7939\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.8102 - mae: 0.7290\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.7296 - mae: 0.6866\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5924 - mae: 0.6208\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5860 - mae: 0.6162\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6383 - mae: 0.6448\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4992 - mae: 0.5646\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.4873 - mae: 0.5588\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.4587 - mae: 0.5441\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.5429 - mae: 0.5904\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.4614 - mae: 0.5466\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4538 - mae: 0.5432\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4755 - mae: 0.5521\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4389 - mae: 0.5345\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4710 - mae: 0.5490\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4417 - mae: 0.5366\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4386 - mae: 0.5358\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4197 - mae: 0.5215\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4177 - mae: 0.5183\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4337 - mae: 0.5285\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4211 - mae: 0.5193\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4198 - mae: 0.5213\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4056 - mae: 0.5121\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4073 - mae: 0.5082\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.4030 - mae: 0.5045\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.4020 - mae: 0.5084\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3809 - mae: 0.4882\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.4016 - mae: 0.5097\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.3796 - mae: 0.4900\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4141 - mae: 0.5120\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3749 - mae: 0.4910\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3778 - mae: 0.4940\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3617 - mae: 0.4786\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3828 - mae: 0.4962\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3757 - mae: 0.4899\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3864 - mae: 0.4938\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3859 - mae: 0.4952\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3578 - mae: 0.4780\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3732 - mae: 0.4873\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3703 - mae: 0.4864\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3703 - mae: 0.4898\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3616 - mae: 0.4841\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.3613 - mae: 0.4773\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.3599 - mae: 0.4790\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.3510 - mae: 0.4661\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.6094182825484764\n",
            "Precision: 0.5276043644464697\n",
            "Recall: 0.47998280908357993\n",
            "F1-Score: 0.4742810316577133\n",
            "Cohen Kappa Score: 0.757017614413255\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_23 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_44 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_45 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_22 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7175 - mae: 2.4044 - mse: 6.7175\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.008310249307479225\n",
            "Precision: 0.001662049861495845\n",
            "Recall: 0.2\n",
            "F1-Score: 0.0032967032967032976\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6620498614958449\n",
            "Precision: 0.5417278175215692\n",
            "Recall: 0.5212171670750031\n",
            "F1-Score: 0.5281770668862222\n",
            "Cohen Kappa Score: 0.7827152426074171\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6952908587257618\n",
            "Precision: 0.7707487995822552\n",
            "Recall: 0.6122629059968483\n",
            "F1-Score: 0.6540029787542625\n",
            "Cohen Kappa Score: 0.8073400762527698\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5235457063711911\n",
            "Precision: 0.2767440892440892\n",
            "Recall: 0.32171302149178255\n",
            "F1-Score: 0.2595932203389831\n",
            "Cohen Kappa Score: 0.5487053173581542\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5650969529085873\n",
            "Precision: 0.4639342637412277\n",
            "Recall: 0.43879011083121844\n",
            "F1-Score: 0.44663886975732003\n",
            "Cohen Kappa Score: 0.7133927827318944\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.34349030470914127\n",
            "Precision: 0.06869806094182826\n",
            "Recall: 0.2\n",
            "F1-Score: 0.10226804123711339\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_96 (LSTM)              (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_97 (LSTM)              (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 19ms/step - loss: 1.8465 - mae: 1.0679\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9835 - mae: 0.8315\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.0064 - mae: 0.8291\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9803 - mae: 0.8111\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9718 - mae: 0.8143\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9094 - mae: 0.7978\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9089 - mae: 0.7878\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8877 - mae: 0.7720\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8233 - mae: 0.7432\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7630 - mae: 0.7128\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7797 - mae: 0.7121\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7060 - mae: 0.6790\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6728 - mae: 0.6664\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5718 - mae: 0.6083\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6360 - mae: 0.6409\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5159 - mae: 0.5711\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5579 - mae: 0.6010\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5906 - mae: 0.6251\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4779 - mae: 0.5539\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5398 - mae: 0.5861\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5640 - mae: 0.6039\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4754 - mae: 0.5518\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4619 - mae: 0.5402\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4622 - mae: 0.5409\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3963 - mae: 0.5028\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5245 - mae: 0.5881\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3985 - mae: 0.5051\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4848 - mae: 0.5499\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4595 - mae: 0.5468\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.4589 - mae: 0.5413\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4123 - mae: 0.5172\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4864 - mae: 0.5559\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4103 - mae: 0.5117\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4710 - mae: 0.5432\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4428 - mae: 0.5351\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4508 - mae: 0.5334\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4198 - mae: 0.5173\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4634 - mae: 0.5444\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3887 - mae: 0.5005\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4075 - mae: 0.5117\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.4012 - mae: 0.5032\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4246 - mae: 0.5228\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.4576 - mae: 0.5469\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.3975 - mae: 0.5024\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3736 - mae: 0.4939\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4077 - mae: 0.5113\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4390 - mae: 0.5319\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3690 - mae: 0.4869\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4038 - mae: 0.5075\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3943 - mae: 0.5052\n",
            "12/12 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.631578947368421\n",
            "Precision: 0.5099333641673947\n",
            "Recall: 0.5052746133475562\n",
            "F1-Score: 0.5056864646119731\n",
            "Cohen Kappa Score: 0.7529111628651176\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_48 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_49 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 12s 61ms/step - loss: 1.3222 - mae: 0.9261\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 1.0125 - mae: 0.8367\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9963 - mae: 0.8223\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9470 - mae: 0.8037\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.9024 - mae: 0.7779\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.8843 - mae: 0.7638\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.7412 - mae: 0.6986\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6060 - mae: 0.6272\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6003 - mae: 0.6261\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5455 - mae: 0.5959\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5452 - mae: 0.5917\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4511 - mae: 0.5374\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4876 - mae: 0.5580\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5531 - mae: 0.5964\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.4235 - mae: 0.5214\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 0.4518 - mae: 0.5375\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.4503 - mae: 0.5400\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4352 - mae: 0.5348\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4685 - mae: 0.5427\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4153 - mae: 0.5195\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4094 - mae: 0.5232\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4141 - mae: 0.5164\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4091 - mae: 0.5138\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3987 - mae: 0.5067\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4076 - mae: 0.5168\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3864 - mae: 0.4996\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4381 - mae: 0.5272\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3857 - mae: 0.4955\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4097 - mae: 0.5167\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3863 - mae: 0.5002\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.3827 - mae: 0.4947\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.3817 - mae: 0.4947\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3651 - mae: 0.4844\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3868 - mae: 0.4967\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.3869 - mae: 0.4961\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3767 - mae: 0.4967\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3867 - mae: 0.5002\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3693 - mae: 0.4921\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3632 - mae: 0.4874\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3609 - mae: 0.4807\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3694 - mae: 0.4839\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3752 - mae: 0.4870\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3634 - mae: 0.4842\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3698 - mae: 0.4860\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3575 - mae: 0.4769\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3523 - mae: 0.4704\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3707 - mae: 0.4893\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.3691 - mae: 0.4840\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3593 - mae: 0.4763\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.3499 - mae: 0.4808\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.628808864265928\n",
            "Precision: 0.5114777670656812\n",
            "Recall: 0.5003697373792515\n",
            "F1-Score: 0.5000300049228651\n",
            "Cohen Kappa Score: 0.7690136647704862\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_46 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_47 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_23 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.8871 - mae: 2.4398 - mse: 6.8871\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.024930747922437674\n",
            "Precision: 0.004986149584487535\n",
            "Recall: 0.2\n",
            "F1-Score: 0.009729729729729731\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6398891966759003\n",
            "Precision: 0.5187582607722903\n",
            "Recall: 0.5019076370284474\n",
            "F1-Score: 0.5056784067859119\n",
            "Cohen Kappa Score: 0.7477266007866186\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6537396121883656\n",
            "Precision: 0.6284907183212267\n",
            "Recall: 0.5642007321350258\n",
            "F1-Score: 0.5846102279015948\n",
            "Cohen Kappa Score: 0.7709312296347111\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.46537396121883656\n",
            "Precision: 0.24802628131223142\n",
            "Recall: 0.31160687488745276\n",
            "F1-Score: 0.27201955034213093\n",
            "Cohen Kappa Score: 0.5488988298470301\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5595567867036011\n",
            "Precision: 0.4521929824561404\n",
            "Recall: 0.43164497248048156\n",
            "F1-Score: 0.43574031683743913\n",
            "Cohen Kappa Score: 0.6751862322845255\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.38227146814404434\n",
            "Precision: 0.07645429362880887\n",
            "Recall: 0.2\n",
            "F1-Score: 0.11062124248496996\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_100 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_101 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 18ms/step - loss: 2.0410 - mae: 1.1289\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.0090 - mae: 0.8296\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9791 - mae: 0.8175\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9465 - mae: 0.8040\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9643 - mae: 0.8081\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9453 - mae: 0.8027\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9183 - mae: 0.7871\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.9053 - mae: 0.7744\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.8902 - mae: 0.7624\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7023 - mae: 0.6897\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.7987 - mae: 0.7220\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.7172 - mae: 0.6864\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6727 - mae: 0.6596\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6413 - mae: 0.6466\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5468 - mae: 0.5870\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5937 - mae: 0.6149\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5751 - mae: 0.6078\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5578 - mae: 0.5908\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5171 - mae: 0.5744\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5685 - mae: 0.6139\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4502 - mae: 0.5368\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5190 - mae: 0.5721\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4949 - mae: 0.5542\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4870 - mae: 0.5566\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4707 - mae: 0.5426\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4441 - mae: 0.5280\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4429 - mae: 0.5346\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4955 - mae: 0.5628\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4625 - mae: 0.5367\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4679 - mae: 0.5481\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4799 - mae: 0.5538\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4348 - mae: 0.5263\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5062 - mae: 0.5658\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4214 - mae: 0.5167\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4402 - mae: 0.5247\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4348 - mae: 0.5244\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4913 - mae: 0.5592\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4186 - mae: 0.5152\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4749 - mae: 0.5531\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4318 - mae: 0.5239\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3934 - mae: 0.5025\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4156 - mae: 0.5160\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4340 - mae: 0.5256\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4154 - mae: 0.5155\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4402 - mae: 0.5327\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4027 - mae: 0.5028\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4037 - mae: 0.5079\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4374 - mae: 0.5323\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3937 - mae: 0.4945\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4250 - mae: 0.5164\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4265927977839335\n",
            "Precision: 0.25775687815833803\n",
            "Recall: 0.363629431570608\n",
            "F1-Score: 0.28829251700680275\n",
            "Cohen Kappa Score: 0.6094410016944163\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_50 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_51 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 13s 32ms/step - loss: 1.3833 - mae: 0.9380\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.0052 - mae: 0.8240\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.0034 - mae: 0.8238\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9757 - mae: 0.8178\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9483 - mae: 0.8016\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.8706 - mae: 0.7658\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.7943 - mae: 0.7258\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.6837 - mae: 0.6628\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.6806 - mae: 0.6646\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.5861 - mae: 0.6087\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5579 - mae: 0.6048\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5239 - mae: 0.5827\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4883 - mae: 0.5515\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5393 - mae: 0.5907\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5058 - mae: 0.5653\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4789 - mae: 0.5577\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4462 - mae: 0.5373\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4646 - mae: 0.5482\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4530 - mae: 0.5384\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4241 - mae: 0.5172\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4460 - mae: 0.5331\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4694 - mae: 0.5488\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4542 - mae: 0.5461\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4196 - mae: 0.5176\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4161 - mae: 0.5181\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.4344 - mae: 0.5218\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.4383 - mae: 0.5251\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4192 - mae: 0.5134\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3917 - mae: 0.5006\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4015 - mae: 0.5069\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4076 - mae: 0.5104\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4072 - mae: 0.5074\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4026 - mae: 0.5018\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3885 - mae: 0.5018\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4014 - mae: 0.5084\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4119 - mae: 0.5120\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.3728 - mae: 0.4857\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.4045 - mae: 0.5034\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3826 - mae: 0.4917\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.4012 - mae: 0.5043\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.3923 - mae: 0.4982\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.3958 - mae: 0.5005\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.3917 - mae: 0.4901\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.3654 - mae: 0.4772\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.3964 - mae: 0.4970\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3804 - mae: 0.4794\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3614 - mae: 0.4794\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3740 - mae: 0.4869\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3693 - mae: 0.4833\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3675 - mae: 0.4818\n",
            "12/12 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.6537396121883656\n",
            "Precision: 0.5273068820851811\n",
            "Recall: 0.531426108878751\n",
            "F1-Score: 0.529157180575585\n",
            "Cohen Kappa Score: 0.8039575060245053\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_25 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_48 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_49 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_24 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 15ms/step - loss: 50.3593 - mae: 4.2711 - mse: 50.3593\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7306 - mae: 2.4051 - mse: 6.7306\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.008310249307479225\n",
            "Precision: 0.001662049861495845\n",
            "Recall: 0.2\n",
            "F1-Score: 0.0032967032967032976\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6537396121883656\n",
            "Precision: 0.5268003216627489\n",
            "Recall: 0.5196511979213874\n",
            "F1-Score: 0.52257935215996\n",
            "Cohen Kappa Score: 0.7939219368923789\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6343490304709142\n",
            "Precision: 0.5145421406943587\n",
            "Recall: 0.5129031759939038\n",
            "F1-Score: 0.5128812386027541\n",
            "Cohen Kappa Score: 0.7923457452927867\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5346260387811634\n",
            "Precision: 0.3182350052697135\n",
            "Recall: 0.4026500297088532\n",
            "F1-Score: 0.34190932675018504\n",
            "Cohen Kappa Score: 0.6885218755447098\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5623268698060941\n",
            "Precision: 0.468986568986569\n",
            "Recall: 0.43413594234132613\n",
            "F1-Score: 0.4456907714084606\n",
            "Cohen Kappa Score: 0.672803210071097\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3767313019390582\n",
            "Precision: 0.07534626038781164\n",
            "Recall: 0.2\n",
            "F1-Score: 0.10945674044265594\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_104 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_105 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 18ms/step - loss: 1.8712 - mae: 1.0768\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.0412 - mae: 0.8322\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9762 - mae: 0.8164\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9739 - mae: 0.8121\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9547 - mae: 0.8053\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9417 - mae: 0.8012\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8639 - mae: 0.7656\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8373 - mae: 0.7440\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7509 - mae: 0.7071\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.7791 - mae: 0.7129\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6887 - mae: 0.6748\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6623 - mae: 0.6560\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6556 - mae: 0.6452\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5596 - mae: 0.6027\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5514 - mae: 0.6044\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5587 - mae: 0.6001\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4595 - mae: 0.5426\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5039 - mae: 0.5671\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5470 - mae: 0.5958\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4508 - mae: 0.5431\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4731 - mae: 0.5584\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4885 - mae: 0.5571\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4262 - mae: 0.5127\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4912 - mae: 0.5557\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4659 - mae: 0.5474\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4807 - mae: 0.5553\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4135 - mae: 0.5187\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4519 - mae: 0.5421\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4607 - mae: 0.5361\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3743 - mae: 0.4872\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4687 - mae: 0.5500\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4413 - mae: 0.5336\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4363 - mae: 0.5238\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4447 - mae: 0.5397\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4454 - mae: 0.5315\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.4367 - mae: 0.5333\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4061 - mae: 0.5101\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3888 - mae: 0.4963\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4297 - mae: 0.5280\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.3841 - mae: 0.4959\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4173 - mae: 0.5167\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.4533 - mae: 0.5381\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4089 - mae: 0.5136\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3953 - mae: 0.5025\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.3785 - mae: 0.4940\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4056 - mae: 0.5109\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.4126 - mae: 0.5140\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.4117 - mae: 0.5217\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3924 - mae: 0.5032\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.3993 - mae: 0.5040\n",
            "12/12 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45429362880886426\n",
            "Precision: 0.44964498212287457\n",
            "Recall: 0.39033747391037815\n",
            "F1-Score: 0.36982929508302637\n",
            "Cohen Kappa Score: 0.6800502916503494\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_52 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_53 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 14s 65ms/step - loss: 1.3885 - mae: 0.9408\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9817 - mae: 0.8156\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.9890 - mae: 0.8204\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9579 - mae: 0.8135\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.9140 - mae: 0.7794\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.8545 - mae: 0.7519\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.8061 - mae: 0.7235\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.6224 - mae: 0.6333\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5983 - mae: 0.6155\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5546 - mae: 0.6008\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5890 - mae: 0.6148\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4961 - mae: 0.5697\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5041 - mae: 0.5671\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5021 - mae: 0.5698\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.4632 - mae: 0.5489\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4437 - mae: 0.5395\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.4550 - mae: 0.5418\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.4197 - mae: 0.5197\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4364 - mae: 0.5313\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4315 - mae: 0.5249\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4447 - mae: 0.5341\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4439 - mae: 0.5301\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4317 - mae: 0.5303\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4119 - mae: 0.5197\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4205 - mae: 0.5242\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.4177 - mae: 0.5172\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4203 - mae: 0.5224\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4096 - mae: 0.5121\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3982 - mae: 0.5085\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3851 - mae: 0.4987\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3996 - mae: 0.5037\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.3728 - mae: 0.4837\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.3963 - mae: 0.5085\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.4030 - mae: 0.5113\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 0.3739 - mae: 0.4897\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.3685 - mae: 0.4871\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.4002 - mae: 0.5054\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.4045 - mae: 0.5136\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3879 - mae: 0.4968\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.3695 - mae: 0.4854\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.3820 - mae: 0.4915\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3682 - mae: 0.4890\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3776 - mae: 0.4944\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.3662 - mae: 0.4838\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3595 - mae: 0.4751\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.3572 - mae: 0.4797\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.3775 - mae: 0.4949\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.3486 - mae: 0.4730\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.3661 - mae: 0.4795\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.3765 - mae: 0.4919\n",
            "12/12 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.47645429362880887\n",
            "Precision: 0.44717333640871865\n",
            "Recall: 0.415030062810345\n",
            "F1-Score: 0.39700582498270365\n",
            "Cohen Kappa Score: 0.6976316971420942\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_50 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_51 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_25 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 18.2116 - mae: 3.2246 - mse: 18.2116\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.7334 - mae: 2.4065 - mse: 6.7334\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.01662049861495845\n",
            "Precision: 0.00332409972299169\n",
            "Recall: 0.2\n",
            "F1-Score: 0.0065395095367847406\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6481994459833795\n",
            "Precision: 0.5398731843987319\n",
            "Recall: 0.5037241193595874\n",
            "F1-Score: 0.5146582672898463\n",
            "Cohen Kappa Score: 0.7505619840801887\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.628808864265928\n",
            "Precision: 0.7131391944698796\n",
            "Recall: 0.5302015210996955\n",
            "F1-Score: 0.5602590145305733\n",
            "Cohen Kappa Score: 0.7537233429905466\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.5512465373961218\n",
            "Precision: 0.45180896846531526\n",
            "Recall: 0.5143354107404429\n",
            "F1-Score: 0.44887806143452497\n",
            "Cohen Kappa Score: 0.7298402929026152\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5706371191135734\n",
            "Precision: 0.46880175017929204\n",
            "Recall: 0.4405588212921415\n",
            "F1-Score: 0.44721801536579153\n",
            "Cohen Kappa Score: 0.6961929153379703\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3573407202216066\n",
            "Precision: 0.07146814404432132\n",
            "Recall: 0.2\n",
            "F1-Score: 0.10530612244897959\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 667.96907 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.632   |   0.510   | 0.505  |  0.506   |    0.753    |\n",
            "|           BiLSTM          |  0.654   |   0.528   | 0.531  |  0.529   |    0.804    |\n",
            "|            CNN            |  0.025   |   0.005   | 0.200  |  0.010   |    0.000    |\n",
            "|    Logistic Regression    |  0.662   |   0.542   | 0.521  |  0.528   |    0.794    |\n",
            "|  Random Forest Classifier |  0.695   |   0.771   | 0.621  |  0.654   |    0.813    |\n",
            "|    Adaboost Classifier    |  0.560   |   0.452   | 0.514  |  0.449   |    0.730    |\n",
            "|   K Neighbors Classifier  |  0.584   |   0.483   | 0.463  |  0.471   |    0.717    |\n",
            "| Support Vector Classifier |  0.382   |   0.076   | 0.200  |  0.111   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 6--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_108 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_109 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 19ms/step - loss: 2.1401 - mae: 1.1328\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9758 - mae: 0.7805\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.0332 - mae: 0.7970\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.0120 - mae: 0.7921\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9783 - mae: 0.7860\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.9663 - mae: 0.7724\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9677 - mae: 0.7707\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9613 - mae: 0.7725\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9239 - mae: 0.7635\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.8628 - mae: 0.7303\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8781 - mae: 0.7448\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8496 - mae: 0.7252\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8084 - mae: 0.7112\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8002 - mae: 0.7054\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7277 - mae: 0.6776\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7058 - mae: 0.6596\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7528 - mae: 0.6882\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6692 - mae: 0.6404\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6759 - mae: 0.6497\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6759 - mae: 0.6437\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6601 - mae: 0.6360\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6717 - mae: 0.6438\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.7363 - mae: 0.6820\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6015 - mae: 0.6099\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6493 - mae: 0.6283\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6819 - mae: 0.6515\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6419 - mae: 0.6290\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6190 - mae: 0.6161\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6458 - mae: 0.6244\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5816 - mae: 0.5997\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6510 - mae: 0.6311\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6313 - mae: 0.6244\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6086 - mae: 0.6111\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6084 - mae: 0.6129\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.5804 - mae: 0.5962\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6274 - mae: 0.6157\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5764 - mae: 0.5962\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.6139 - mae: 0.6114\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.6089 - mae: 0.6156\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5799 - mae: 0.5949\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5995 - mae: 0.5987\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5883 - mae: 0.5970\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5776 - mae: 0.5995\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.5817 - mae: 0.5927\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6140 - mae: 0.6137\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 0.5674 - mae: 0.5915\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.5553 - mae: 0.5810\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5734 - mae: 0.5916\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5764 - mae: 0.5912\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5616 - mae: 0.5866\n",
            "12/12 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5138888888888888\n",
            "Precision: 0.2917323047441221\n",
            "Recall: 0.3507441978947751\n",
            "F1-Score: 0.3113866857246006\n",
            "Cohen Kappa Score: 0.5266677093923516\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_54 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_55 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 10s 65ms/step - loss: 1.5179 - mae: 0.9623\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 1.0040 - mae: 0.7841\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 1.0085 - mae: 0.7861\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.9676 - mae: 0.7747\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 1.0036 - mae: 0.7815\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.8942 - mae: 0.7409\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9144 - mae: 0.7613\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.8148 - mae: 0.7169\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.7982 - mae: 0.7013\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.7396 - mae: 0.6760\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.7310 - mae: 0.6742\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6827 - mae: 0.6580\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6453 - mae: 0.6345\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6740 - mae: 0.6413\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6690 - mae: 0.6413\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.6295 - mae: 0.6289\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.6083 - mae: 0.6139\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.6128 - mae: 0.6158\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.5855 - mae: 0.6048\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.6240 - mae: 0.6282\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.5835 - mae: 0.6002\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.6103 - mae: 0.6155\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5844 - mae: 0.5970\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6214 - mae: 0.6226\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5806 - mae: 0.5943\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5892 - mae: 0.6089\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5754 - mae: 0.5960\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5559 - mae: 0.5807\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5524 - mae: 0.5767\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5639 - mae: 0.5857\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5714 - mae: 0.5919\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5646 - mae: 0.5835\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5545 - mae: 0.5799\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5641 - mae: 0.5860\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5530 - mae: 0.5838\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5605 - mae: 0.5826\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.5521 - mae: 0.5813\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5471 - mae: 0.5714\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.5747 - mae: 0.5945\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5456 - mae: 0.5772\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5581 - mae: 0.5897\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5425 - mae: 0.5713\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5575 - mae: 0.5846\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5661 - mae: 0.5881\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5562 - mae: 0.5794\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5400 - mae: 0.5769\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5443 - mae: 0.5757\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5276 - mae: 0.5657\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5399 - mae: 0.5731\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5494 - mae: 0.5780\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.4888888888888889\n",
            "Precision: 0.2924372320881813\n",
            "Recall: 0.34548824186505345\n",
            "F1-Score: 0.3133429498486895\n",
            "Cohen Kappa Score: 0.5957936247124548\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_52 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_53 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_26 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 18ms/step - loss: 9.2475 - mae: 2.8607 - mse: 9.2475\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4757 - mae: 2.7451 - mse: 8.4757\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.027777777777777776\n",
            "Precision: 0.005555555555555555\n",
            "Recall: 0.2\n",
            "F1-Score: 0.010810810810810811\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5944444444444444\n",
            "Precision: 0.4455026383235339\n",
            "Recall: 0.40264120666970094\n",
            "F1-Score: 0.41249207994378045\n",
            "Cohen Kappa Score: 0.6346601334659108\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6083333333333333\n",
            "Precision: 0.6095400943396225\n",
            "Recall: 0.4834286730847772\n",
            "F1-Score: 0.5149130539223419\n",
            "Cohen Kappa Score: 0.694736044264221\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4166666666666667\n",
            "Precision: 0.43395879323031644\n",
            "Recall: 0.4903767879891682\n",
            "F1-Score: 0.42968956339012915\n",
            "Cohen Kappa Score: 0.6269989339019191\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.55\n",
            "Precision: 0.5199506079027356\n",
            "Recall: 0.4424403622487631\n",
            "F1-Score: 0.46552383413038684\n",
            "Cohen Kappa Score: 0.5610412423149514\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45\n",
            "Precision: 0.09\n",
            "Recall: 0.2\n",
            "F1-Score: 0.12413793103448276\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_112 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_113 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 20ms/step - loss: 2.0465 - mae: 1.0964\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.0006 - mae: 0.7965\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.0441 - mae: 0.8091\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9922 - mae: 0.7906\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9816 - mae: 0.7907\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9926 - mae: 0.7873\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9571 - mae: 0.7768\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9729 - mae: 0.7776\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9264 - mae: 0.7576\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9134 - mae: 0.7517\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8655 - mae: 0.7280\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8325 - mae: 0.7192\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.8373 - mae: 0.7169\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8499 - mae: 0.7333\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7741 - mae: 0.6969\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7713 - mae: 0.6967\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7538 - mae: 0.6860\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6469 - mae: 0.6257\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7081 - mae: 0.6547\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7011 - mae: 0.6638\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6226 - mae: 0.6237\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6577 - mae: 0.6444\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6449 - mae: 0.6375\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6482 - mae: 0.6362\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6682 - mae: 0.6406\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6070 - mae: 0.6091\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6372 - mae: 0.6318\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6315 - mae: 0.6301\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6098 - mae: 0.6170\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6199 - mae: 0.6249\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5851 - mae: 0.6045\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6038 - mae: 0.6113\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5812 - mae: 0.5996\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5849 - mae: 0.6034\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5846 - mae: 0.6012\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5948 - mae: 0.6121\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5833 - mae: 0.5992\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5945 - mae: 0.6062\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5783 - mae: 0.5964\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.5308 - mae: 0.5671\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6303 - mae: 0.6225\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5779 - mae: 0.6023\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5818 - mae: 0.5993\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.5779 - mae: 0.5964\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5759 - mae: 0.5899\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5540 - mae: 0.5839\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5617 - mae: 0.5884\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5523 - mae: 0.5837\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5755 - mae: 0.5951\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.5774 - mae: 0.5904\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5138888888888888\n",
            "Precision: 0.4437719349037549\n",
            "Recall: 0.35273877887632354\n",
            "F1-Score: 0.3434814769983928\n",
            "Cohen Kappa Score: 0.5657747529367891\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_56 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_57 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 11s 30ms/step - loss: 1.4528 - mae: 0.9386\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 1.0358 - mae: 0.8111\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9788 - mae: 0.7912\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9688 - mae: 0.7798\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.9911 - mae: 0.7879\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9413 - mae: 0.7711\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9086 - mae: 0.7530\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.8310 - mae: 0.7175\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.7754 - mae: 0.6942\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.7439 - mae: 0.6719\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.7145 - mae: 0.6627\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.6581 - mae: 0.6433\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.6753 - mae: 0.6433\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.6170 - mae: 0.6187\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.6516 - mae: 0.6359\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.6325 - mae: 0.6203\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6326 - mae: 0.6234\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6171 - mae: 0.6162\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.6055 - mae: 0.6096\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5855 - mae: 0.6051\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6080 - mae: 0.6128\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5955 - mae: 0.6052\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5588 - mae: 0.5818\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6240 - mae: 0.6235\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5547 - mae: 0.5833\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5978 - mae: 0.6074\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5814 - mae: 0.5946\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5772 - mae: 0.5957\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5887 - mae: 0.5921\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.5538 - mae: 0.5832\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 58ms/step - loss: 0.5404 - mae: 0.5755\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.5533 - mae: 0.5776\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.5588 - mae: 0.5873\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.5531 - mae: 0.5857\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5584 - mae: 0.5854\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5548 - mae: 0.5803\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5198 - mae: 0.5656\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5659 - mae: 0.5925\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5603 - mae: 0.5844\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5746 - mae: 0.5907\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5526 - mae: 0.5807\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5458 - mae: 0.5805\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5575 - mae: 0.5869\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5280 - mae: 0.5693\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5435 - mae: 0.5768\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5475 - mae: 0.5815\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5563 - mae: 0.5802\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 65ms/step - loss: 0.5282 - mae: 0.5720\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.5279 - mae: 0.5647\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.5421 - mae: 0.5761\n",
            "12/12 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.575\n",
            "Precision: 0.4298883572567783\n",
            "Recall: 0.4186843613636292\n",
            "F1-Score: 0.41675169269996354\n",
            "Cohen Kappa Score: 0.6420290674659277\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_28 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_54 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_55 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_27 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 15ms/step - loss: 10.0517 - mae: 2.9375 - mse: 10.0517\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2465 - mae: 2.7007 - mse: 8.2465\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.016666666666666666\n",
            "Precision: 0.003333333333333333\n",
            "Recall: 0.2\n",
            "F1-Score: 0.006557377049180328\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5472222222222223\n",
            "Precision: 0.4113312674687083\n",
            "Recall: 0.37896539106860166\n",
            "F1-Score: 0.38905528662692335\n",
            "Cohen Kappa Score: 0.6033717558283356\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.5722222222222222\n",
            "Precision: 0.5802704706199353\n",
            "Recall: 0.49551666935246885\n",
            "F1-Score: 0.5279887115172854\n",
            "Cohen Kappa Score: 0.6555408765930991\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.475\n",
            "Precision: 0.3648530956223264\n",
            "Recall: 0.39076199052701754\n",
            "F1-Score: 0.34268118473902554\n",
            "Cohen Kappa Score: 0.553301350045459\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.49444444444444446\n",
            "Precision: 0.41305180774550926\n",
            "Recall: 0.41228985177531524\n",
            "F1-Score: 0.4023428779234406\n",
            "Cohen Kappa Score: 0.517685797582768\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.46111111111111114\n",
            "Precision: 0.09222222222222223\n",
            "Recall: 0.2\n",
            "F1-Score: 0.1262357414448669\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_116 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_117 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 20ms/step - loss: 2.0995 - mae: 1.1120\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.0433 - mae: 0.8151\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9864 - mae: 0.7875\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9744 - mae: 0.7823\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9968 - mae: 0.7877\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9794 - mae: 0.7950\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9585 - mae: 0.7744\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9436 - mae: 0.7707\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9119 - mae: 0.7512\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8970 - mae: 0.7466\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.8453 - mae: 0.7402\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8693 - mae: 0.7433\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8385 - mae: 0.7187\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.7992 - mae: 0.7117\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.7688 - mae: 0.6992\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.7539 - mae: 0.6836\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7303 - mae: 0.6807\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.6516 - mae: 0.6398\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.7197 - mae: 0.6728\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.7093 - mae: 0.6694\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6781 - mae: 0.6584\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6294 - mae: 0.6270\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.6858 - mae: 0.6577\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6352 - mae: 0.6296\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.6351 - mae: 0.6301\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.6265 - mae: 0.6210\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.6035\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6731 - mae: 0.6566\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5876 - mae: 0.6046\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.6479 - mae: 0.6372\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5620 - mae: 0.5841\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5915 - mae: 0.6076\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6158 - mae: 0.6230\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5827 - mae: 0.5999\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6162 - mae: 0.6176\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5574 - mae: 0.5859\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5786 - mae: 0.5989\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6118 - mae: 0.6180\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6090 - mae: 0.6125\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5511 - mae: 0.5820\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6018 - mae: 0.6133\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5572 - mae: 0.5897\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5919 - mae: 0.6086\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5501 - mae: 0.5804\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5913 - mae: 0.6096\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5900 - mae: 0.6025\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5685 - mae: 0.5883\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5647 - mae: 0.5888\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5689 - mae: 0.5979\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5664 - mae: 0.5936\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5111111111111111\n",
            "Precision: 0.2957361387465955\n",
            "Recall: 0.3416559691912709\n",
            "F1-Score: 0.30130632438292493\n",
            "Cohen Kappa Score: 0.4890510948905109\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_58 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_59 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 13s 30ms/step - loss: 1.5098 - mae: 0.9500\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 1.0464 - mae: 0.8170\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.9940 - mae: 0.7943\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9752 - mae: 0.7848\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9520 - mae: 0.7672\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9348 - mae: 0.7660\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.9603 - mae: 0.7712\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.8847 - mae: 0.7505\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.8397 - mae: 0.7294\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.8024 - mae: 0.7083\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7252 - mae: 0.6736\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.7408 - mae: 0.6742\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6429 - mae: 0.6293\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.6731 - mae: 0.6542\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6691 - mae: 0.6400\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6211 - mae: 0.6281\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6206 - mae: 0.6161\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.6172 - mae: 0.6253\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6074 - mae: 0.6131\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5922 - mae: 0.6077\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5935 - mae: 0.6005\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5868 - mae: 0.6055\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5794 - mae: 0.6010\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5806 - mae: 0.5989\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.5780 - mae: 0.5983\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.5815 - mae: 0.5962\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.5570 - mae: 0.5837\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 2s 74ms/step - loss: 0.5550 - mae: 0.5887\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.5548 - mae: 0.5826\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5890 - mae: 0.6002\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5660 - mae: 0.5953\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5683 - mae: 0.5926\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5598 - mae: 0.5900\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5501 - mae: 0.5841\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5510 - mae: 0.5797\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5369 - mae: 0.5762\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5404 - mae: 0.5786\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5773 - mae: 0.5921\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5570 - mae: 0.5874\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.5441 - mae: 0.5772\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5286 - mae: 0.5763\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.5543 - mae: 0.5847\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.5421 - mae: 0.5763\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.5447 - mae: 0.5805\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.5479 - mae: 0.5841\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.5379 - mae: 0.5788\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.5376 - mae: 0.5735\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5289 - mae: 0.5665\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5319 - mae: 0.5755\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5119 - mae: 0.5582\n",
            "12/12 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.45\n",
            "Precision: 0.2472530179847253\n",
            "Recall: 0.3530499690961822\n",
            "F1-Score: 0.2898155433167235\n",
            "Cohen Kappa Score: 0.5486725663716814\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_29 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_56 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_28 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_57 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_28 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 19.2648 - mae: 3.4871 - mse: 19.2648\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2590 - mae: 2.7062 - mse: 8.2590\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.030555555555555555\n",
            "Precision: 0.0061111111111111106\n",
            "Recall: 0.2\n",
            "F1-Score: 0.011859838274932616\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5694444444444444\n",
            "Precision: 0.41127946127946124\n",
            "Recall: 0.3820187324680264\n",
            "F1-Score: 0.3890349988356239\n",
            "Cohen Kappa Score: 0.6248064839267826\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6222222222222222\n",
            "Precision: 0.5736150229255923\n",
            "Recall: 0.501948021075107\n",
            "F1-Score: 0.5280539055441261\n",
            "Cohen Kappa Score: 0.6769808907012074\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4027777777777778\n",
            "Precision: 0.3391311033752894\n",
            "Recall: 0.400929923972286\n",
            "F1-Score: 0.3266788255405774\n",
            "Cohen Kappa Score: 0.6508702572264722\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5194444444444445\n",
            "Precision: 0.47282401479584574\n",
            "Recall: 0.39097543686760633\n",
            "F1-Score: 0.41382493328823244\n",
            "Cohen Kappa Score: 0.5293920616312175\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45555555555555555\n",
            "Precision: 0.09111111111111111\n",
            "Recall: 0.2\n",
            "F1-Score: 0.1251908396946565\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_120 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_121 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 5s 18ms/step - loss: 2.1296 - mae: 1.1345\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9880 - mae: 0.7873\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9686 - mae: 0.7746\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9740 - mae: 0.7876\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9810 - mae: 0.7959\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9519 - mae: 0.7756\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9527 - mae: 0.7776\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9150 - mae: 0.7571\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9251 - mae: 0.7513\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8948 - mae: 0.7474\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8487 - mae: 0.7351\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8461 - mae: 0.7286\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8058 - mae: 0.7061\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7774 - mae: 0.6935\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7109 - mae: 0.6641\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6840 - mae: 0.6510\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7395 - mae: 0.6778\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7152 - mae: 0.6757\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6676 - mae: 0.6450\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6839 - mae: 0.6529\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6999 - mae: 0.6593\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6002 - mae: 0.6059\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6723 - mae: 0.6461\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6435 - mae: 0.6377\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6219 - mae: 0.6200\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6142 - mae: 0.6140\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.6141 - mae: 0.6175\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.5685 - mae: 0.5957\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.6336 - mae: 0.6281\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.5796 - mae: 0.5937\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.5665 - mae: 0.5975\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6039 - mae: 0.6213\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5927 - mae: 0.6009\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5766 - mae: 0.5967\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6059 - mae: 0.6175\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5629 - mae: 0.5888\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5933 - mae: 0.6045\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.5555 - mae: 0.5857\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.5866 - mae: 0.6036\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 0.5600 - mae: 0.5922\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.5340 - mae: 0.5733\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5790 - mae: 0.5947\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5616 - mae: 0.5882\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5462 - mae: 0.5824\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5351 - mae: 0.5759\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5307 - mae: 0.5714\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5856 - mae: 0.6026\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5375 - mae: 0.5763\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5807 - mae: 0.5974\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5431 - mae: 0.5820\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5333333333333333\n",
            "Precision: 0.4239127911907408\n",
            "Recall: 0.3743938251748874\n",
            "F1-Score: 0.3775625385911564\n",
            "Cohen Kappa Score: 0.5999532109018599\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_60 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_61 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 14s 35ms/step - loss: 1.4579 - mae: 0.9380\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.0326 - mae: 0.8057\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.9928 - mae: 0.7880\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.9889 - mae: 0.7857\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.9655 - mae: 0.7775\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.9500 - mae: 0.7781\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.9172 - mae: 0.7575\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.8652 - mae: 0.7425\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.8264 - mae: 0.7184\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.8173 - mae: 0.7146\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.7003 - mae: 0.6508\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.7230 - mae: 0.6709\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.6639 - mae: 0.6431\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6699 - mae: 0.6439\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6575 - mae: 0.6346\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5948 - mae: 0.6104\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.6430 - mae: 0.6306\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5992 - mae: 0.6127\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5937 - mae: 0.6133\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5949 - mae: 0.6126\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5840 - mae: 0.6037\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5830 - mae: 0.6006\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 0.5798 - mae: 0.6023\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 0.5585 - mae: 0.5915\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.5533 - mae: 0.5867\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.5561 - mae: 0.5817\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.5846 - mae: 0.6034\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5348 - mae: 0.5723\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5647 - mae: 0.5886\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5487 - mae: 0.5828\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5485 - mae: 0.5833\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5451 - mae: 0.5794\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5546 - mae: 0.5847\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5453 - mae: 0.5852\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5498 - mae: 0.5804\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5402 - mae: 0.5768\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5356 - mae: 0.5765\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5406 - mae: 0.5752\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5239 - mae: 0.5688\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.5555 - mae: 0.5813\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 0.5119 - mae: 0.5625\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 74ms/step - loss: 0.5441 - mae: 0.5805\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 66ms/step - loss: 0.5329 - mae: 0.5688\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.5173 - mae: 0.5603\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5208 - mae: 0.5683\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5218 - mae: 0.5611\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5248 - mae: 0.5660\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5079 - mae: 0.5590\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5123 - mae: 0.5639\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5262 - mae: 0.5638\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.5444444444444444\n",
            "Precision: 0.4619487672494943\n",
            "Recall: 0.3330053659301436\n",
            "F1-Score: 0.3246271234760444\n",
            "Cohen Kappa Score: 0.5156576200417535\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_30 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_58 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_59 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_29 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 16.5724 - mae: 3.3703 - mse: 16.5724\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3167 - mae: 2.7181 - mse: 8.3167\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.025\n",
            "Precision: 0.005\n",
            "Recall: 0.2\n",
            "F1-Score: 0.009756097560975611\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.5944444444444444\n",
            "Precision: 0.4651325110806573\n",
            "Recall: 0.4072793700287091\n",
            "F1-Score: 0.42154982829142834\n",
            "Cohen Kappa Score: 0.5938289031591085\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.6083333333333333\n",
            "Precision: 0.6737201979307244\n",
            "Recall: 0.4746635253003914\n",
            "F1-Score: 0.5123223328395743\n",
            "Cohen Kappa Score: 0.6624751819986764\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.46944444444444444\n",
            "Precision: 0.2214930907707911\n",
            "Recall: 0.335520307618361\n",
            "F1-Score: 0.24296438064859113\n",
            "Cohen Kappa Score: 0.5395428157999002\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.49722222222222223\n",
            "Precision: 0.473449486258001\n",
            "Recall: 0.4130902814152034\n",
            "F1-Score: 0.4285753528813019\n",
            "Cohen Kappa Score: 0.5193253689388615\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45\n",
            "Precision: 0.09\n",
            "Recall: 0.2\n",
            "F1-Score: 0.12413793103448276\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_124 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_125 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 35ms/step - loss: 2.1418 - mae: 1.1380\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.0629 - mae: 0.8170\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1.0018 - mae: 0.7900\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.9814 - mae: 0.7777\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1.0230 - mae: 0.7935\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9558 - mae: 0.7709\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9412 - mae: 0.7669\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.9696 - mae: 0.7800\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9232 - mae: 0.7618\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.9260 - mae: 0.7567\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8476 - mae: 0.7255\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8876 - mae: 0.7409\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7632 - mae: 0.6844\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8788 - mae: 0.7475\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7910 - mae: 0.7012\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7288 - mae: 0.6719\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7527 - mae: 0.6823\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6561 - mae: 0.6364\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7002 - mae: 0.6561\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7363 - mae: 0.6781\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6691 - mae: 0.6421\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6459 - mae: 0.6345\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6608 - mae: 0.6447\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6341 - mae: 0.6291\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6768 - mae: 0.6509\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6284 - mae: 0.6285\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6453 - mae: 0.6315\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6547 - mae: 0.6383\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5662 - mae: 0.5920\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6523 - mae: 0.6350\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6374 - mae: 0.6299\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6025 - mae: 0.6116\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5980 - mae: 0.6095\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6113 - mae: 0.6103\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.6075\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6236 - mae: 0.6184\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6117 - mae: 0.6174\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5753 - mae: 0.5981\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6346 - mae: 0.6268\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5561 - mae: 0.5849\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5982 - mae: 0.6022\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6139 - mae: 0.6174\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5567 - mae: 0.5817\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5588 - mae: 0.5884\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5891 - mae: 0.6149\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.6040 - mae: 0.6089\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5760 - mae: 0.5947\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5780 - mae: 0.6011\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.5962 - mae: 0.6080\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.5832 - mae: 0.5980\n",
            "12/12 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4861111111111111\n",
            "Precision: 0.2703558491442365\n",
            "Recall: 0.3610103033424027\n",
            "F1-Score: 0.3066609628215856\n",
            "Cohen Kappa Score: 0.5888166062472067\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_62 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_63 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 10s 33ms/step - loss: 1.5115 - mae: 0.9555\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 1.0214 - mae: 0.8003\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 1.0210 - mae: 0.8010\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.9873 - mae: 0.7878\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.9455 - mae: 0.7756\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.9657 - mae: 0.7772\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.9150 - mae: 0.7522\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 60ms/step - loss: 0.8397 - mae: 0.7254\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.8081 - mae: 0.7052\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.7294 - mae: 0.6649\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.7101 - mae: 0.6680\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.7119 - mae: 0.6637\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6686 - mae: 0.6430\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.6518 - mae: 0.6393\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6559 - mae: 0.6378\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6096 - mae: 0.6194\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6328 - mae: 0.6289\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.6389 - mae: 0.6202\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5749 - mae: 0.5964\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5962 - mae: 0.6076\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.6113 - mae: 0.6179\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.6198 - mae: 0.6220\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.5802 - mae: 0.6018\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 0.5752 - mae: 0.5934\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.5633 - mae: 0.5868\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.5941 - mae: 0.6016\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5683 - mae: 0.5940\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5769 - mae: 0.5926\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5544 - mae: 0.5822\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5660 - mae: 0.5898\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5534 - mae: 0.5779\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6033 - mae: 0.6124\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5749 - mae: 0.5897\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5588 - mae: 0.5894\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5611 - mae: 0.5886\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5377 - mae: 0.5713\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5568 - mae: 0.5886\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.5744 - mae: 0.5949\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.5428 - mae: 0.5768\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.5548 - mae: 0.5859\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 0.5343 - mae: 0.5729\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5443 - mae: 0.5783\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.5445 - mae: 0.5697\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.5495 - mae: 0.5792\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5447 - mae: 0.5717\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.5165 - mae: 0.5620\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5387 - mae: 0.5714\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.5413 - mae: 0.5792\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5220 - mae: 0.5641\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5411 - mae: 0.5753\n",
            "12/12 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.5222222222222223\n",
            "Precision: 0.4142142923892293\n",
            "Recall: 0.3981778174086958\n",
            "F1-Score: 0.3891926049563048\n",
            "Cohen Kappa Score: 0.6303864948911595\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_31 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_60 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_30 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_61 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_30 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 16ms/step - loss: 21.6974 - mae: 3.5970 - mse: 21.6974\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4021 - mae: 2.7299 - mse: 8.4021\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.022222222222222223\n",
            "Precision: 0.0044444444444444444\n",
            "Recall: 0.2\n",
            "F1-Score: 0.008695652173913045\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.6194444444444445\n",
            "Precision: 0.4847438052143934\n",
            "Recall: 0.4240536162577855\n",
            "F1-Score: 0.44088229126338885\n",
            "Cohen Kappa Score: 0.6453391872356373\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.5916666666666667\n",
            "Precision: 0.4672725422089902\n",
            "Recall: 0.425506166609346\n",
            "F1-Score: 0.4397945670022132\n",
            "Cohen Kappa Score: 0.6683603210028966\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.4027777777777778\n",
            "Precision: 0.35144285799631503\n",
            "Recall: 0.4323149424329788\n",
            "F1-Score: 0.3488522244054078\n",
            "Cohen Kappa Score: 0.5819243774976944\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.5027777777777778\n",
            "Precision: 0.44466082542060353\n",
            "Recall: 0.39181704892112446\n",
            "F1-Score: 0.41081220104513605\n",
            "Cohen Kappa Score: 0.572006160954948\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4527777777777778\n",
            "Precision: 0.09055555555555556\n",
            "Recall: 0.2\n",
            "F1-Score: 0.12466539196940726\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 617.28924 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.533   |   0.444   | 0.374  |  0.378   |    0.600    |\n",
            "|           BiLSTM          |  0.575   |   0.462   | 0.419  |  0.417   |    0.642    |\n",
            "|            CNN            |  0.031   |   0.006   | 0.200  |  0.012   |    0.000    |\n",
            "|    Logistic Regression    |  0.619   |   0.485   | 0.424  |  0.441   |    0.645    |\n",
            "|  Random Forest Classifier |  0.622   |   0.674   | 0.502  |  0.528   |    0.695    |\n",
            "|    Adaboost Classifier    |  0.475   |   0.434   | 0.490  |  0.430   |    0.651    |\n",
            "|   K Neighbors Classifier  |  0.550   |   0.520   | 0.442  |  0.466   |    0.572    |\n",
            "| Support Vector Classifier |  0.461   |   0.092   | 0.200  |  0.126   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 7--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_128 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_129 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 8s 24ms/step - loss: 141.2196 - mae: 10.5244\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 36.6526 - mae: 5.0799\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 28.2609 - mae: 4.4249\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 25.0732 - mae: 4.1306\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 22.6658 - mae: 3.8950\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 21.9362 - mae: 3.7888\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.7399 - mae: 3.7704\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 22.0188 - mae: 3.7850\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 22.0039 - mae: 3.7246\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.3855 - mae: 3.7189\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.5954 - mae: 3.7254\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.5369 - mae: 3.7006\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.7220 - mae: 3.7550\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.8839 - mae: 3.7613\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 21.7278 - mae: 3.7536\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.2664 - mae: 3.7131\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.3940 - mae: 3.7139\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.3584 - mae: 3.7346\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.4563 - mae: 3.7172\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.7545 - mae: 3.7474\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 21.1381 - mae: 3.6950\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 20.6093 - mae: 3.6522\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 20.4368 - mae: 3.6521\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 18.9964 - mae: 3.5277\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.1781 - mae: 3.5036\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 18.5855 - mae: 3.4930\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 16.7825 - mae: 3.3273\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 17.7899 - mae: 3.4070\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 16.3791 - mae: 3.2484\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.4759 - mae: 3.2802\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 14.6522 - mae: 3.1124\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 14.9491 - mae: 3.1114\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.9537 - mae: 3.1314\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.8949 - mae: 3.1539\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.0859 - mae: 3.1327\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.7052 - mae: 3.0690\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.7260 - mae: 3.0876\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 14.5013 - mae: 3.0775\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 13.7000 - mae: 3.0193\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 15.0447 - mae: 3.1525\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 12.9508 - mae: 2.9425\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.8084 - mae: 2.9725\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 14.3013 - mae: 3.0693\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 13.5370 - mae: 3.0010\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 13.0771 - mae: 2.9183\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 14.1996 - mae: 3.0564\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 14.2482 - mae: 3.0615\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.5261 - mae: 3.0226\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 13.7566 - mae: 2.9806\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.5893 - mae: 2.9978\n",
            "10/10 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.08917197452229299\n",
            "Precision: 0.03193153886878453\n",
            "Recall: 0.06174751174751175\n",
            "F1-Score: 0.037266039895455974\n",
            "Cohen Kappa Score: 0.4372748729731566\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_64 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_65 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 12s 34ms/step - loss: 64.0030 - mae: 6.1308\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 21.4256 - mae: 3.6985\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 21.1110 - mae: 3.6887\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 21.3939 - mae: 3.7132\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 20.9399 - mae: 3.6702\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 20.7131 - mae: 3.6501\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 19.5913 - mae: 3.5839\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 18.7892 - mae: 3.5062\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 17.3394 - mae: 3.3475\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 16.2513 - mae: 3.2612\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 15.3228 - mae: 3.1423\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 65ms/step - loss: 15.3285 - mae: 3.1456\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 14.4744 - mae: 3.0703\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 14.6919 - mae: 3.0986\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 14.3928 - mae: 3.0938\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 13.5234 - mae: 2.9810\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 13.3067 - mae: 2.9484\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 14.1448 - mae: 3.0359\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 13.8314 - mae: 3.0128\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.7786 - mae: 2.9631\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.6926 - mae: 2.9030\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.6617 - mae: 2.9725\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 13.1494 - mae: 2.9283\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.3446 - mae: 2.8491\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.2616 - mae: 2.9272\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.0250 - mae: 2.9075\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.5962 - mae: 2.8374\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.5468 - mae: 2.8531\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.8485 - mae: 2.8997\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 48ms/step - loss: 12.9175 - mae: 2.8728\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 12.7731 - mae: 2.8926\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 13.1019 - mae: 2.9337\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 12.1779 - mae: 2.8279\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 72ms/step - loss: 12.6986 - mae: 2.8640\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 12.3384 - mae: 2.8318\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.4876 - mae: 2.8526\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.3762 - mae: 2.8587\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.4857 - mae: 2.8313\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.7468 - mae: 2.8845\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.6622 - mae: 2.8729\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.4431 - mae: 2.8620\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.2049 - mae: 2.8260\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.7637 - mae: 2.8589\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 12.0645 - mae: 2.7979\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.7964 - mae: 2.8508\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.2949 - mae: 2.8392\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.2845 - mae: 2.8379\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 12.1933 - mae: 2.8030\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 44ms/step - loss: 12.5588 - mae: 2.8371\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 12.5450 - mae: 2.8512\n",
            "10/10 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.10828025477707007\n",
            "Precision: 0.05603125994202057\n",
            "Recall: 0.07844536415964985\n",
            "F1-Score: 0.06349821750085886\n",
            "Cohen Kappa Score: 0.666054598927029\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_32 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_62 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_31 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_63 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_31 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 2s 34ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 278.8645 - mae: 16.0582 - mse: 278.8645\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.1592356687898089\n",
            "Precision: 0.09627785917324351\n",
            "Recall: 0.09751452251452251\n",
            "F1-Score: 0.0747443713954002\n",
            "Cohen Kappa Score: 0.5874321888705123\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.13694267515923567\n",
            "Precision: 0.09822116617209653\n",
            "Recall: 0.0964737643309072\n",
            "F1-Score: 0.08082392752529463\n",
            "Cohen Kappa Score: 0.6704121599236983\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.13694267515923567\n",
            "Precision: 0.03694623341139734\n",
            "Recall: 0.07817460317460317\n",
            "F1-Score: 0.03159820890381469\n",
            "Cohen Kappa Score: 0.3849444335177924\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.08280254777070063\n",
            "Precision: 0.06273836819432527\n",
            "Recall: 0.06229061342697706\n",
            "F1-Score: 0.058735641478194774\n",
            "Cohen Kappa Score: 0.4811641518664108\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11464968152866242\n",
            "Precision: 0.00545950864422202\n",
            "Recall: 0.047619047619047616\n",
            "F1-Score: 0.009795918367346938\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_132 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_133 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 21ms/step - loss: 143.0998 - mae: 10.5129\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 35.2696 - mae: 4.9475\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 27.5403 - mae: 4.3606\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.8904 - mae: 4.0239\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 22.8454 - mae: 3.9096\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 22.0450 - mae: 3.8025\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.8508 - mae: 3.7780\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 21.8816 - mae: 3.7462\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.2805 - mae: 3.7089\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 21.8055 - mae: 3.7341\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.5237 - mae: 3.7292\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 21.5196 - mae: 3.7494\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 22.0363 - mae: 3.7675\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 21.6563 - mae: 3.7459\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 21.6317 - mae: 3.7202\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 21.6686 - mae: 3.7314\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 21.6101 - mae: 3.7506\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 21.5846 - mae: 3.7225\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 21.3565 - mae: 3.7244\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 21.1792 - mae: 3.6965\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 20.4027 - mae: 3.6386\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 20.4771 - mae: 3.6461\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 19.0493 - mae: 3.5315\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 17.9551 - mae: 3.4200\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 18.1717 - mae: 3.4586\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 17.2137 - mae: 3.3477\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 16.0543 - mae: 3.2637\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 16.2939 - mae: 3.2787\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.9970 - mae: 3.1980\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 14.6933 - mae: 3.0962\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.1699 - mae: 3.1305\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.4953 - mae: 3.2688\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 15.0268 - mae: 3.1176\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.8955 - mae: 3.0330\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 13.4222 - mae: 2.9470\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 14.0744 - mae: 3.0108\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.1945 - mae: 3.0481\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 14.1998 - mae: 3.0440\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.4265 - mae: 3.0818\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.4138 - mae: 2.8634\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.9332 - mae: 3.1509\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 13.4322 - mae: 2.9451\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 14.3107 - mae: 3.0859\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 13.5472 - mae: 2.9869\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 14.1096 - mae: 3.0607\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 12.7357 - mae: 2.8751\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 13.6587 - mae: 3.0062\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 13.3301 - mae: 2.9536\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.5861 - mae: 2.9698\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 12.5944 - mae: 2.9073\n",
            "10/10 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1305732484076433\n",
            "Precision: 0.06354602051409994\n",
            "Recall: 0.09176241886768202\n",
            "F1-Score: 0.06165426202292969\n",
            "Cohen Kappa Score: 0.4723658488309984\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_66 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_67 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_104 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 13s 65ms/step - loss: 71.4021 - mae: 6.5156\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 21.8156 - mae: 3.7586\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 64ms/step - loss: 21.6557 - mae: 3.7378\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 21.0439 - mae: 3.6879\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 21.6047 - mae: 3.7352\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 21.0488 - mae: 3.6927\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 19.9437 - mae: 3.5804\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 18.8558 - mae: 3.5099\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 18.2186 - mae: 3.4356\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 16.9736 - mae: 3.3208\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 15.6083 - mae: 3.2078\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 14.8238 - mae: 3.1279\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 15.3702 - mae: 3.1267\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.7682 - mae: 3.0082\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 14.6482 - mae: 3.1006\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.5349 - mae: 2.9642\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 13.2146 - mae: 2.9457\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.0717 - mae: 2.9091\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 12.9766 - mae: 2.9387\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 13.8952 - mae: 2.9927\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 13.3198 - mae: 2.9498\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 72ms/step - loss: 12.6165 - mae: 2.8804\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 13.0541 - mae: 2.9209\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 13.2404 - mae: 2.9446\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.1455 - mae: 2.9239\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.5279 - mae: 2.8727\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.3716 - mae: 2.8125\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.6672 - mae: 2.8379\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.3678 - mae: 2.8183\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.0800 - mae: 2.8225\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.2597 - mae: 2.8325\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.4007 - mae: 2.8502\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.3973 - mae: 2.8644\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.0611 - mae: 2.8990\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 11.9258 - mae: 2.8005\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.3529 - mae: 2.8439\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.0384 - mae: 2.7914\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 12.0611 - mae: 2.8094\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 11.9695 - mae: 2.8202\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 11.7878 - mae: 2.7796\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 64ms/step - loss: 12.3906 - mae: 2.8327\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 64ms/step - loss: 11.6290 - mae: 2.7597\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 12.3692 - mae: 2.8336\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 11.9193 - mae: 2.7927\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.3273 - mae: 2.8318\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.0540 - mae: 2.8240\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.2934 - mae: 2.8140\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.0349 - mae: 2.8084\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.0080 - mae: 2.7896\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 11.7582 - mae: 2.7741\n",
            "10/10 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.1305732484076433\n",
            "Precision: 0.07852803335879768\n",
            "Recall: 0.10264051909562744\n",
            "F1-Score: 0.08637494984760666\n",
            "Cohen Kappa Score: 0.6351086241970298\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_33 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_64 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_32 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_65 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_32 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 2s 17ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 282.1602 - mae: 16.1602 - mse: 282.1602\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.16560509554140126\n",
            "Precision: 0.06992454791367834\n",
            "Recall: 0.10253756047873695\n",
            "F1-Score: 0.07595836040564534\n",
            "Cohen Kappa Score: 0.5412493161460132\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.20382165605095542\n",
            "Precision: 0.18947913477147008\n",
            "Recall: 0.1496849786411927\n",
            "F1-Score: 0.13314866617387625\n",
            "Cohen Kappa Score: 0.6269313987789691\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.16878980891719744\n",
            "Precision: 0.015285763428178289\n",
            "Recall: 0.07986394557823129\n",
            "F1-Score: 0.02558991767624861\n",
            "Cohen Kappa Score: 0.40644324371015594\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.07961783439490445\n",
            "Precision: 0.047388395448740274\n",
            "Recall: 0.050270370871271515\n",
            "F1-Score: 0.04721822645020137\n",
            "Cohen Kappa Score: 0.4916071399565112\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1592356687898089\n",
            "Precision: 0.0075826508947528055\n",
            "Recall: 0.047619047619047616\n",
            "F1-Score: 0.013082155939298795\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_136 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_137 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_105 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 18ms/step - loss: 146.8570 - mae: 10.6612\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 38.3000 - mae: 5.1796\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 29.0889 - mae: 4.4645\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 25.6867 - mae: 4.1827\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 23.3063 - mae: 3.9399\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 21.8667 - mae: 3.8048\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21.7882 - mae: 3.7794\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 21.2622 - mae: 3.7152\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.6499 - mae: 3.7278\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.4975 - mae: 3.7231\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.0304 - mae: 3.6904\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 21.5551 - mae: 3.7339\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 21.3052 - mae: 3.7158\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.4695 - mae: 3.7263\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.1040 - mae: 3.6923\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.0581 - mae: 3.6841\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.6752 - mae: 3.7421\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21.4553 - mae: 3.7215\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.4762 - mae: 3.7268\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 20.7978 - mae: 3.6619\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 20.7226 - mae: 3.6564\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 20.5088 - mae: 3.6476\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 19.5394 - mae: 3.5626\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 19.2693 - mae: 3.5706\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 17.8714 - mae: 3.4272\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.5335 - mae: 3.3906\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 18.0002 - mae: 3.4430\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.9324 - mae: 3.2399\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 15.9441 - mae: 3.2235\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.1919 - mae: 3.2794\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.3864 - mae: 3.0911\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 14.7315 - mae: 3.1241\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.2156 - mae: 3.1764\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 13.3538 - mae: 2.9829\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 13.7909 - mae: 3.0329\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.7915 - mae: 3.1169\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.3260 - mae: 3.0918\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.5373 - mae: 3.1240\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.0823 - mae: 3.0568\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.8260 - mae: 3.0010\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.0153 - mae: 3.0499\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 13.1194 - mae: 2.9507\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 13.5244 - mae: 2.9986\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 12.9699 - mae: 2.9306\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 13.1497 - mae: 2.9736\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 13.4345 - mae: 2.9882\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 12.7981 - mae: 2.9196\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 12.8045 - mae: 2.9001\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 13.2717 - mae: 2.9774\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.4684 - mae: 2.9882\n",
            "10/10 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.08917197452229299\n",
            "Precision: 0.02741671744331319\n",
            "Recall: 0.056404327211780625\n",
            "F1-Score: 0.03462374898826183\n",
            "Cohen Kappa Score: 0.3728134357214933\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_68 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_69 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_106 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 13s 33ms/step - loss: 70.6199 - mae: 6.6159\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 21.4733 - mae: 3.7396\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 21.3838 - mae: 3.7172\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 21.1879 - mae: 3.6953\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 21.1194 - mae: 3.6697\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 20.9261 - mae: 3.7038\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 20.9188 - mae: 3.6771\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 19.9862 - mae: 3.5900\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 62ms/step - loss: 19.2604 - mae: 3.5141\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 16.8532 - mae: 3.3214\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 72ms/step - loss: 16.5981 - mae: 3.3028\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 72ms/step - loss: 15.8393 - mae: 3.1975\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 14.7345 - mae: 3.1243\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 14.4685 - mae: 3.0554\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 14.8373 - mae: 3.1465\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.9397 - mae: 3.0490\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.9250 - mae: 3.0379\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 13.5190 - mae: 2.9888\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 13.3143 - mae: 2.9458\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.2849 - mae: 2.9728\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.1213 - mae: 2.9355\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 12.7567 - mae: 2.9044\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 14.1404 - mae: 3.0398\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.5441 - mae: 2.8699\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 12.5218 - mae: 2.8711\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 12.6944 - mae: 2.8704\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 12.3293 - mae: 2.8482\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 12.7941 - mae: 2.9214\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 12.6949 - mae: 2.8955\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 12.7178 - mae: 2.8645\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 12.1487 - mae: 2.8377\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 62ms/step - loss: 12.0269 - mae: 2.8412\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.3209 - mae: 2.9280\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 11.5059 - mae: 2.7647\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.1468 - mae: 2.8304\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 11.7785 - mae: 2.7689\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.7593 - mae: 2.9020\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 11.5570 - mae: 2.7482\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 11.9051 - mae: 2.7988\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 11.6639 - mae: 2.7469\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.3507 - mae: 2.8355\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.2368 - mae: 2.8351\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 11.9386 - mae: 2.8046\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.2902 - mae: 2.8863\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 11.5984 - mae: 2.7528\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 11.5439 - mae: 2.7374\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 73ms/step - loss: 11.6696 - mae: 2.7590\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 73ms/step - loss: 11.9317 - mae: 2.7930\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 11.6866 - mae: 2.7950\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 65ms/step - loss: 11.8240 - mae: 2.7913\n",
            "10/10 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.10828025477707007\n",
            "Precision: 0.055755335363630296\n",
            "Recall: 0.08228585241738329\n",
            "F1-Score: 0.06308182328222348\n",
            "Cohen Kappa Score: 0.600376239526017\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_34 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_66 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_33 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_67 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_33 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 2s 17ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 280.3108 - mae: 16.1084 - mse: 280.3108\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.17197452229299362\n",
            "Precision: 0.10810036272722004\n",
            "Recall: 0.10661863178112242\n",
            "F1-Score: 0.08896740208765365\n",
            "Cohen Kappa Score: 0.5316597126027341\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.1910828025477707\n",
            "Precision: 0.08424228277169454\n",
            "Recall: 0.10705584778811322\n",
            "F1-Score: 0.08727124519968972\n",
            "Cohen Kappa Score: 0.6212802884342217\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.16560509554140126\n",
            "Precision: 0.016026097835209908\n",
            "Recall: 0.0822890559732665\n",
            "F1-Score: 0.026827319930768204\n",
            "Cohen Kappa Score: 0.40659205035444024\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.08280254777070063\n",
            "Precision: 0.0585167776879244\n",
            "Recall: 0.055939389138916086\n",
            "F1-Score: 0.055572155402449225\n",
            "Cohen Kappa Score: 0.41668901789108626\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1337579617834395\n",
            "Precision: 0.006369426751592357\n",
            "Recall: 0.047619047619047616\n",
            "F1-Score: 0.011235955056179775\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_140 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_141 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_107 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 21ms/step - loss: 143.4375 - mae: 10.5862\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 37.8058 - mae: 5.1697\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.2276 - mae: 4.5169\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 25.2467 - mae: 4.1450\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.0091 - mae: 3.9493\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 22.0541 - mae: 3.8041\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.5893 - mae: 3.7157\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 21.4935 - mae: 3.7054\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.4168 - mae: 3.7148\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21.5475 - mae: 3.7322\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.6993 - mae: 3.7158\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.7448 - mae: 3.7429\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.5538 - mae: 3.7092\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.5417 - mae: 3.6963\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21.2233 - mae: 3.6870\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 21.5356 - mae: 3.6989\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.4125 - mae: 3.6833\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21.0952 - mae: 3.6892\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.4142 - mae: 3.7167\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 21.0627 - mae: 3.6783\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 20.4215 - mae: 3.6447\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 20.0659 - mae: 3.5943\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 19.0017 - mae: 3.5112\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 18.7998 - mae: 3.4623\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.7973 - mae: 3.3309\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 18.5104 - mae: 3.4581\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.8694 - mae: 3.3148\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.4575 - mae: 3.1822\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.7453 - mae: 3.2081\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 15.0948 - mae: 3.1373\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 14.7110 - mae: 3.0984\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 15.3558 - mae: 3.1688\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 14.5890 - mae: 3.1063\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 14.9309 - mae: 3.1257\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 14.9335 - mae: 3.1062\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.4213 - mae: 2.9584\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 14.4216 - mae: 3.0965\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.8383 - mae: 3.0324\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.0935 - mae: 3.1159\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 14.2109 - mae: 3.0432\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 13.6048 - mae: 2.9673\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 13.8558 - mae: 3.0326\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 12.8156 - mae: 2.9076\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 14.3438 - mae: 3.0607\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 13.1175 - mae: 2.9548\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 13.9254 - mae: 3.0322\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 12.6456 - mae: 2.8493\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 13.9565 - mae: 3.0057\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 13.3255 - mae: 3.0041\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.0937 - mae: 2.9261\n",
            "10/10 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.12738853503184713\n",
            "Precision: 0.05726336299981187\n",
            "Recall: 0.0968870139148777\n",
            "F1-Score: 0.06665449406733953\n",
            "Cohen Kappa Score: 0.5628758623621561\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_70 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_71 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_108 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 14s 35ms/step - loss: 66.7501 - mae: 6.2594\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 21.3501 - mae: 3.6974\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 21.1975 - mae: 3.6633\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 21.3201 - mae: 3.6807\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 20.5763 - mae: 3.6404\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 20.1137 - mae: 3.5997\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 2s 75ms/step - loss: 18.6911 - mae: 3.4580\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 74ms/step - loss: 17.2134 - mae: 3.3301\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 2s 80ms/step - loss: 17.7798 - mae: 3.4008\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 64ms/step - loss: 15.9757 - mae: 3.2510\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 15.5024 - mae: 3.1326\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 14.8468 - mae: 3.0837\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 14.4837 - mae: 3.0999\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 14.7473 - mae: 3.1198\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 14.1190 - mae: 3.0215\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 13.3146 - mae: 2.9516\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.7212 - mae: 3.0017\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.9590 - mae: 2.9023\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 13.1625 - mae: 2.9595\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.3834 - mae: 2.9700\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.7019 - mae: 2.8676\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.8293 - mae: 2.9084\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.6134 - mae: 2.8838\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 13.2885 - mae: 2.9393\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 63ms/step - loss: 13.2502 - mae: 2.9370\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 64ms/step - loss: 13.2390 - mae: 2.9360\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 61ms/step - loss: 12.8376 - mae: 2.8830\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 61ms/step - loss: 12.2190 - mae: 2.8444\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 13.4372 - mae: 2.9578\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 12.0699 - mae: 2.7727\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.7361 - mae: 2.8630\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.4954 - mae: 2.8719\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.5232 - mae: 2.8763\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.7338 - mae: 2.9025\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.2685 - mae: 2.8538\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 12.4965 - mae: 2.8710\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.5117 - mae: 2.8571\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.5730 - mae: 2.8498\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.5397 - mae: 2.8453\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 11.9595 - mae: 2.7881\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 12.4515 - mae: 2.8181\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.0030 - mae: 2.7925\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.6586 - mae: 2.8990\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 11.9907 - mae: 2.7881\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 62ms/step - loss: 12.1588 - mae: 2.8219\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 11.6692 - mae: 2.7415\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 61ms/step - loss: 11.8631 - mae: 2.7994\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 72ms/step - loss: 11.7440 - mae: 2.7682\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 12.0648 - mae: 2.8265\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 11.4944 - mae: 2.7329\n",
            "10/10 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.12738853503184713\n",
            "Precision: 0.06330969887955182\n",
            "Recall: 0.10247866383702298\n",
            "F1-Score: 0.0738261041261844\n",
            "Cohen Kappa Score: 0.6035786045386115\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_35 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_68 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_34 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_69 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_34 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 2s 18ms/step - loss: 49.1227 - mae: 5.7377 - mse: 49.1227\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 27.6220 - mae: 4.2281 - mse: 27.6220\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 22.2479 - mae: 3.7631 - mse: 22.2479\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.8917 - mae: 3.7469 - mse: 21.8917\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.7354 - mae: 3.7029 - mse: 21.7354\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.0241 - mae: 3.6348 - mse: 21.0241\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.9465 - mae: 3.6376 - mse: 20.9465\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.4051 - mae: 3.7204 - mse: 21.4051\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 22.3247 - mae: 3.8062 - mse: 22.3247\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.1812 - mae: 3.6777 - mse: 21.1812\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.5094 - mae: 3.5861 - mse: 20.5094\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.6180 - mae: 3.6039 - mse: 20.6180\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.5586 - mae: 3.7237 - mse: 21.5586\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.4789 - mae: 3.6348 - mse: 20.4789\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.9708 - mae: 3.6340 - mse: 20.9708\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.0135 - mae: 3.5712 - mse: 20.0135\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.6092 - mae: 3.6255 - mse: 20.6092\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.8770 - mae: 3.6416 - mse: 20.8770\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.7203 - mae: 3.7147 - mse: 21.7203\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 25.1134 - mae: 4.0738 - mse: 25.1134\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.9784 - mae: 3.8057 - mse: 21.9784\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 21.0879 - mae: 3.6823 - mse: 21.0879\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.0461 - mae: 3.5772 - mse: 20.0461\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.1751 - mae: 3.5833 - mse: 20.1751\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.8100 - mae: 3.5309 - mse: 19.8100\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.6405 - mae: 3.5796 - mse: 19.6405\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.6038 - mae: 3.6541 - mse: 20.6038\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 19.5139 - mae: 3.5308 - mse: 19.5139\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.4757 - mae: 3.5120 - mse: 19.4757\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.1585 - mae: 3.4754 - mse: 19.1585\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.1597 - mae: 3.4878 - mse: 19.1597\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.3119 - mae: 3.5192 - mse: 19.3119\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.7370 - mae: 3.5370 - mse: 19.7370\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.6417 - mae: 3.5303 - mse: 19.6417\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.5710 - mae: 3.5297 - mse: 19.5710\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.8635 - mae: 3.4663 - mse: 18.8635\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.9821 - mae: 3.4698 - mse: 18.9821\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.8302 - mae: 3.4963 - mse: 18.8302\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.8710 - mae: 3.4630 - mse: 18.8710\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.0052 - mae: 3.5042 - mse: 19.0052\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.7401 - mae: 3.4540 - mse: 18.7401\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.4315 - mae: 3.4133 - mse: 18.4315\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.7181 - mae: 3.4557 - mse: 18.7181\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.5176 - mae: 3.4469 - mse: 18.5176\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.2823 - mae: 3.4085 - mse: 18.2823\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.3749 - mae: 3.5260 - mse: 19.3749\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.3574 - mae: 3.4166 - mse: 18.3574\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.5046 - mae: 3.5540 - mse: 19.5046\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.6095 - mae: 3.5515 - mse: 19.6095\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.5564 - mae: 3.5619 - mse: 19.5564\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.3004 - mae: 3.4028 - mse: 18.3004\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.9985 - mae: 3.4035 - mse: 17.9985\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17.9220 - mae: 3.3805 - mse: 17.9220\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17.7898 - mae: 3.3540 - mse: 17.7898\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.5303 - mae: 3.3373 - mse: 17.5303\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.6474 - mae: 3.3450 - mse: 17.6474\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.4207 - mae: 3.4610 - mse: 18.4207\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.2329 - mae: 3.4108 - mse: 18.2329\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.3867 - mae: 3.4308 - mse: 18.3867\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.4160 - mae: 3.6344 - mse: 20.4160\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 21.5605 - mae: 3.7823 - mse: 21.5605\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.6031 - mae: 3.5894 - mse: 19.6031\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.6773 - mae: 3.4623 - mse: 18.6773\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.0525 - mae: 3.3977 - mse: 18.0525\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17.2316 - mae: 3.3310 - mse: 17.2316\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.8460 - mae: 3.2718 - mse: 16.8460\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.9597 - mae: 3.2953 - mse: 16.9597\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.0886 - mae: 3.3140 - mse: 17.0886\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.8903 - mae: 3.2847 - mse: 16.8903\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.8869 - mae: 3.2784 - mse: 16.8869\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.4743 - mae: 3.4653 - mse: 18.4743\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.6369 - mae: 3.3981 - mse: 17.6369\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 17.8470 - mae: 3.4113 - mse: 17.8470\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.4721 - mae: 3.6965 - mse: 20.4721\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17.3725 - mae: 3.3259 - mse: 17.3725\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.9941 - mae: 3.3351 - mse: 16.9941\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.3873 - mae: 3.2490 - mse: 16.3873\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.5266 - mae: 3.3689 - mse: 17.5266\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.6646 - mae: 3.2890 - mse: 16.6646\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.3239 - mae: 3.2152 - mse: 16.3239\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.3306 - mae: 3.2423 - mse: 16.3306\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.1017 - mae: 3.2285 - mse: 16.1017\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.0286 - mae: 3.3113 - mse: 17.0286\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 16.0527 - mae: 3.2022 - mse: 16.0527\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.1117 - mae: 3.2234 - mse: 16.1117\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.1374 - mae: 3.4448 - mse: 18.1374\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.6880 - mae: 3.6053 - mse: 19.6880\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.2047 - mae: 3.2233 - mse: 16.2047\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.8693 - mae: 3.2060 - mse: 15.8693\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.5577 - mae: 3.1622 - mse: 15.5577\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.5909 - mae: 3.1662 - mse: 15.5909\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.4567 - mae: 3.1412 - mse: 15.4567\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.3462 - mae: 3.1573 - mse: 15.3462\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.5701 - mae: 3.1654 - mse: 15.5701\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.1479 - mae: 3.3342 - mse: 17.1479\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.2125 - mae: 3.1485 - mse: 15.2125\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.4393 - mae: 3.1602 - mse: 15.4393\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.1269 - mae: 3.1195 - mse: 15.1269\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 14.9207 - mae: 3.0981 - mse: 14.9207\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.3726 - mae: 3.1657 - mse: 15.3726\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.06369426751592357\n",
            "Precision: 0.016840362286389274\n",
            "Recall: 0.04669004241372663\n",
            "F1-Score: 0.024434544935675703\n",
            "Cohen Kappa Score: 0.3432164208256895\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.1305732484076433\n",
            "Precision: 0.04313011063011063\n",
            "Recall: 0.08084128590707539\n",
            "F1-Score: 0.052040024825301824\n",
            "Cohen Kappa Score: 0.5431044403213549\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.14968152866242038\n",
            "Precision: 0.09710576138089935\n",
            "Recall: 0.1019255692707705\n",
            "F1-Score: 0.08211058772038363\n",
            "Cohen Kappa Score: 0.6584706869073151\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.11146496815286625\n",
            "Precision: 0.022059711565785733\n",
            "Recall: 0.0875\n",
            "F1-Score: 0.03331333034781311\n",
            "Cohen Kappa Score: 0.5868345849607364\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.09235668789808917\n",
            "Precision: 0.08193217356990418\n",
            "Recall: 0.07303621613711678\n",
            "F1-Score: 0.07228394338431986\n",
            "Cohen Kappa Score: 0.4252639251915681\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.07643312101910828\n",
            "Precision: 0.003821656050955414\n",
            "Recall: 0.05\n",
            "F1-Score: 0.007100591715976332\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_144 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_145 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_109 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 19ms/step - loss: 147.4889 - mae: 10.8186\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 40.9224 - mae: 5.3616\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 30.8487 - mae: 4.6317\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.6364 - mae: 4.2762\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 23.8659 - mae: 4.0366\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 22.4987 - mae: 3.8683\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 21.9289 - mae: 3.7986\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 22.2303 - mae: 3.8021\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 21.8635 - mae: 3.7444\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 21.6914 - mae: 3.7379\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 21.9957 - mae: 3.7601\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 21.9107 - mae: 3.7693\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 22.2714 - mae: 3.7893\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 21.6668 - mae: 3.7403\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 22.0856 - mae: 3.7946\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 21.8371 - mae: 3.7645\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 21.4188 - mae: 3.7200\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 21.8494 - mae: 3.7871\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 21.6906 - mae: 3.7493\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.6676 - mae: 3.7501\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.7851 - mae: 3.7555\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 21.7479 - mae: 3.7757\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 20.9779 - mae: 3.6975\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 21.3462 - mae: 3.7436\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 20.3655 - mae: 3.6658\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 18.8210 - mae: 3.5055\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 19.7766 - mae: 3.5992\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 17.6824 - mae: 3.4387\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 18.7892 - mae: 3.5217\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 16.7882 - mae: 3.3464\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 15.2187 - mae: 3.1729\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.1766 - mae: 3.3490\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 14.7862 - mae: 3.1489\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 16.9369 - mae: 3.3301\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.0438 - mae: 3.0788\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.7442 - mae: 3.1895\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.3532 - mae: 3.0602\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 15.0516 - mae: 3.1581\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.4533 - mae: 3.0795\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.8062 - mae: 2.9972\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 15.2206 - mae: 3.1728\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.8068 - mae: 2.9918\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.0118 - mae: 3.0095\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 13.4676 - mae: 2.9851\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 13.6672 - mae: 2.9936\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 13.5185 - mae: 2.9792\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.3035 - mae: 3.0792\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.9918 - mae: 3.0207\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.2117 - mae: 3.0764\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.0578 - mae: 2.9462\n",
            "10/10 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.12140575079872204\n",
            "Precision: 0.04933414979825871\n",
            "Recall: 0.09269551681365791\n",
            "F1-Score: 0.059768223388861695\n",
            "Cohen Kappa Score: 0.5902340780501139\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_72 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_73 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_110 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 11s 32ms/step - loss: 64.6783 - mae: 6.1705\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 21.6885 - mae: 3.7357\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 22.0902 - mae: 3.7748\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 21.2444 - mae: 3.7038\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 21.4483 - mae: 3.7392\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 20.5424 - mae: 3.6586\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 20.2975 - mae: 3.6024\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 19.2102 - mae: 3.5350\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 17.3961 - mae: 3.3476\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 16.1530 - mae: 3.2501\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 15.9571 - mae: 3.2439\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 14.9457 - mae: 3.1165\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 15.6031 - mae: 3.1842\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 13.8297 - mae: 3.0151\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 2s 80ms/step - loss: 14.9405 - mae: 3.1514\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 13.5452 - mae: 2.9914\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 2s 98ms/step - loss: 13.6431 - mae: 2.9952\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 13.6283 - mae: 2.9971\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 13.9356 - mae: 3.0356\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 13.6274 - mae: 2.9645\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 12.9285 - mae: 2.9099\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 13.6701 - mae: 2.9831\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.6961 - mae: 2.9928\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.9114 - mae: 2.9037\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.0459 - mae: 2.9132\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.4766 - mae: 2.8462\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.9956 - mae: 2.9058\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 13.0505 - mae: 2.9415\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.5309 - mae: 2.8622\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.9435 - mae: 2.9111\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 65ms/step - loss: 12.2667 - mae: 2.8293\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 13.0688 - mae: 2.9052\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 12.7126 - mae: 2.8629\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 67ms/step - loss: 12.3267 - mae: 2.8102\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 13.3247 - mae: 2.9336\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 12.8047 - mae: 2.9079\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 12.0972 - mae: 2.8184\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.3125 - mae: 2.8356\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.7245 - mae: 2.8893\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 13.1109 - mae: 2.9071\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.3105 - mae: 2.8271\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 12.4467 - mae: 2.8340\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.2271 - mae: 2.8165\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 11.9367 - mae: 2.7632\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 12.0811 - mae: 2.7948\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 11.8651 - mae: 2.7852\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 12.8351 - mae: 2.8893\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 12.0941 - mae: 2.8173\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 12.3493 - mae: 2.8110\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 12.5415 - mae: 2.8469\n",
            "10/10 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.10543130990415335\n",
            "Precision: 0.04917424521829556\n",
            "Recall: 0.0742409978972129\n",
            "F1-Score: 0.05428084781688863\n",
            "Cohen Kappa Score: 0.5754019144269744\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_36 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_70 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_35 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_71 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_35 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 2s 35ms/step - loss: 87.1823 - mae: 7.5730 - mse: 87.1823\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 33.9337 - mae: 4.7838 - mse: 33.9337\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 24.2946 - mae: 3.9463 - mse: 24.2946\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.8394 - mae: 3.7507 - mse: 21.8394\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.6734 - mae: 3.7365 - mse: 21.6734\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.4586 - mae: 3.7151 - mse: 21.4586\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.4430 - mae: 3.6917 - mse: 21.4430\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.5570 - mae: 3.7164 - mse: 21.5570\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.5362 - mae: 3.7440 - mse: 21.5362\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.3627 - mae: 3.6907 - mse: 21.3627\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.3463 - mae: 3.7143 - mse: 21.3463\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.2706 - mae: 3.6915 - mse: 21.2706\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 21.0839 - mae: 3.6643 - mse: 21.0839\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.7815 - mae: 3.7608 - mse: 21.7815\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.5971 - mae: 3.7418 - mse: 21.5971\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21.0851 - mae: 3.7099 - mse: 21.0851\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.6130 - mae: 3.7437 - mse: 21.6130\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.4339 - mae: 3.7126 - mse: 21.4339\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.7628 - mae: 3.6701 - mse: 20.7628\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.8892 - mae: 3.6695 - mse: 20.8892\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.0761 - mae: 3.6971 - mse: 21.0761\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.6642 - mae: 3.6526 - mse: 20.6642\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.7283 - mae: 3.6395 - mse: 20.7283\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 23.1196 - mae: 3.9179 - mse: 23.1196\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21.3567 - mae: 3.7185 - mse: 21.3567\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.7757 - mae: 3.7607 - mse: 21.7757\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.4628 - mae: 3.6208 - mse: 20.4628\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 20.2534 - mae: 3.6058 - mse: 20.2534\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 21.2727 - mae: 3.7230 - mse: 21.2727\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.3643 - mae: 3.6312 - mse: 20.3643\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.2091 - mae: 3.5990 - mse: 20.2091\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.7429 - mae: 3.6727 - mse: 20.7429\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.8430 - mae: 3.6761 - mse: 20.8430\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.3571 - mae: 3.6445 - mse: 20.3571\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.6792 - mae: 3.6406 - mse: 20.6792\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.0610 - mae: 3.5954 - mse: 20.0610\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.4034 - mae: 3.6540 - mse: 20.4034\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.7343 - mae: 3.6620 - mse: 20.7343\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.6651 - mae: 3.6840 - mse: 20.6651\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.0591 - mae: 3.5834 - mse: 20.0591\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.1956 - mae: 3.6201 - mse: 20.1956\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.6557 - mae: 3.5619 - mse: 19.6557\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.6525 - mae: 3.6442 - mse: 20.6525\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.0606 - mae: 3.6117 - mse: 20.0606\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 20.3914 - mae: 3.6583 - mse: 20.3914\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.6759 - mae: 3.6487 - mse: 20.6759\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.1721 - mae: 3.6325 - mse: 20.1721\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.5813 - mae: 3.5306 - mse: 19.5813\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.1860 - mae: 3.5221 - mse: 19.1860\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.2342 - mae: 3.5155 - mse: 19.2342\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.5472 - mae: 3.5746 - mse: 19.5472\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 19.3788 - mae: 3.5406 - mse: 19.3788\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.4274 - mae: 3.5635 - mse: 19.4274\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.2796 - mae: 3.5387 - mse: 19.2796\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.8898 - mae: 3.5062 - mse: 18.8898\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.9207 - mae: 3.4947 - mse: 18.9207\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.7803 - mae: 3.5923 - mse: 19.7803\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.5701 - mae: 3.5425 - mse: 19.5701\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.9456 - mae: 3.5933 - mse: 19.9456\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.6352 - mae: 3.7204 - mse: 20.6352\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.0673 - mae: 3.6262 - mse: 20.0673\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.8426 - mae: 3.4691 - mse: 18.8426\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.4783 - mae: 3.4754 - mse: 18.4783\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.6338 - mae: 3.5666 - mse: 19.6338\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 19.0545 - mae: 3.5262 - mse: 19.0545\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.5997 - mae: 3.4696 - mse: 18.5997\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.2989 - mae: 3.4423 - mse: 18.2989\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.7722 - mae: 3.4942 - mse: 18.7722\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.6194 - mae: 3.5054 - mse: 18.6194\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 18.1044 - mae: 3.4181 - mse: 18.1044\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.3237 - mae: 3.4335 - mse: 18.3237\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.9315 - mae: 3.4262 - mse: 17.9315\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.1671 - mae: 3.4353 - mse: 18.1671\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.0116 - mae: 3.4432 - mse: 18.0116\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.5250 - mae: 3.3529 - mse: 17.5250\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.4386 - mae: 3.3735 - mse: 17.4386\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17.1005 - mae: 3.3149 - mse: 17.1005\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.5099 - mae: 3.3947 - mse: 17.5099\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.3341 - mae: 3.3536 - mse: 17.3341\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.5789 - mae: 3.4549 - mse: 18.5789\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.3896 - mae: 3.3672 - mse: 17.3896\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18.1796 - mae: 3.4652 - mse: 18.1796\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.8765 - mae: 3.3373 - mse: 16.8765\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.9609 - mae: 3.4098 - mse: 17.9609\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.5840 - mae: 3.4055 - mse: 17.5840\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 16.4666 - mae: 3.2762 - mse: 16.4666\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.2070 - mae: 3.2469 - mse: 16.2070\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.9476 - mae: 3.2132 - mse: 15.9476\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.8658 - mae: 3.2075 - mse: 15.8658\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.8937 - mae: 3.2156 - mse: 15.8937\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.9210 - mae: 3.2164 - mse: 15.9210\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.8783 - mae: 3.2138 - mse: 15.8783\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.9319 - mae: 3.2312 - mse: 15.9319\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 16.0748 - mae: 3.2256 - mse: 16.0748\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.6359 - mae: 3.1906 - mse: 15.6359\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 15.6683 - mae: 3.2097 - mse: 15.6683\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.5520 - mae: 3.1886 - mse: 15.5520\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.0963 - mae: 3.1456 - mse: 15.0963\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 15.6015 - mae: 3.2045 - mse: 15.6015\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.3554 - mae: 3.3988 - mse: 17.3554\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.11501597444089456\n",
            "Precision: 0.03057196782766043\n",
            "Recall: 0.060354972575017374\n",
            "F1-Score: 0.038751054515373404\n",
            "Cohen Kappa Score: 0.39605359051988454\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.16293929712460065\n",
            "Precision: 0.08014152147316221\n",
            "Recall: 0.09478470313436718\n",
            "F1-Score: 0.07462583296254906\n",
            "Cohen Kappa Score: 0.5101633832038132\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.16932907348242812\n",
            "Precision: 0.13426953572576766\n",
            "Recall: 0.1278075240673225\n",
            "F1-Score: 0.12005199021811115\n",
            "Cohen Kappa Score: 0.6446661580483228\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.14376996805111822\n",
            "Precision: 0.032763408462126775\n",
            "Recall: 0.06919667212220404\n",
            "F1-Score: 0.03826232507849375\n",
            "Cohen Kappa Score: 0.44737339956192845\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.07348242811501597\n",
            "Precision: 0.054961137347500987\n",
            "Recall: 0.07442881866174139\n",
            "F1-Score: 0.05624236801744638\n",
            "Cohen Kappa Score: 0.35755782692524263\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1501597444089457\n",
            "Precision: 0.007507987220447284\n",
            "Recall: 0.05\n",
            "F1-Score: 0.013055555555555556\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 663.78656 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.131   |   0.064   | 0.097  |  0.067   |    0.590    |\n",
            "|           BiLSTM          |  0.131   |   0.079   | 0.103  |  0.086   |    0.666    |\n",
            "|            CNN            |  0.115   |   0.031   | 0.060  |  0.039   |    0.396    |\n",
            "|    Logistic Regression    |  0.172   |   0.108   | 0.107  |  0.089   |    0.587    |\n",
            "|  Random Forest Classifier |  0.204   |   0.189   | 0.150  |  0.133   |    0.670    |\n",
            "|    Adaboost Classifier    |  0.169   |   0.037   | 0.087  |  0.038   |    0.587    |\n",
            "|   K Neighbors Classifier  |  0.092   |   0.082   | 0.074  |  0.072   |    0.492    |\n",
            "| Support Vector Classifier |  0.159   |   0.008   | 0.050  |  0.013   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------SET 8--------\n",
            "\n",
            " -------------------------------------------------\n",
            " -------------------------------------------------\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_148 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_149 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_111 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 23ms/step - loss: 1265.4008 - mae: 35.0664\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 815.5482 - mae: 27.8779\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 634.2021 - mae: 24.5201\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 581.1631 - mae: 23.4214\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 549.2626 - mae: 22.7302\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 521.3580 - mae: 22.0938\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 500.0975 - mae: 21.6154\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 477.8395 - mae: 21.1122\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 458.9608 - mae: 20.6532\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 438.7468 - mae: 20.1618\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 418.2305 - mae: 19.6445\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 401.6940 - mae: 19.2212\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 380.9174 - mae: 18.6732\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 365.2867 - mae: 18.2558\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 346.9123 - mae: 17.7371\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 334.6774 - mae: 17.4078\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 316.4305 - mae: 16.8620\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 298.9351 - mae: 16.3537\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 287.9154 - mae: 16.0040\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 268.7088 - mae: 15.4286\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 255.6169 - mae: 14.9914\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 243.1694 - mae: 14.5549\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 229.4587 - mae: 14.0891\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 216.6499 - mae: 13.6095\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 205.6996 - mae: 13.2531\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 195.6769 - mae: 12.8475\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 180.8724 - mae: 12.2833\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 170.5920 - mae: 11.8557\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 160.4367 - mae: 11.4376\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 151.5239 - mae: 11.0357\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 142.4210 - mae: 10.6357\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 133.5053 - mae: 10.2393\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 124.8613 - mae: 9.7704\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 114.4881 - mae: 9.3302\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 105.7226 - mae: 8.8905\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 99.8827 - mae: 8.5165\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 90.8643 - mae: 8.0920\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 85.8572 - mae: 7.7507\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 80.5723 - mae: 7.4978\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 75.2739 - mae: 7.1908\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 69.9077 - mae: 6.8143\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 63.5991 - mae: 6.4976\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 59.2750 - mae: 6.2157\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 55.9629 - mae: 6.0517\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 50.7011 - mae: 5.6926\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 49.6012 - mae: 5.6517\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 47.4392 - mae: 5.5105\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 44.9725 - mae: 5.3834\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 41.7444 - mae: 5.1379\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 38.8217 - mae: 4.9749\n",
            "5/5 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.041379310344827586\n",
            "Precision: 0.0014778325123152708\n",
            "Recall: 0.03571428571428571\n",
            "F1-Score: 0.0028382213812677384\n",
            "Cohen Kappa Score: 0.0\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_74 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_75 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_112 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 11s 71ms/step - loss: 938.2927 - mae: 29.6612\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 437.7340 - mae: 20.1018\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 358.1898 - mae: 18.0609\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 302.4977 - mae: 16.4557\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 259.6594 - mae: 15.0995\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 217.1190 - mae: 13.6565\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 182.3575 - mae: 12.3278\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 150.4665 - mae: 11.0244\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 122.8177 - mae: 9.7522\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 103.6047 - mae: 8.7372\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 81.4662 - mae: 7.4967\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 66.1179 - mae: 6.7042\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 53.7229 - mae: 5.9415\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 45.0250 - mae: 5.3928\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 37.8336 - mae: 4.9057\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 35.7312 - mae: 4.7353\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 34.7966 - mae: 4.7293\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 32.6813 - mae: 4.5425\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 32.7120 - mae: 4.6275\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 33.8867 - mae: 4.6302\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 34.8209 - mae: 4.7415\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 32.7989 - mae: 4.5713\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 34.3210 - mae: 4.7232\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 33.9046 - mae: 4.6606\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 34.3019 - mae: 4.7014\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 32.8621 - mae: 4.5174\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 30.0705 - mae: 4.3155\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 28.7526 - mae: 4.2530\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 29.4035 - mae: 4.2974\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 29.1074 - mae: 4.3181\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 29.0691 - mae: 4.2976\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 29.2732 - mae: 4.2486\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 29.1172 - mae: 4.2915\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 28.4530 - mae: 4.2313\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 28.7433 - mae: 4.2442\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 28.9926 - mae: 4.2284\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 29.3219 - mae: 4.3075\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 28.5458 - mae: 4.2049\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 29.0409 - mae: 4.2488\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 28.7622 - mae: 4.3051\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 29.4484 - mae: 4.2660\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 29.6627 - mae: 4.3342\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 27.6947 - mae: 4.1388\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 26.9935 - mae: 4.1343\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 26.8899 - mae: 4.0849\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 27.6369 - mae: 4.1288\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 26.4325 - mae: 4.0583\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 26.9726 - mae: 4.1360\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 24.1694 - mae: 3.8894\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 25.2079 - mae: 3.9731\n",
            "5/5 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.11724137931034483\n",
            "Precision: 0.02768132057728331\n",
            "Recall: 0.05085466004583651\n",
            "F1-Score: 0.03116313191943444\n",
            "Cohen Kappa Score: 0.3553666871982355\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_37 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_72 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_36 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_73 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_36 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 48ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1396.4048 - mae: 36.9377 - mse: 1396.4048\n",
            "5/5 [==============================] - 0s 16ms/step\n",
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.23448275862068965\n",
            "Precision: 0.04833764164593799\n",
            "Recall: 0.05137685168111131\n",
            "F1-Score: 0.04088918744091158\n",
            "Cohen Kappa Score: 0.18152034210723367\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.18620689655172415\n",
            "Precision: 0.02857507109934294\n",
            "Recall: 0.03548828622358034\n",
            "F1-Score: 0.026020937379946218\n",
            "Cohen Kappa Score: 0.4762976305372193\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.1793103448275862\n",
            "Precision: 0.009833024118738404\n",
            "Recall: 0.03413865546218488\n",
            "F1-Score: 0.015227021040974531\n",
            "Cohen Kappa Score: 0.3485204558663736\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.0896551724137931\n",
            "Precision: 0.027977470558115718\n",
            "Recall: 0.031616928296245184\n",
            "F1-Score: 0.026952663979311946\n",
            "Cohen Kappa Score: 0.3647568051996768\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.23448275862068965\n",
            "Precision: 0.008374384236453201\n",
            "Recall: 0.03571428571428571\n",
            "F1-Score: 0.013567438148443734\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_152 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_153 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_113 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 8s 23ms/step - loss: 1252.9712 - mae: 34.8776\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 817.4318 - mae: 27.9416\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 646.7281 - mae: 24.7710\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 597.5457 - mae: 23.7715\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 564.4615 - mae: 23.0598\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 539.0833 - mae: 22.4975\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 518.2120 - mae: 22.0174\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 495.4914 - mae: 21.5190\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 472.9610 - mae: 20.9911\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 452.7531 - mae: 20.5067\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 434.6503 - mae: 20.0638\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 413.7003 - mae: 19.5422\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 397.9257 - mae: 19.1144\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 380.0963 - mae: 18.6522\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 362.0745 - mae: 18.1639\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 345.4100 - mae: 17.7146\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 328.8972 - mae: 17.2508\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 311.8257 - mae: 16.7456\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 296.6415 - mae: 16.2683\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 282.4690 - mae: 15.8379\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 268.1562 - mae: 15.3879\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 255.3747 - mae: 14.9577\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 240.4359 - mae: 14.4566\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 228.7927 - mae: 14.0910\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 216.8797 - mae: 13.6418\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 203.0528 - mae: 13.1540\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 192.9574 - mae: 12.7473\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 179.8179 - mae: 12.2392\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 170.5670 - mae: 11.8412\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 158.0230 - mae: 11.3189\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 148.5976 - mae: 10.9729\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 140.5869 - mae: 10.5679\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 129.7045 - mae: 10.0711\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 123.2326 - mae: 9.7516\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 113.0495 - mae: 9.2226\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 105.7723 - mae: 8.8586\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 98.2083 - mae: 8.4661\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 91.6560 - mae: 8.1178\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 86.2694 - mae: 7.8176\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 80.7215 - mae: 7.5049\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 73.8977 - mae: 7.0952\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 69.9203 - mae: 6.8853\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 62.8897 - mae: 6.5110\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 60.0074 - mae: 6.2522\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 56.0708 - mae: 6.0576\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 54.1486 - mae: 5.9530\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 47.2414 - mae: 5.5815\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 46.7371 - mae: 5.5239\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 43.9514 - mae: 5.3063\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 40.8486 - mae: 5.1502\n",
            "5/5 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.05517241379310345\n",
            "Precision: 0.0020434227330779053\n",
            "Recall: 0.037037037037037035\n",
            "F1-Score: 0.003873154199951585\n",
            "Cohen Kappa Score: 0.0\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_76 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_77 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_114 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 11s 37ms/step - loss: 923.9082 - mae: 29.3985\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 424.4781 - mae: 19.7752\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 341.8860 - mae: 17.6080\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 290.4086 - mae: 16.0859\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 246.9845 - mae: 14.6786\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 208.6331 - mae: 13.3502\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 174.8372 - mae: 12.0475\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 141.1660 - mae: 10.6318\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 118.2642 - mae: 9.5136\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 93.8811 - mae: 8.2650\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 78.3358 - mae: 7.3814\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 63.7331 - mae: 6.5315\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 51.9354 - mae: 5.8364\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 43.0503 - mae: 5.2639\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 41.2120 - mae: 5.1246\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 37.1054 - mae: 4.8978\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 34.1803 - mae: 4.6391\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 35.0792 - mae: 4.6987\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 35.3806 - mae: 4.7478\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 34.8300 - mae: 4.6550\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 35.4517 - mae: 4.7385\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 35.4159 - mae: 4.7766\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 48ms/step - loss: 34.9377 - mae: 4.6381\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 34.1915 - mae: 4.6541\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 32.3285 - mae: 4.5078\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 31.8565 - mae: 4.4912\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 31.5154 - mae: 4.4587\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 31.1764 - mae: 4.4316\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 30.0715 - mae: 4.2944\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 30.2211 - mae: 4.3304\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 31.1332 - mae: 4.3962\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 29.0734 - mae: 4.2235\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 30.4879 - mae: 4.3302\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 29.9311 - mae: 4.2311\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 30.2230 - mae: 4.3884\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 29.3041 - mae: 4.2562\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 29.4970 - mae: 4.2716\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 28.2712 - mae: 4.1578\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 26.9969 - mae: 4.0169\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 27.9825 - mae: 4.2060\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 27.1988 - mae: 4.0983\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 26.8828 - mae: 4.1056\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 26.2666 - mae: 4.0214\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 26.4226 - mae: 3.9853\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 27.0937 - mae: 4.0798\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 26.8311 - mae: 4.0733\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 24.5535 - mae: 3.8707\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 23.1470 - mae: 3.7400\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 25.9823 - mae: 3.9666\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 23.5757 - mae: 3.7363\n",
            "5/5 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.06206896551724138\n",
            "Precision: 0.02061157796451914\n",
            "Recall: 0.06285714285714286\n",
            "F1-Score: 0.01693738051685486\n",
            "Cohen Kappa Score: 0.28776346084817905\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_38 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_74 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_37 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_75 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_37 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 15ms/step - loss: 241.7389 - mae: 12.8235 - mse: 241.7389\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.1732 - mae: 8.2528 - mse: 108.1732\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 95.2734 - mae: 8.2270 - mse: 95.2734\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 60.0336 - mae: 6.1975 - mse: 60.0336\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 43.3983 - mae: 5.3066 - mse: 43.3983\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 46.0530 - mae: 5.3955 - mse: 46.0530\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41.0142 - mae: 5.0800 - mse: 41.0142\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36.7305 - mae: 4.7918 - mse: 36.7305\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.8594 - mae: 4.7292 - mse: 35.8594\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36.5390 - mae: 4.7858 - mse: 36.5390\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.2465 - mae: 4.6888 - mse: 35.2465\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.0661 - mae: 4.7017 - mse: 36.0661\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.7358 - mae: 4.6709 - mse: 34.7358\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1908 - mae: 4.6106 - mse: 34.1908\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.0029 - mae: 4.5879 - mse: 34.0029\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.7035 - mae: 4.6504 - mse: 34.7035\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.1698 - mae: 4.5981 - mse: 34.1698\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.8107 - mae: 4.5684 - mse: 33.8107\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.0700 - mae: 4.5878 - mse: 34.0700\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.5700 - mae: 4.6660 - mse: 34.5700\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8282 - mae: 4.5577 - mse: 33.8282\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.4190 - mae: 4.5447 - mse: 33.4190\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.7670 - mae: 4.5551 - mse: 33.7670\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.5444 - mae: 4.5566 - mse: 33.5444\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.5211 - mae: 4.5400 - mse: 33.5211\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.5762 - mae: 4.5574 - mse: 33.5762\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.7131 - mae: 4.5680 - mse: 33.7131\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.5084 - mae: 4.5484 - mse: 33.5084\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.2423 - mae: 4.5235 - mse: 33.2423\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.3794 - mae: 4.5348 - mse: 33.3794\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.3734 - mae: 4.5540 - mse: 33.3734\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.5792 - mae: 4.6203 - mse: 34.5792\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.6439 - mae: 4.8025 - mse: 36.6439\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35.1699 - mae: 4.6531 - mse: 35.1699\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.1340 - mae: 4.5192 - mse: 33.1340\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.2832 - mae: 4.5462 - mse: 33.2832\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.7762 - mae: 4.6476 - mse: 34.7762\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.1537 - mae: 4.5231 - mse: 33.1537\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.2951 - mae: 4.5381 - mse: 33.2951\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.1031 - mae: 4.5221 - mse: 33.1031\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.3913 - mae: 4.5534 - mse: 33.3913\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.6558 - mae: 4.4965 - mse: 32.6558\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.5215 - mae: 4.4772 - mse: 32.5215\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.5565 - mae: 4.4791 - mse: 32.5565\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.0341 - mae: 4.5014 - mse: 33.0341\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.8108 - mae: 4.5105 - mse: 32.8108\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.3224 - mae: 4.4689 - mse: 32.3224\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.4390 - mae: 4.4781 - mse: 32.4390\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.4799 - mae: 4.5381 - mse: 33.4799\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.5352 - mae: 4.6216 - mse: 34.5352\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6917 - mae: 4.6804 - mse: 34.6917\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8581 - mae: 4.5881 - mse: 33.8581\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.6300 - mae: 4.4127 - mse: 31.6300\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.3151 - mae: 4.4636 - mse: 32.3151\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.0037 - mae: 4.5171 - mse: 33.0037\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.9937 - mae: 4.5657 - mse: 32.9937\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.8275 - mae: 4.7928 - mse: 35.8275\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 36.9467 - mae: 4.8601 - mse: 36.9467\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.9281 - mae: 4.6069 - mse: 33.9281\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.4754 - mae: 4.5391 - mse: 33.4754\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.9531 - mae: 4.5155 - mse: 32.9531\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.9228 - mae: 4.5440 - mse: 32.9228\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.7329 - mae: 4.6133 - mse: 33.7329\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.6422 - mae: 4.5443 - mse: 32.6422\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.0725 - mae: 4.4325 - mse: 32.0725\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.4003 - mae: 4.4093 - mse: 31.4003\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.3970 - mae: 4.4012 - mse: 31.3970\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.8302 - mae: 4.4575 - mse: 31.8302\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.7117 - mae: 4.4740 - mse: 32.7117\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.1215 - mae: 4.3898 - mse: 31.1215\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.0670 - mae: 4.4625 - mse: 32.0670\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.3424 - mae: 4.3820 - mse: 31.3424\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.8027 - mae: 4.4691 - mse: 31.8027\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.3150 - mae: 4.4242 - mse: 31.3150\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.0922 - mae: 4.3975 - mse: 31.0922\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31.4833 - mae: 4.4186 - mse: 31.4833\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.8746 - mae: 4.4540 - mse: 31.8746\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 30.9913 - mae: 4.3666 - mse: 30.9913\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.9550 - mae: 4.3754 - mse: 30.9550\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31.0422 - mae: 4.3672 - mse: 31.0422\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 31.6919 - mae: 4.4276 - mse: 31.6919\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.6261 - mae: 4.4223 - mse: 31.6261\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 31.1772 - mae: 4.3962 - mse: 31.1772\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.9475 - mae: 4.3779 - mse: 30.9475\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.0196 - mae: 4.3824 - mse: 31.0196\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 30.7376 - mae: 4.3604 - mse: 30.7376\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 30.7891 - mae: 4.3706 - mse: 30.7891\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.1961 - mae: 4.3964 - mse: 31.1961\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.9355 - mae: 4.3672 - mse: 30.9355\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.2859 - mae: 4.5249 - mse: 32.2859\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.1597 - mae: 4.6059 - mse: 33.1597\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.1125 - mae: 4.5018 - mse: 32.1125\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.6077 - mae: 4.6413 - mse: 34.6077\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.6199 - mae: 4.5136 - mse: 32.6199\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31.4692 - mae: 4.3988 - mse: 31.4692\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.3927 - mae: 4.3416 - mse: 30.3927\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30.4213 - mae: 4.3487 - mse: 30.4213\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30.4941 - mae: 4.3452 - mse: 30.4941\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.0209 - mae: 4.4033 - mse: 31.0209\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 30.5048 - mae: 4.3438 - mse: 30.5048\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Accuracy: 0.09655172413793103\n",
            "Precision: 0.026977625088090203\n",
            "Recall: 0.039655612244897956\n",
            "F1-Score: 0.02995772608658689\n",
            "Cohen Kappa Score: 0.23272204133012442\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.15172413793103448\n",
            "Precision: 0.03440301354186535\n",
            "Recall: 0.040535714285714286\n",
            "F1-Score: 0.028397327310370788\n",
            "Cohen Kappa Score: 0.18435663046111406\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.18620689655172415\n",
            "Precision: 0.018391188251001337\n",
            "Recall: 0.048482142857142856\n",
            "F1-Score: 0.024509910379475603\n",
            "Cohen Kappa Score: 0.4452422714317036\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.1793103448275862\n",
            "Precision: 0.012608682199325472\n",
            "Recall: 0.04796296296296296\n",
            "F1-Score: 0.01951325865968986\n",
            "Cohen Kappa Score: 0.26099150189503795\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.07586206896551724\n",
            "Precision: 0.00996376811594203\n",
            "Recall: 0.021785714285714287\n",
            "F1-Score: 0.01351861167002012\n",
            "Cohen Kappa Score: 0.28718706671697947\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1724137931034483\n",
            "Precision: 0.006385696040868455\n",
            "Recall: 0.037037037037037035\n",
            "F1-Score: 0.010893246187363835\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_156 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_157 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_115 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 38ms/step - loss: 1280.2689 - mae: 35.2574\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 833.4338 - mae: 28.1961\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 661.4086 - mae: 25.0247\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 607.8021 - mae: 23.9494\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 576.2593 - mae: 23.2654\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 548.7366 - mae: 22.6875\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 526.7204 - mae: 22.1905\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 503.1726 - mae: 21.6702\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 482.8280 - mae: 21.1782\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 463.3488 - mae: 20.7289\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 444.9631 - mae: 20.2708\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 424.7589 - mae: 19.7955\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 404.7778 - mae: 19.2761\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 386.6571 - mae: 18.7928\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 369.1787 - mae: 18.3190\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 352.1223 - mae: 17.8589\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 336.3944 - mae: 17.4228\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 322.0594 - mae: 16.9925\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 306.4182 - mae: 16.5270\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 291.1056 - mae: 16.0800\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 277.6347 - mae: 15.6399\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 260.6827 - mae: 15.1323\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 248.9342 - mae: 14.7016\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 236.4583 - mae: 14.3119\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 221.7426 - mae: 13.7807\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 208.6317 - mae: 13.3038\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 196.9119 - mae: 12.9176\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 189.1338 - mae: 12.5582\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 175.7617 - mae: 12.0823\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 163.4443 - mae: 11.5750\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 154.3961 - mae: 11.1470\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 144.9892 - mae: 10.7721\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 135.1058 - mae: 10.3460\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 126.5719 - mae: 9.9464\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 115.4806 - mae: 9.3619\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 112.3375 - mae: 9.2182\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 103.2808 - mae: 8.8134\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 96.0819 - mae: 8.3111\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 89.3120 - mae: 8.0135\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 82.2534 - mae: 7.6207\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 78.1823 - mae: 7.3498\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 73.4739 - mae: 7.0715\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 67.8990 - mae: 6.7168\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 63.9998 - mae: 6.5133\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 59.4666 - mae: 6.2379\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 55.6291 - mae: 6.0595\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 51.5119 - mae: 5.7018\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 47.9174 - mae: 5.5299\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 47.1820 - mae: 5.5093\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 43.3426 - mae: 5.2415\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.06896551724137931\n",
            "Precision: 0.003134796238244514\n",
            "Recall: 0.045454545454545456\n",
            "F1-Score: 0.005865102639296188\n",
            "Cohen Kappa Score: 0.0\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_78 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_79 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_116 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 13s 33ms/step - loss: 913.2479 - mae: 29.2146\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 426.8265 - mae: 19.8157\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 348.6148 - mae: 17.7591\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 296.2383 - mae: 16.2307\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 250.9921 - mae: 14.7971\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 213.7157 - mae: 13.4871\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 177.1423 - mae: 12.1432\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 144.6658 - mae: 10.7602\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 120.5950 - mae: 9.6716\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 99.5430 - mae: 8.5489\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 79.3688 - mae: 7.4297\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 66.1947 - mae: 6.6340\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 52.5883 - mae: 5.8424\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 46.7066 - mae: 5.4497\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 41.0579 - mae: 5.0758\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 37.5870 - mae: 4.7999\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 37.2941 - mae: 4.8924\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 36.1293 - mae: 4.7372\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 37.0108 - mae: 4.8013\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 34.4875 - mae: 4.6722\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 36.3412 - mae: 4.6817\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 35.9133 - mae: 4.6824\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 35.5227 - mae: 4.6789\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 35.3339 - mae: 4.6504\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 33.9750 - mae: 4.5827\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 32.4036 - mae: 4.4719\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 31.3365 - mae: 4.4297\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 31.9666 - mae: 4.4474\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 32.6233 - mae: 4.4873\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 30.8392 - mae: 4.3664\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 31.4855 - mae: 4.4425\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 30.7488 - mae: 4.3485\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 31.1264 - mae: 4.4334\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 30.9512 - mae: 4.3442\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 30.4890 - mae: 4.3045\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 31.7116 - mae: 4.4108\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 31.0861 - mae: 4.3898\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 31.3638 - mae: 4.3583\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 30.8005 - mae: 4.3830\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 27.9973 - mae: 4.1615\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 28.8294 - mae: 4.2412\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 29.8137 - mae: 4.2717\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 27.9424 - mae: 4.1217\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 27.6884 - mae: 4.0937\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 28.3003 - mae: 4.1399\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 28.6351 - mae: 4.1843\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 26.9916 - mae: 4.0406\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.5453 - mae: 3.8916\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 26.0651 - mae: 3.9385\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 24.9166 - mae: 3.8632\n",
            "5/5 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.04827586206896552\n",
            "Precision: 0.01716999623204788\n",
            "Recall: 0.04997086247086247\n",
            "F1-Score: 0.02238878143133462\n",
            "Cohen Kappa Score: 0.2681516339315725\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_39 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_76 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_38 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_77 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_38 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 18ms/step - loss: 423.3181 - mae: 17.0546 - mse: 423.3181\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 197.1305 - mae: 11.2856 - mse: 197.1305\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 144.4612 - mae: 10.6796 - mse: 144.4612\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 55.5605 - mae: 5.9074 - mse: 55.5605\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 75.8113 - mae: 6.9739 - mse: 75.8113\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 52.7166 - mae: 5.8882 - mse: 52.7166\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 42.5729 - mae: 5.2132 - mse: 42.5729\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 46.4267 - mae: 5.4580 - mse: 46.4267\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 42.8900 - mae: 5.2027 - mse: 42.8900\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 38.8805 - mae: 4.9191 - mse: 38.8805\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 38.0084 - mae: 4.8768 - mse: 38.0084\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 37.2164 - mae: 4.7959 - mse: 37.2164\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36.7062 - mae: 4.7694 - mse: 36.7062\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36.4026 - mae: 4.7475 - mse: 36.4026\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36.2414 - mae: 4.7461 - mse: 36.2414\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35.9654 - mae: 4.7103 - mse: 35.9654\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35.8068 - mae: 4.7003 - mse: 35.8068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.7811 - mae: 4.6951 - mse: 35.7811\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.6852 - mae: 4.6888 - mse: 35.6852\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.5728 - mae: 4.6763 - mse: 35.5728\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.6311 - mae: 4.6811 - mse: 35.6311\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35.4967 - mae: 4.6667 - mse: 35.4967\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.7166 - mae: 4.6810 - mse: 35.7166\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35.7015 - mae: 4.6815 - mse: 35.7015\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35.6485 - mae: 4.6784 - mse: 35.6485\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.6130 - mae: 4.6803 - mse: 35.6130\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.1575 - mae: 4.6436 - mse: 35.1575\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.1338 - mae: 4.6513 - mse: 35.1338\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35.8456 - mae: 4.6988 - mse: 35.8456\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.9127 - mae: 4.6993 - mse: 35.9127\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35.4361 - mae: 4.6491 - mse: 35.4361\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.0455 - mae: 4.6488 - mse: 35.0455\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.2841 - mae: 4.6384 - mse: 35.2841\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.3799 - mae: 4.6719 - mse: 35.3799\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35.2471 - mae: 4.6459 - mse: 35.2471\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.8449 - mae: 4.6243 - mse: 34.8449\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.5688 - mae: 4.6660 - mse: 35.5688\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35.8361 - mae: 4.6821 - mse: 35.8361\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.8546 - mae: 4.6369 - mse: 34.8546\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.9318 - mae: 4.6375 - mse: 34.9318\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.7577 - mae: 4.6315 - mse: 34.7577\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6212 - mae: 4.6169 - mse: 34.6212\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.7013 - mae: 4.6245 - mse: 34.7013\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.9945 - mae: 4.6259 - mse: 34.9945\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.0445 - mae: 4.6308 - mse: 35.0445\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.5965 - mae: 4.6088 - mse: 34.5965\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.4285 - mae: 4.7420 - mse: 36.4285\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.4897 - mae: 4.7369 - mse: 36.4897\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.9673 - mae: 4.7874 - mse: 36.9673\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.2709 - mae: 4.7126 - mse: 36.2709\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.2728 - mae: 4.6396 - mse: 35.2728\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6727 - mae: 4.6405 - mse: 34.6727\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6000 - mae: 4.6122 - mse: 34.6000\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.5827 - mae: 4.6188 - mse: 34.5827\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.0106 - mae: 4.5639 - mse: 34.0106\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.8653 - mae: 4.5535 - mse: 33.8653\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8323 - mae: 4.5539 - mse: 33.8323\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.1519 - mae: 4.5765 - mse: 34.1519\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.0528 - mae: 4.5734 - mse: 34.0528\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.2034 - mae: 4.5760 - mse: 34.2034\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 34.2506 - mae: 4.6220 - mse: 34.2506\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.7615 - mae: 4.6213 - mse: 34.7615\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 36.7167 - mae: 4.7400 - mse: 36.7167\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 33.3895 - mae: 4.4957 - mse: 33.3895\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.2193 - mae: 4.5133 - mse: 33.2193\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.5766 - mae: 4.5362 - mse: 33.5766\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.7787 - mae: 4.5515 - mse: 33.7787\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.8735 - mae: 4.6477 - mse: 34.8735\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.2368 - mae: 4.5893 - mse: 34.2368\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.5090 - mae: 4.5383 - mse: 33.5090\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.2846 - mae: 4.5228 - mse: 33.2846\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.0547 - mae: 4.5072 - mse: 33.0547\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.0452 - mae: 4.5167 - mse: 33.0452\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.3034 - mae: 4.5481 - mse: 33.3034\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.6612 - mae: 4.5077 - mse: 32.6612\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.5748 - mae: 4.5307 - mse: 33.5748\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.0527 - mae: 4.5061 - mse: 33.0527\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.1000 - mae: 4.4939 - mse: 33.1000\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.6808 - mae: 4.4802 - mse: 32.6808\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.8649 - mae: 4.6184 - mse: 33.8649\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.0167 - mae: 4.6819 - mse: 35.0167\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.2247 - mae: 4.7199 - mse: 35.2247\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.8951 - mae: 4.6477 - mse: 34.8951\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.7232 - mae: 4.5682 - mse: 33.7232\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.7698 - mae: 4.4909 - mse: 32.7698\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.5467 - mae: 4.5653 - mse: 33.5467\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8046 - mae: 4.5968 - mse: 33.8046\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.5030 - mae: 4.4823 - mse: 32.5030\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.3161 - mae: 4.4665 - mse: 32.3161\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.0468 - mae: 4.4600 - mse: 32.0468\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.2003 - mae: 4.4503 - mse: 32.2003\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.6275 - mae: 4.4047 - mse: 31.6275\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.0214 - mae: 4.6602 - mse: 35.0214\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.8254 - mae: 4.5276 - mse: 32.8254\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.8737 - mae: 4.5692 - mse: 33.8737\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.7377 - mae: 4.5853 - mse: 33.7377\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36.0935 - mae: 4.7667 - mse: 36.0935\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.2413 - mae: 4.6169 - mse: 34.2413\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31.9242 - mae: 4.4203 - mse: 31.9242\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.7305 - mae: 4.4342 - mse: 31.7305\n",
            "5/5 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.07586206896551724\n",
            "Precision: 0.06264164476774448\n",
            "Recall: 0.06742475464584997\n",
            "F1-Score: 0.046823432599688554\n",
            "Cohen Kappa Score: 0.2919575466156571\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.1793103448275862\n",
            "Precision: 0.013102334823646299\n",
            "Recall: 0.04185874976950028\n",
            "F1-Score: 0.01818597022981586\n",
            "Cohen Kappa Score: 0.014157581646366824\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.22758620689655173\n",
            "Precision: 0.02292647122317689\n",
            "Recall: 0.05870141852150848\n",
            "F1-Score: 0.031622383252818034\n",
            "Cohen Kappa Score: 0.3677373320950461\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.21379310344827587\n",
            "Precision: 0.018672503966621613\n",
            "Recall: 0.05823486857969617\n",
            "F1-Score: 0.027625527625527623\n",
            "Cohen Kappa Score: 0.33525514731736716\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.14482758620689656\n",
            "Precision: 0.0665727321524423\n",
            "Recall: 0.05219816911275104\n",
            "F1-Score: 0.04874652430207987\n",
            "Cohen Kappa Score: 0.20722865922605194\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2\n",
            "Precision: 0.009090909090909092\n",
            "Recall: 0.045454545454545456\n",
            "F1-Score: 0.015151515151515154\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_160 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_161 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_117 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 24ms/step - loss: 1282.4238 - mae: 35.3180\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 820.9908 - mae: 28.0107\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 643.2705 - mae: 24.6860\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 587.8854 - mae: 23.5603\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 555.1217 - mae: 22.8525\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 529.3053 - mae: 22.2882\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 506.3115 - mae: 21.7764\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 482.6015 - mae: 21.2223\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 464.2353 - mae: 20.7729\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 443.7065 - mae: 20.2753\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 421.7421 - mae: 19.7270\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 406.8469 - mae: 19.3535\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 391.5753 - mae: 18.9455\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 371.7515 - mae: 18.4248\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 354.1385 - mae: 17.9382\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 336.4299 - mae: 17.4170\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 321.0307 - mae: 16.9965\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 306.6015 - mae: 16.5723\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 292.2575 - mae: 16.1251\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 276.1832 - mae: 15.6095\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 258.3145 - mae: 15.0580\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 243.3472 - mae: 14.5795\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 234.4723 - mae: 14.2416\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 222.2094 - mae: 13.8118\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 209.6467 - mae: 13.3532\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 198.3441 - mae: 12.9317\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 185.6316 - mae: 12.4540\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 174.2658 - mae: 12.0133\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 163.2063 - mae: 11.5360\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 154.4761 - mae: 11.1413\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 144.2855 - mae: 10.7341\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 134.1994 - mae: 10.2388\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 128.2442 - mae: 9.9245\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 118.5501 - mae: 9.4671\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 111.0769 - mae: 9.1133\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 102.6233 - mae: 8.7008\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 93.1164 - mae: 8.1589\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 90.4759 - mae: 7.9354\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 82.0949 - mae: 7.5373\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 76.7803 - mae: 7.2348\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 71.4708 - mae: 6.8957\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 66.8544 - mae: 6.6945\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 62.5770 - mae: 6.3838\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 59.3366 - mae: 6.2201\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 54.0497 - mae: 5.8498\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 50.5134 - mae: 5.6619\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 47.4855 - mae: 5.4683\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 44.8153 - mae: 5.3086\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 43.4471 - mae: 5.2440\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 39.9184 - mae: 4.9818\n",
            "5/5 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.06944444444444445\n",
            "Precision: 0.002777777777777778\n",
            "Recall: 0.04\n",
            "F1-Score: 0.005194805194805196\n",
            "Cohen Kappa Score: 0.0\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_80 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_81 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_118 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 12s 66ms/step - loss: 973.8813 - mae: 30.2804\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 479.0744 - mae: 21.1178\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 393.3424 - mae: 18.9882\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 338.0840 - mae: 17.4767\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 288.7479 - mae: 16.0214\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 246.2543 - mae: 14.6597\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 208.9946 - mae: 13.3331\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 173.8520 - mae: 11.9693\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 142.6249 - mae: 10.6407\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 117.5315 - mae: 9.4609\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 94.4926 - mae: 8.1772\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 76.5590 - mae: 7.2508\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 61.3078 - mae: 6.3393\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 51.8640 - mae: 5.7276\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 43.7790 - mae: 5.2968\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 39.3604 - mae: 4.9363\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 36.1466 - mae: 4.6940\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 33.6320 - mae: 4.5991\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 34.6502 - mae: 4.6725\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 33.9052 - mae: 4.6143\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 35.3436 - mae: 4.7371\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 34.8366 - mae: 4.6433\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 35.2999 - mae: 4.6907\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 31.8302 - mae: 4.5199\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 30.9778 - mae: 4.4268\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 31.7847 - mae: 4.4591\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 30.5940 - mae: 4.3746\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 32.3147 - mae: 4.5173\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 31.4012 - mae: 4.4265\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 30.8973 - mae: 4.3952\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 30.0021 - mae: 4.3304\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 31.7713 - mae: 4.4158\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 29.3538 - mae: 4.2544\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 30.1262 - mae: 4.3299\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 29.9934 - mae: 4.3206\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 29.3756 - mae: 4.2583\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 29.1132 - mae: 4.1770\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 29.6343 - mae: 4.2611\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 28.9801 - mae: 4.2720\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 28.3556 - mae: 4.2284\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 28.6356 - mae: 4.1819\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 26.1206 - mae: 4.0516\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 26.0677 - mae: 4.0062\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 25.4226 - mae: 3.9175\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 24.5272 - mae: 3.8256\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 25.3751 - mae: 3.9327\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 23.4499 - mae: 3.7801\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.7466 - mae: 3.8823\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 25.7577 - mae: 3.8985\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 22.3017 - mae: 3.6499\n",
            "5/5 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.0763888888888889\n",
            "Precision: 0.0441010101010101\n",
            "Recall: 0.07095970695970695\n",
            "F1-Score: 0.03356298547787909\n",
            "Cohen Kappa Score: 0.4127196589372413\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_40 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_78 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_39 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_79 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_39 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 48ms/step - loss: 429.1932 - mae: 17.2455 - mse: 429.1932\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 151.8201 - mae: 9.7879 - mse: 151.8201\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 137.3967 - mae: 10.3168 - mse: 137.3967\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 69.9108 - mae: 6.5716 - mse: 69.9108\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 57.3360 - mae: 6.0564 - mse: 57.3360\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 59.9906 - mae: 6.2895 - mse: 59.9906\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 42.3749 - mae: 5.1403 - mse: 42.3749\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 42.0897 - mae: 5.1449 - mse: 42.0897\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41.2370 - mae: 5.0646 - mse: 41.2370\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38.4955 - mae: 4.9039 - mse: 38.4955\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36.2549 - mae: 4.7283 - mse: 36.2549\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38.1011 - mae: 4.8658 - mse: 38.1011\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38.6940 - mae: 4.8816 - mse: 38.6940\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38.0011 - mae: 4.8701 - mse: 38.0011\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36.3091 - mae: 4.7423 - mse: 36.3091\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36.2774 - mae: 4.7567 - mse: 36.2774\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36.1104 - mae: 4.7408 - mse: 36.1104\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35.9775 - mae: 4.7009 - mse: 35.9775\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.7323 - mae: 4.6355 - mse: 34.7323\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34.4300 - mae: 4.6096 - mse: 34.4300\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 34.5847 - mae: 4.6120 - mse: 34.5847\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6147 - mae: 4.6224 - mse: 34.6147\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.3874 - mae: 4.6040 - mse: 34.3874\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.4358 - mae: 4.6049 - mse: 34.4358\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.4160 - mae: 4.6051 - mse: 34.4160\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.2178 - mae: 4.5969 - mse: 34.2178\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.2830 - mae: 4.6107 - mse: 34.2830\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6288 - mae: 4.6338 - mse: 34.6288\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.0063 - mae: 4.5881 - mse: 34.0063\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35.0788 - mae: 4.6639 - mse: 35.0788\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1950 - mae: 4.6111 - mse: 34.1950\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1199 - mae: 4.5810 - mse: 34.1199\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1380 - mae: 4.5880 - mse: 34.1380\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1039 - mae: 4.5779 - mse: 34.1039\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.3929 - mae: 4.6093 - mse: 34.3929\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.9288 - mae: 4.5876 - mse: 33.9288\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.6463 - mae: 4.6237 - mse: 34.6463\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.9759 - mae: 4.5713 - mse: 33.9759\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.6829 - mae: 4.5453 - mse: 33.6829\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.5285 - mae: 4.6238 - mse: 34.5285\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.3985 - mae: 4.6237 - mse: 34.3985\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35.3851 - mae: 4.6953 - mse: 35.3851\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8826 - mae: 4.5936 - mse: 33.8826\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 34.0550 - mae: 4.5916 - mse: 34.0550\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.9659 - mae: 4.5595 - mse: 33.9659\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.7681 - mae: 4.5760 - mse: 33.7681\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.6751 - mae: 4.5501 - mse: 33.6751\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.8571 - mae: 4.5796 - mse: 33.8571\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.0848 - mae: 4.5639 - mse: 34.0848\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.8331 - mae: 4.5779 - mse: 33.8331\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.9083 - mae: 4.5630 - mse: 33.9083\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.3111 - mae: 4.6057 - mse: 34.3111\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.1541 - mae: 4.5169 - mse: 33.1541\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.4717 - mae: 4.5324 - mse: 33.4717\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.6646 - mae: 4.5915 - mse: 33.6646\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.3732 - mae: 4.5815 - mse: 34.3732\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.5211 - mae: 4.6637 - mse: 34.5211\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.8438 - mae: 4.6111 - mse: 34.8438\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.3082 - mae: 4.6129 - mse: 34.3082\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.0584 - mae: 4.5222 - mse: 33.0584\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.8256 - mae: 4.4911 - mse: 32.8256\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.3063 - mae: 4.5295 - mse: 33.3063\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.3706 - mae: 4.5184 - mse: 33.3706\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35.5130 - mae: 4.7459 - mse: 35.5130\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.3435 - mae: 4.6244 - mse: 34.3435\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.5094 - mae: 4.6528 - mse: 34.5094\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35.0111 - mae: 4.6447 - mse: 35.0111\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.6697 - mae: 4.4931 - mse: 32.6697\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.3502 - mae: 4.5627 - mse: 33.3502\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34.2608 - mae: 4.5943 - mse: 34.2608\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.7277 - mae: 4.5040 - mse: 32.7277\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.2917 - mae: 4.4707 - mse: 32.2917\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.7499 - mae: 4.5035 - mse: 32.7499\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.8352 - mae: 4.4881 - mse: 32.8352\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.1494 - mae: 4.4584 - mse: 32.1494\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.7718 - mae: 4.5100 - mse: 32.7718\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.0676 - mae: 4.5073 - mse: 33.0676\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.9587 - mae: 4.4334 - mse: 31.9587\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.4318 - mae: 4.5751 - mse: 33.4318\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.7883 - mae: 4.4797 - mse: 32.7883\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.7938 - mae: 4.4422 - mse: 31.7938\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.7193 - mae: 4.5905 - mse: 33.7193\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.8859 - mae: 4.5626 - mse: 33.8859\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.1250 - mae: 4.5512 - mse: 33.1250\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.4172 - mae: 4.5483 - mse: 33.4172\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.0595 - mae: 4.4533 - mse: 32.0595\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.8468 - mae: 4.5553 - mse: 33.8468\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.5005 - mae: 4.4685 - mse: 32.5005\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.8108 - mae: 4.5580 - mse: 33.8108\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.0436 - mae: 4.4052 - mse: 32.0436\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.3941 - mae: 4.4064 - mse: 31.3941\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.2939 - mae: 4.3971 - mse: 31.2939\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31.4679 - mae: 4.4059 - mse: 31.4679\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.9511 - mae: 4.4413 - mse: 31.9511\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.5924 - mae: 4.4248 - mse: 31.5924\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31.7613 - mae: 4.4062 - mse: 31.7613\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.9727 - mae: 4.6069 - mse: 33.9727\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.8451 - mae: 4.4468 - mse: 31.8451\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.0630 - mae: 4.4352 - mse: 32.0630\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.8619 - mae: 4.5714 - mse: 32.8619\n",
            "5/5 [==============================] - 0s 20ms/step\n",
            "Accuracy: 0.0763888888888889\n",
            "Precision: 0.036325668596636336\n",
            "Recall: 0.03881684981684982\n",
            "F1-Score: 0.025293419224453707\n",
            "Cohen Kappa Score: 0.2634493416181064\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.1597222222222222\n",
            "Precision: 0.008270406328658756\n",
            "Recall: 0.02184235517568851\n",
            "F1-Score: 0.011997913406364111\n",
            "Cohen Kappa Score: 0.09602928752464113\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.25\n",
            "Precision: 0.023344848221085845\n",
            "Recall: 0.04325832897261468\n",
            "F1-Score: 0.028811524609843937\n",
            "Cohen Kappa Score: 0.5946645234787125\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.2777777777777778\n",
            "Precision: 0.01788787483702738\n",
            "Recall: 0.05259697567389875\n",
            "F1-Score: 0.026688186298527247\n",
            "Cohen Kappa Score: 0.46262464966396544\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.10416666666666667\n",
            "Precision: 0.02710084033613445\n",
            "Recall: 0.03012166405023548\n",
            "F1-Score: 0.02725842165497338\n",
            "Cohen Kappa Score: 0.3049230631285835\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2708333333333333\n",
            "Precision: 0.010833333333333332\n",
            "Recall: 0.04\n",
            "F1-Score: 0.01704918032786885\n",
            "Cohen Kappa Score: 0.0\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "-----------------------LSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_164 (LSTM)             (None, 1, 400)            1870400   \n",
            "                                                                 \n",
            " lstm_165 (LSTM)             (None, 128)               270848    \n",
            "                                                                 \n",
            " dropout_119 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,377\n",
            "Trainable params: 2,141,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 36ms/step - loss: 1294.4977 - mae: 35.4906\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 846.9243 - mae: 28.4605\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 650.3871 - mae: 24.8238\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 591.9575 - mae: 23.6352\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 557.7878 - mae: 22.9201\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 534.0657 - mae: 22.3894\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 508.3276 - mae: 21.8080\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 487.0663 - mae: 21.3193\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 467.9074 - mae: 20.8559\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 445.8421 - mae: 20.3416\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 428.5930 - mae: 19.9031\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 411.5456 - mae: 19.4552\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 390.9969 - mae: 18.9333\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 372.1050 - mae: 18.4362\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 356.8445 - mae: 18.0310\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 339.0799 - mae: 17.5254\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 323.6455 - mae: 17.0684\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 306.6518 - mae: 16.5831\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 292.7567 - mae: 16.1503\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 278.4848 - mae: 15.7136\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 262.7827 - mae: 15.2005\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 250.6526 - mae: 14.8147\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 236.2817 - mae: 14.3178\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 223.3657 - mae: 13.9125\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 211.9271 - mae: 13.4515\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 199.0917 - mae: 12.9954\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 188.1215 - mae: 12.5847\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 176.2102 - mae: 12.1068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 167.9009 - mae: 11.7269\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 155.3413 - mae: 11.2200\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 147.4847 - mae: 10.9164\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 136.0855 - mae: 10.3622\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 127.0929 - mae: 9.9038\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 118.7617 - mae: 9.5175\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 110.8029 - mae: 9.1087\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 103.8987 - mae: 8.7598\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 95.1756 - mae: 8.3392\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 89.9849 - mae: 7.9667\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 83.8130 - mae: 7.6132\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 75.7567 - mae: 7.1747\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 72.3975 - mae: 6.9894\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 68.2218 - mae: 6.7143\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 63.0243 - mae: 6.4377\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 60.5465 - mae: 6.3515\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 54.5584 - mae: 5.9620\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 51.6313 - mae: 5.7063\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 49.6111 - mae: 5.6406\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 47.9157 - mae: 5.5418\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 43.8816 - mae: 5.3028\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 41.8539 - mae: 5.0764\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.09722222222222222\n",
            "Precision: 0.0037393162393162395\n",
            "Recall: 0.038461538461538464\n",
            "F1-Score: 0.006815968841285297\n",
            "Cohen Kappa Score: 0.0\n",
            "-----------------------BiLSTM-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_82 (Bidirecti  (None, 1, 600)           2565600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_83 (Bidirecti  (None, 200)              560800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_120 (Dropout)       (None, 200)               0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,126,601\n",
            "Trainable params: 3,126,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 11s 34ms/step - loss: 942.6613 - mae: 29.7791\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 454.5901 - mae: 20.5195\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 372.0333 - mae: 18.4272\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 317.9438 - mae: 16.9004\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 271.0468 - mae: 15.4870\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 230.0990 - mae: 14.1190\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 194.2931 - mae: 12.7991\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 158.8088 - mae: 11.3922\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 131.1190 - mae: 10.1341\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 106.5825 - mae: 8.9315\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 86.5614 - mae: 7.8542\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 71.1698 - mae: 6.9427\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 59.1683 - mae: 6.2205\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 47.6990 - mae: 5.5054\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 40.8047 - mae: 5.0618\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 38.8902 - mae: 4.9058\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 37.0591 - mae: 4.8116\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 34.9198 - mae: 4.6384\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 35.6695 - mae: 4.7473\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 34.8741 - mae: 4.6840\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 34.5902 - mae: 4.6656\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 35.3461 - mae: 4.7141\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 35.6892 - mae: 4.7142\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 34.8254 - mae: 4.6629\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 33.5953 - mae: 4.5908\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 32.3475 - mae: 4.4821\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 30.8684 - mae: 4.4021\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 29.5886 - mae: 4.2818\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 30.3719 - mae: 4.4115\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 30.5729 - mae: 4.2872\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 31.5276 - mae: 4.4344\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 29.5459 - mae: 4.2600\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 28.9402 - mae: 4.2594\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 29.6668 - mae: 4.3367\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 30.1738 - mae: 4.2791\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 31.0900 - mae: 4.3998\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 29.8277 - mae: 4.3330\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 29.1763 - mae: 4.2394\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 29.4832 - mae: 4.2650\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 27.5834 - mae: 4.0819\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 28.9029 - mae: 4.1895\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 28.1032 - mae: 4.1892\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 27.3805 - mae: 4.0758\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 26.6660 - mae: 4.0616\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 26.7590 - mae: 4.0631\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 25.5742 - mae: 3.9650\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 26.3358 - mae: 4.0116\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 25.2997 - mae: 3.9525\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 23.8903 - mae: 3.8422\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 25.3539 - mae: 3.8795\n",
            "5/5 [==============================] - 2s 7ms/step\n",
            "Accuracy: 0.08333333333333333\n",
            "Precision: 0.03854261680348637\n",
            "Recall: 0.04430079724197371\n",
            "F1-Score: 0.036877367646598415\n",
            "Cohen Kappa Score: 0.3495194245307214\n",
            "-----------------------CNN-----------------------\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_41 (InputLayer)       [(None, 768, 1)]          0         \n",
            "                                                                 \n",
            " conv1d_80 (Conv1D)          (None, 768, 64)           256       \n",
            "                                                                 \n",
            " max_pooling1d_40 (MaxPoolin  (None, 384, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_81 (Conv1D)          (None, 384, 128)          24704     \n",
            "                                                                 \n",
            " global_max_pooling1d_40 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,089\n",
            "Trainable params: 25,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 19ms/step - loss: 470.7773 - mae: 17.8353 - mse: 470.7773\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 116.0254 - mae: 8.8034 - mse: 116.0254\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 80.7609 - mae: 7.4088 - mse: 80.7609\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 61.3979 - mae: 6.2532 - mse: 61.3979\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 49.8810 - mae: 5.6440 - mse: 49.8810\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41.6743 - mae: 5.1920 - mse: 41.6743\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37.9582 - mae: 4.8057 - mse: 37.9582\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36.0717 - mae: 4.7828 - mse: 36.0717\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.9550 - mae: 4.7181 - mse: 34.9550\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.8634 - mae: 4.6518 - mse: 34.8634\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35.0286 - mae: 4.7125 - mse: 35.0286\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34.7517 - mae: 4.6485 - mse: 34.7517\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34.7500 - mae: 4.6515 - mse: 34.7500\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.9802 - mae: 4.6020 - mse: 33.9802\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.0295 - mae: 4.6074 - mse: 34.0295\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.2888 - mae: 4.6058 - mse: 34.2888\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.9907 - mae: 4.5902 - mse: 33.9907\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.3624 - mae: 4.6161 - mse: 34.3624\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.8883 - mae: 4.5811 - mse: 33.8883\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.6818 - mae: 4.5881 - mse: 33.6818\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.7898 - mae: 4.5838 - mse: 33.7898\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33.7872 - mae: 4.6156 - mse: 33.7872\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.7300 - mae: 4.6018 - mse: 33.7300\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.1631 - mae: 4.6484 - mse: 35.1631\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34.1867 - mae: 4.6202 - mse: 34.1867\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.4001 - mae: 4.5741 - mse: 33.4001\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 34.5563 - mae: 4.6443 - mse: 34.5563\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.3805 - mae: 4.5479 - mse: 33.3805\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 33.3420 - mae: 4.5491 - mse: 33.3420\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.9684 - mae: 4.6117 - mse: 33.9684\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.6146 - mae: 4.5807 - mse: 33.6146\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34.1054 - mae: 4.5983 - mse: 34.1054\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.1732 - mae: 4.5426 - mse: 33.1732\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.9591 - mae: 4.5290 - mse: 32.9591\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.2386 - mae: 4.5666 - mse: 33.2386\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.1373 - mae: 4.5363 - mse: 33.1373\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35.0513 - mae: 4.6246 - mse: 35.0513\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34.5074 - mae: 4.6310 - mse: 34.5074\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 34.0390 - mae: 4.5936 - mse: 34.0390\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34.1591 - mae: 4.6322 - mse: 34.1591\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.6652 - mae: 4.5149 - mse: 32.6652\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.5633 - mae: 4.5044 - mse: 32.5633\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.6157 - mae: 4.5115 - mse: 32.6157\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33.9918 - mae: 4.6387 - mse: 33.9918\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.7974 - mae: 4.4883 - mse: 32.7974\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.6562 - mae: 4.5138 - mse: 32.6562\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32.6812 - mae: 4.5174 - mse: 32.6812\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.1320 - mae: 4.5424 - mse: 33.1320\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 32.4998 - mae: 4.4850 - mse: 32.4998\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.1338 - mae: 4.4776 - mse: 32.1338\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.0424 - mae: 4.4785 - mse: 32.0424\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31.9010 - mae: 4.4537 - mse: 31.9010\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.1397 - mae: 4.4685 - mse: 32.1397\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.3774 - mae: 4.5254 - mse: 33.3774\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.6924 - mae: 4.5386 - mse: 32.6924\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.4188 - mae: 4.5023 - mse: 32.4188\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32.0143 - mae: 4.4446 - mse: 32.0143\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.5473 - mae: 4.5364 - mse: 32.5473\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.1982 - mae: 4.5339 - mse: 33.1982\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35.3211 - mae: 4.7270 - mse: 35.3211\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 34.6656 - mae: 4.6318 - mse: 34.6656\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35.0981 - mae: 4.6580 - mse: 35.0981\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.6865 - mae: 4.5723 - mse: 33.6865\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 37.4132 - mae: 4.8744 - mse: 37.4132\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33.0683 - mae: 4.5151 - mse: 33.0683\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33.4904 - mae: 4.5588 - mse: 33.4904\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.4040 - mae: 4.5248 - mse: 32.4040\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.9277 - mae: 4.3930 - mse: 30.9277\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31.0274 - mae: 4.4006 - mse: 31.0274\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31.0363 - mae: 4.3965 - mse: 31.0363\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 31.3584 - mae: 4.4159 - mse: 31.3584\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.9358 - mae: 4.3981 - mse: 30.9358\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.5281 - mae: 4.4012 - mse: 31.5281\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31.3750 - mae: 4.4329 - mse: 31.3750\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32.8705 - mae: 4.5372 - mse: 32.8705\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.8243 - mae: 4.4947 - mse: 31.8243\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33.1769 - mae: 4.5811 - mse: 33.1769\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30.7353 - mae: 4.3762 - mse: 30.7353\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.7780 - mae: 4.4484 - mse: 31.7780\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31.1867 - mae: 4.4379 - mse: 31.1867\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31.2290 - mae: 4.4358 - mse: 31.2290\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32.2905 - mae: 4.4482 - mse: 32.2905\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32.0331 - mae: 4.4723 - mse: 32.0331\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31.8632 - mae: 4.4316 - mse: 31.8632\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30.2611 - mae: 4.3349 - mse: 30.2611\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.6419 - mae: 4.3715 - mse: 30.6419\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.2055 - mae: 4.3497 - mse: 30.2055\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.5418 - mae: 4.3602 - mse: 30.5418\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30.4752 - mae: 4.3643 - mse: 30.4752\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30.6782 - mae: 4.3779 - mse: 30.6782\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30.4223 - mae: 4.3862 - mse: 30.4223\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31.4999 - mae: 4.4482 - mse: 31.4999\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32.3051 - mae: 4.5040 - mse: 32.3051\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32.7702 - mae: 4.5367 - mse: 32.7702\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.6680 - mae: 4.3801 - mse: 30.6680\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30.6317 - mae: 4.3816 - mse: 30.6317\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30.0242 - mae: 4.3256 - mse: 30.0242\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32.1727 - mae: 4.4642 - mse: 32.1727\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30.4029 - mae: 4.3549 - mse: 30.4029\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29.9201 - mae: 4.2941 - mse: 29.9201\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.10416666666666667\n",
            "Precision: 0.08103038936372269\n",
            "Recall: 0.07182846202454046\n",
            "F1-Score: 0.05433047793613387\n",
            "Cohen Kappa Score: 0.3289968432278102\n",
            "\n",
            "-----------------------Logistic Regression-----------------------\n",
            "Accuracy: 0.19444444444444445\n",
            "Precision: 0.03496503496503497\n",
            "Recall: 0.07187028657616892\n",
            "F1-Score: 0.0449128862590401\n",
            "Cohen Kappa Score: -0.002986174549195031\n",
            "\n",
            "\n",
            "-----------------------Random Forest Classifier-----------------------\n",
            "Accuracy: 0.2569444444444444\n",
            "Precision: 0.07430168263501596\n",
            "Recall: 0.05692027652811967\n",
            "F1-Score: 0.04358595113217802\n",
            "Cohen Kappa Score: 0.3934533297404442\n",
            "\n",
            "\n",
            "-----------------------Adaboost Classifier-----------------------\n",
            "Accuracy: 0.24305555555555555\n",
            "Precision: 0.016025641025641024\n",
            "Recall: 0.04432332373508844\n",
            "F1-Score: 0.021980900189386306\n",
            "Cohen Kappa Score: 0.2598649749738099\n",
            "\n",
            "\n",
            "-----------------------K Neibhors Classifier-----------------------\n",
            "Accuracy: 0.09722222222222222\n",
            "Precision: 0.01594454396178534\n",
            "Recall: 0.025293502981129756\n",
            "F1-Score: 0.01905884664505354\n",
            "Cohen Kappa Score: 0.25345783711476777\n",
            "\n",
            "\n",
            "-----------------------Support Vector Classifier-----------------------\n",
            "Accuracy: 0.2361111111111111\n",
            "Precision: 0.00908119658119658\n",
            "Recall: 0.038461538461538464\n",
            "F1-Score: 0.014693171996542782\n",
            "Cohen Kappa Score: 0.0\n",
            "Time taken: 364.66410 seconds\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|           Model           | Accuracy | Precision | Recall | F1-Score | Kappa Score |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n",
            "|            LSTM           |  0.097   |   0.004   | 0.045  |  0.007   |    0.000    |\n",
            "|           BiLSTM          |  0.117   |   0.044   | 0.071  |  0.037   |    0.413    |\n",
            "|            CNN            |  0.104   |   0.081   | 0.072  |  0.054   |    0.329    |\n",
            "|    Logistic Regression    |  0.234   |   0.048   | 0.072  |  0.045   |    0.184    |\n",
            "|  Random Forest Classifier |  0.257   |   0.074   | 0.059  |  0.044   |    0.595    |\n",
            "|    Adaboost Classifier    |  0.278   |   0.019   | 0.058  |  0.028   |    0.463    |\n",
            "|   K Neighbors Classifier  |  0.145   |   0.067   | 0.052  |  0.049   |    0.365    |\n",
            "| Support Vector Classifier |  0.271   |   0.011   | 0.045  |  0.017   |    0.000    |\n",
            "+---------------------------+----------+-----------+--------+----------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ik2_6Xa5Q9z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metric names and their corresponding values\n",
        "metric_names = [\"Prompt-1\",\"Prompt-2\",\"Prompt-3\",\"Prompt-4\",\"Prompt-5\",\"Prompt-6\",\"Prompt-7\",\"Prompt-8\"]\n",
        "\n",
        "metrics_list=[final_lstm, final_bilstm, final_cnn, final_logistic_reg, final_random_forest, final_adaboost, final_k_neighbors, final_svc]\n",
        "# Define the ML model names\n",
        "model_names = [\"LSTM\",\"BiLSTM\",\"CNN\",\"Logistic Regression\", \"Random Forest Classifier\", \"Adaboost Classifier\", \n",
        "              \"K Neighbors Classifier\", \"Support Vector Classifier\"]\n",
        "\n",
        "table = PrettyTable([\"Model\"] + metric_names)\n",
        "\n",
        "  # Add the metric values for each model as rows to the table\n",
        "for i, model_name in enumerate(model_names):\n",
        "    row = [model_name]\n",
        "    for j in range(len(metric_names)):\n",
        "        value = metrics_list[i][j]\n",
        "\n",
        "        # Format the value with three decimal places\n",
        "        value_formatted = f\"{value:.3f}\"\n",
        "        row.append(value_formatted)\n",
        "\n",
        "    table.add_row(row)\n",
        "\n",
        "# Print the formatted table\n",
        "print(table.get_string())\n"
      ],
      "metadata": {
        "id": "lcQx-GeVQ91N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbea42da-a015-4da2-ffd3-1e95e6f91f59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|           Model           | Prompt-1 | Prompt-2 | Prompt-3 | Prompt-4 | Prompt-5 | Prompt-6 | Prompt-7 | Prompt-8 |\n",
            "+---------------------------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|            LSTM           |  0.780   |  0.610   |  0.690   |  0.655   |  0.753   |  0.600   |  0.590   |  0.000   |\n",
            "|           BiLSTM          |  0.798   |  0.633   |  0.698   |  0.678   |  0.804   |  0.642   |  0.666   |  0.413   |\n",
            "|            CNN            |  0.450   |  0.000   |  0.000   |  0.000   |  0.000   |  0.000   |  0.396   |  0.329   |\n",
            "|    Logistic Regression    |  0.677   |  0.484   |  0.709   |  0.706   |  0.794   |  0.645   |  0.587   |  0.184   |\n",
            "|  Random Forest Classifier |  0.786   |  0.693   |  0.694   |  0.738   |  0.813   |  0.695   |  0.670   |  0.595   |\n",
            "|    Adaboost Classifier    |  0.654   |  0.633   |  0.616   |  0.764   |  0.730   |  0.651   |  0.587   |  0.463   |\n",
            "|   K Neighbors Classifier  |  0.755   |  0.555   |  0.597   |  0.648   |  0.717   |  0.572   |  0.492   |  0.365   |\n",
            "| Support Vector Classifier |  0.221   |  0.226   |  0.000   |  0.000   |  0.000   |  0.000   |  0.000   |  0.000   |\n",
            "+---------------------------+----------+----------+----------+----------+----------+----------+----------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(metrics_list)\n",
        "final_df.to_csv('GPT_2.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "zUEznlbonIPs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWkP_M5Qnfzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}