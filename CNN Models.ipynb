{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "337f41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tensorflow.keras.layers import Input, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2535ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ASAP Dataset/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0911b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>word_len</th>\n",
       "      <th>chars_len</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>pos_ratios</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>sentiment_polariy</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>1875</td>\n",
       "      <td>3.984456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.031088082901554404, 'JJ': 0.05181347...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>2288</td>\n",
       "      <td>4.030172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.03879310344827586, ',': 0.0258620689...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.613167</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>1541</td>\n",
       "      <td>4.035144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.04153354632587859, ',': 0.0287539936...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340393</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>dear people use computer everyone agrees benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>611</td>\n",
       "      <td>3165</td>\n",
       "      <td>4.328969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.11620294599018004, ',': 0.0212765957...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266828</td>\n",
       "      <td>0.441795</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>517</td>\n",
       "      <td>2569</td>\n",
       "      <td>4.071567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.017408123791102514, ',': 0.025145067...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199684</td>\n",
       "      <td>0.485814</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  word_len  chars_len  \\\n",
       "0             NaN             NaN            NaN  ...       386       1875   \n",
       "1             NaN             NaN            NaN  ...       464       2288   \n",
       "2             NaN             NaN            NaN  ...       313       1541   \n",
       "3             NaN             NaN            NaN  ...       611       3165   \n",
       "4             NaN             NaN            NaN  ...       517       2569   \n",
       "\n",
       "   avg_word_length  avg_sentence_length  \\\n",
       "0         3.984456                  1.0   \n",
       "1         4.030172                  1.0   \n",
       "2         4.035144                  1.0   \n",
       "3         4.328969                  1.0   \n",
       "4         4.071567                  1.0   \n",
       "\n",
       "                                          pos_ratios  num_sentences  \\\n",
       "0  {'NNP': 0.031088082901554404, 'JJ': 0.05181347...             16   \n",
       "1  {'NNP': 0.03879310344827586, ',': 0.0258620689...             20   \n",
       "2  {'NNP': 0.04153354632587859, ',': 0.0287539936...             14   \n",
       "3  {'NNP': 0.11620294599018004, ',': 0.0212765957...             27   \n",
       "4  {'NNP': 0.017408123791102514, ',': 0.025145067...             30   \n",
       "\n",
       "   num_paragraphs  sentiment_polariy  sentiment_subjectivity  \\\n",
       "0               1           0.310471                0.385613   \n",
       "1               1           0.274000                0.613167   \n",
       "2               1           0.340393                0.498657   \n",
       "3               1           0.266828                0.441795   \n",
       "4               1           0.199684                0.485814   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  dear local newspaper think effect computer peo...  \n",
       "1  dear believe using computer benefit u many way...  \n",
       "2  dear people use computer everyone agrees benef...  \n",
       "3  dear local newspaper found many expert say com...  \n",
       "4  dear know computer positive effect people comp...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f279fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 1, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "714dc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['essay_id', 'pos_ratios', 'essay']\n",
    "df.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "202d5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the precision score between the true and predicted values\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    return precision\n",
    "\n",
    "def calc_recall(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the recall score between the true and predicted values\n",
    "    \"\"\"\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return recall\n",
    "\n",
    "def calc_f1_score(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the f1-score between the true and predicted values\n",
    "    \"\"\"\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    return f1\n",
    "\n",
    "def calc_cohen_kappa_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the cohen kappa score between the true and predicted values\n",
    "    \"\"\"\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "    return kappa_score\n",
    "\n",
    "def calc_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy score between the true and predicted values\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e0caeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    # Calculate and print accuracy\n",
    "    accuracy = calc_accuracy(y_actual, y_predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Calculate and print precision\n",
    "    precision = calc_precision(y_actual, y_predictions)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculate and print recall\n",
    "    recall = calc_recall(y_actual, y_predictions)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Calculate and print f1-score\n",
    "    f1 = calc_f1_score(y_actual, y_predictions)\n",
    "    print(\"F1-Score:\", f1)\n",
    "\n",
    "    # Calculate and print Cohen Kappa Score\n",
    "    kappa_score = calc_cohen_kappa_score(y_actual, y_predictions)\n",
    "    print(\"Cohen Kappa Score:\", kappa_score)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "843d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set1 = df[df.essay_set == 1]\n",
    "df_essay_set2 = df[df.essay_set == 2]\n",
    "df_essay_set3 = df[df.essay_set == 3]\n",
    "df_essay_set4 = df[df.essay_set == 4]\n",
    "df_essay_set5 = df[df.essay_set == 5]\n",
    "df_essay_set6 = df[df.essay_set == 6]\n",
    "df_essay_set7 = df[df.essay_set == 7]\n",
    "df_essay_set8 = df[df.essay_set == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5a973dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data, target = 'domain1_score'):\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "49839012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set1, y_set1 = dataset_preparation(df_essay_set1)\n",
    "X_set2, y_set2 = dataset_preparation(df_essay_set2)\n",
    "X_set3, y_set3 = dataset_preparation(df_essay_set3)\n",
    "X_set4, y_set4 = dataset_preparation(df_essay_set4)\n",
    "X_set5, y_set5 = dataset_preparation(df_essay_set5)\n",
    "X_set6, y_set6 = dataset_preparation(df_essay_set6)\n",
    "X_set7, y_set7 = dataset_preparation(df_essay_set7)\n",
    "X_set8, y_set8 = dataset_preparation(df_essay_set8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3bfb3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set1, X_test_set1, y_train_set1, y_test_set1 = train_test_split(X_set1, y_set1, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set2, X_test_set2, y_train_set2, y_test_set2 = train_test_split(X_set2, y_set2, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set3, X_test_set3, y_train_set3, y_test_set3 = train_test_split(X_set3, y_set3, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set4, X_test_set4, y_train_set4, y_test_set4 = train_test_split(X_set4, y_set4, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set5, X_test_set5, y_train_set5, y_test_set5 = train_test_split(X_set5, y_set5, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set6, X_test_set6, y_train_set6, y_test_set6 = train_test_split(X_set6, y_set6, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set7, X_test_set7, y_train_set7, y_test_set7 = train_test_split(X_set7, y_set7, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)\n",
    "\n",
    "X_train_set8, X_test_set8, y_train_set8, y_test_set8 = train_test_split(X_set8, y_set8, shuffle = True, \n",
    "                                                                       random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "318ca95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shapes(X_train, X_test, y_train, y_test, \n",
    "                 set_value = \"Essay Set-1\"):\n",
    "    \n",
    "    print(f\"------------------------{set_value}------------------------\")\n",
    "    print(\"The shape of input train data: {}\".format(X_train.shape))\n",
    "    print(\"The shape of input test data: {}\".format(X_test.shape))\n",
    "    print(\"The shape of output train data: {}\".format(y_train.shape))\n",
    "    print(\"The shape of output test data: {}\".format(y_test.shape))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cc798329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Essay Set-1------------------------\n",
      "The shape of input train data: (1426, 12)\n",
      "The shape of input test data: (357, 12)\n",
      "The shape of output train data: (1426,)\n",
      "The shape of output test data: (357,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-2------------------------\n",
      "The shape of input train data: (1440, 12)\n",
      "The shape of input test data: (360, 12)\n",
      "The shape of output train data: (1440,)\n",
      "The shape of output test data: (360,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-3------------------------\n",
      "The shape of input train data: (1380, 12)\n",
      "The shape of input test data: (346, 12)\n",
      "The shape of output train data: (1380,)\n",
      "The shape of output test data: (346,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-4------------------------\n",
      "The shape of input train data: (1416, 12)\n",
      "The shape of input test data: (354, 12)\n",
      "The shape of output train data: (1416,)\n",
      "The shape of output test data: (354,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-5------------------------\n",
      "The shape of input train data: (1444, 12)\n",
      "The shape of input test data: (361, 12)\n",
      "The shape of output train data: (1444,)\n",
      "The shape of output test data: (361,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-6------------------------\n",
      "The shape of input train data: (1440, 12)\n",
      "The shape of input test data: (360, 12)\n",
      "The shape of output train data: (1440,)\n",
      "The shape of output test data: (360,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-7------------------------\n",
      "The shape of input train data: (1255, 12)\n",
      "The shape of input test data: (314, 12)\n",
      "The shape of output train data: (1255,)\n",
      "The shape of output test data: (314,)\n",
      "\n",
      "\n",
      "------------------------Essay Set-8------------------------\n",
      "The shape of input train data: (578, 12)\n",
      "The shape of input test data: (145, 12)\n",
      "The shape of output train data: (578,)\n",
      "The shape of output test data: (145,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_shapes(X_train_set1, X_test_set1, y_train_set1, y_test_set1)\n",
    "print_shapes(X_train_set2, X_test_set2, y_train_set2, y_test_set2, set_value = \"Essay Set-2\")\n",
    "print_shapes(X_train_set3, X_test_set3, y_train_set3, y_test_set3, set_value = \"Essay Set-3\")\n",
    "print_shapes(X_train_set4, X_test_set4, y_train_set4, y_test_set4, set_value = \"Essay Set-4\")\n",
    "print_shapes(X_train_set5, X_test_set5, y_train_set5, y_test_set5, set_value = \"Essay Set-5\")\n",
    "print_shapes(X_train_set6, X_test_set6, y_train_set6, y_test_set6, set_value = \"Essay Set-6\")\n",
    "print_shapes(X_train_set7, X_test_set7, y_train_set7, y_test_set7, set_value = \"Essay Set-7\")\n",
    "print_shapes(X_train_set8, X_test_set8, y_train_set8, y_test_set8, set_value = \"Essay Set-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0987c4e",
   "metadata": {},
   "source": [
    "### Bag-of-Words Representation + Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "52b1e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(train_data, test_data, column = 'preprocessed_text'):\n",
    "    \n",
    "    X_train_corpus = train_data[column]\n",
    "    X_test_corpus = test_data[column]\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_bow = vectorizer.fit_transform(X_train_corpus)\n",
    "    X_test_bow = vectorizer.transform(X_test_corpus)\n",
    "    X_train_bow = pd.DataFrame(X_train_bow.toarray(), columns = vectorizer.get_feature_names())\n",
    "    X_test_bow = pd.DataFrame(X_test_bow.toarray(), columns = vectorizer.get_feature_names())\n",
    "    X_train_features = train_data.drop([column], axis = 1)\n",
    "    X_test_features = test_data.drop([column], axis = 1)\n",
    "    X_train_features.reset_index(drop = True, inplace = True)\n",
    "    X_test_features.reset_index(drop = True, inplace = True)\n",
    "    X_train_final = pd.concat([X_train_bow, X_train_features], axis = 1)\n",
    "    X_test_final = pd.concat([X_test_bow, X_test_features], axis = 1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_final = scaler.fit_transform(X_train_final)\n",
    "    X_test_final = scaler.transform(X_test_final)\n",
    "    \n",
    "    return X_train_final, X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c6ced045",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_test_final = feature_engineering(X_train_set1, X_test_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8619c9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>word_len</th>\n",
       "      <th>chars_len</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>sentiment_polariy</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>386</td>\n",
       "      <td>1875</td>\n",
       "      <td>3.984456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>464</td>\n",
       "      <td>2288</td>\n",
       "      <td>4.030172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.613167</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>313</td>\n",
       "      <td>1541</td>\n",
       "      <td>4.035144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340393</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>dear people use computer everyone agrees benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>611</td>\n",
       "      <td>3165</td>\n",
       "      <td>4.328969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266828</td>\n",
       "      <td>0.441795</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>2569</td>\n",
       "      <td>4.071567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199684</td>\n",
       "      <td>0.485814</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set  rater1_domain1  rater2_domain1  domain1_score  word_len  \\\n",
       "0          1               4               4              8       386   \n",
       "1          1               5               4              9       464   \n",
       "2          1               4               3              7       313   \n",
       "3          1               5               5             10       611   \n",
       "4          1               4               4              8       517   \n",
       "\n",
       "   chars_len  avg_word_length  avg_sentence_length  num_sentences  \\\n",
       "0       1875         3.984456                  1.0             16   \n",
       "1       2288         4.030172                  1.0             20   \n",
       "2       1541         4.035144                  1.0             14   \n",
       "3       3165         4.328969                  1.0             27   \n",
       "4       2569         4.071567                  1.0             30   \n",
       "\n",
       "   num_paragraphs  sentiment_polariy  sentiment_subjectivity  \\\n",
       "0               1           0.310471                0.385613   \n",
       "1               1           0.274000                0.613167   \n",
       "2               1           0.340393                0.498657   \n",
       "3               1           0.266828                0.441795   \n",
       "4               1           0.199684                0.485814   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  dear local newspaper think effect computer peo...  \n",
       "1  dear believe using computer benefit u many way...  \n",
       "2  dear people use computer everyone agrees benef...  \n",
       "3  dear local newspaper found many expert say com...  \n",
       "4  dear know computer positive effect people comp...  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "85b5f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_set', 'rater1_domain1', 'rater2_domain1', 'domain1_score',\n",
       "       'word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
       "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
       "       'sentiment_subjectivity', 'preprocessed_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da8ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bbcad5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346    dear local people using computer year good hea...\n",
       "1349    dear newspaper believe computer positive affec...\n",
       "7       people agree computer make life le complicated...\n",
       "1251    dear world changed much better technology beco...\n",
       "661     technology growing changing rapidly look apple...\n",
       "                              ...                        \n",
       "599     dear know becoming reaching computer helpful m...\n",
       "1599    although many people love computer palying vid...\n",
       "1361    dear local newspaper think computer bad effect...\n",
       "1547    dear local newspaper agree expert said compute...\n",
       "863     dear local newspaper opinion computer everythi...\n",
       "Name: preprocessed_text, Length: 1426, dtype: object"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_set1['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4b02353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_kappa(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the quadratic Cohen's kappa score for two arrays of labels\n",
    "    \"\"\"\n",
    "    # Convert predicted probabilities to integer labels\n",
    "    y_pred_labels = tf.math.argmax(y_pred, axis=1)\n",
    "    y_true_labels = tf.math.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Calculate the quadratic kappa score\n",
    "    kappa = cohen_kappa_score(y_true_labels, y_pred_labels, weights='quadratic')\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24646f",
   "metadata": {},
   "source": [
    "### CNN Configuration - 1 Model (Essay Set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d4288969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_sentences  num_paragraphs\n",
       "1346             37               1\n",
       "1349             15               1\n",
       "7                39               1\n",
       "1251             31               1\n",
       "661              26               1\n",
       "...             ...             ...\n",
       "599              10               1\n",
       "1599             18               1\n",
       "1361             18               1\n",
       "1547             12               1\n",
       "863              17               1\n",
       "\n",
       "[1426 rows x 2 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4e6fbda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_set1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0f41b332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y_train_set1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1fa941a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 500)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "af1c4b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 13)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_set1_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deea8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "28ba79bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12789"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "44acf202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 500)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ff778688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 500)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "034d7763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 13)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_set1_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "30fb64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train_set1[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test_set1[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1fed5f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 500) for input Tensor(\"input_61:0\", shape=(None, 500), dtype=float32), but it was called on an input with incompatible shape (None, 508).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 500) for input Tensor(\"input_61:0\", shape=(None, 500), dtype=float32), but it was called on an input with incompatible shape (None, 508).\n",
      "44/45 [============================>.] - ETA: 0s - loss: 2.2873 - accuracy: 0.3786WARNING:tensorflow:Model was constructed with shape (None, 500) for input Tensor(\"input_61:0\", shape=(None, 500), dtype=float32), but it was called on an input with incompatible shape (None, 508).\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 2.2815 - accuracy: 0.3794 - val_loss: 2.0309 - val_accuracy: 0.3641\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.9092 - accuracy: 0.3906 - val_loss: 1.8274 - val_accuracy: 0.3641\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.7623 - accuracy: 0.3913 - val_loss: 1.7663 - val_accuracy: 0.3641\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.7035 - accuracy: 0.3885 - val_loss: 1.7536 - val_accuracy: 0.3641\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.6387 - accuracy: 0.3969 - val_loss: 1.7319 - val_accuracy: 0.3641\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 1.5637 - accuracy: 0.4313 - val_loss: 1.7071 - val_accuracy: 0.3810\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.4551 - accuracy: 0.4839 - val_loss: 1.6914 - val_accuracy: 0.3669\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.3292 - accuracy: 0.5281 - val_loss: 1.6874 - val_accuracy: 0.3669\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.2315 - accuracy: 0.5589 - val_loss: 1.6722 - val_accuracy: 0.3641\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1016 - accuracy: 0.6206 - val_loss: 1.6805 - val_accuracy: 0.3641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c1c381c10>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_set1['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train_set1['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test_set1['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 500\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "y_train_set1_categorical = to_categorical(y_train_set1)\n",
    "y_test_set1_categorical = to_categorical(y_test_set1)\n",
    "\n",
    "X_train_additional_features = X_train_set1[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test_set1[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train_set1_categorical.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train_set1_categorical, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test_set1_categorical))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1fbb3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3641456582633053\n",
      "Precision: 0.07967984106951911\n",
      "Recall: 0.11190278471528473\n",
      "F1-Score: 0.08674677196087774\n",
      "Cohen Kappa Score: 0.07840432010606246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3641456582633053,\n",
       " 0.07967984106951911,\n",
       " 0.11190278471528473,\n",
       " 0.08674677196087774,\n",
       " 0.07840432010606246)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(y_test_set1, y_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
