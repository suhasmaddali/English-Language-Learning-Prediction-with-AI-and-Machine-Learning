{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "337f41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tensorflow.keras.layers import Input, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2535ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ASAP Dataset/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0911b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>word_len</th>\n",
       "      <th>chars_len</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>pos_ratios</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>sentiment_polariy</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>1875</td>\n",
       "      <td>3.984456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.031088082901554404, 'JJ': 0.05181347...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>2288</td>\n",
       "      <td>4.030172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.03879310344827586, ',': 0.0258620689...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.613167</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>1541</td>\n",
       "      <td>4.035144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.04153354632587859, ',': 0.0287539936...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340393</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>dear people use computer everyone agrees benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>611</td>\n",
       "      <td>3165</td>\n",
       "      <td>4.328969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.11620294599018004, ',': 0.0212765957...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266828</td>\n",
       "      <td>0.441795</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>517</td>\n",
       "      <td>2569</td>\n",
       "      <td>4.071567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.017408123791102514, ',': 0.025145067...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199684</td>\n",
       "      <td>0.485814</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  word_len  chars_len  \\\n",
       "0             NaN             NaN            NaN  ...       386       1875   \n",
       "1             NaN             NaN            NaN  ...       464       2288   \n",
       "2             NaN             NaN            NaN  ...       313       1541   \n",
       "3             NaN             NaN            NaN  ...       611       3165   \n",
       "4             NaN             NaN            NaN  ...       517       2569   \n",
       "\n",
       "   avg_word_length  avg_sentence_length  \\\n",
       "0         3.984456                  1.0   \n",
       "1         4.030172                  1.0   \n",
       "2         4.035144                  1.0   \n",
       "3         4.328969                  1.0   \n",
       "4         4.071567                  1.0   \n",
       "\n",
       "                                          pos_ratios  num_sentences  \\\n",
       "0  {'NNP': 0.031088082901554404, 'JJ': 0.05181347...             16   \n",
       "1  {'NNP': 0.03879310344827586, ',': 0.0258620689...             20   \n",
       "2  {'NNP': 0.04153354632587859, ',': 0.0287539936...             14   \n",
       "3  {'NNP': 0.11620294599018004, ',': 0.0212765957...             27   \n",
       "4  {'NNP': 0.017408123791102514, ',': 0.025145067...             30   \n",
       "\n",
       "   num_paragraphs  sentiment_polariy  sentiment_subjectivity  \\\n",
       "0               1           0.310471                0.385613   \n",
       "1               1           0.274000                0.613167   \n",
       "2               1           0.340393                0.498657   \n",
       "3               1           0.266828                0.441795   \n",
       "4               1           0.199684                0.485814   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  dear local newspaper think effect computer peo...  \n",
       "1  dear believe using computer benefit u many way...  \n",
       "2  dear people use computer everyone agrees benef...  \n",
       "3  dear local newspaper found many expert say com...  \n",
       "4  dear know computer positive effect people comp...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f279fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 1, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "295a9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['essay_id', 'pos_ratios', 'essay', 'rater1_domain1', 'rater2_domain1']\n",
    "df.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1f78d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, average='macro'):\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return recall\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average='macro'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    return f1\n",
    "\n",
    "def calculate_cohen_kappa_score(y_true, y_pred):\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "    return kappa_score\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    accuracy = calculate_accuracy(y_actual, y_predictions)\n",
    "    precision = calculate_precision(y_actual, y_predictions)\n",
    "    recall = calculate_recall(y_actual, y_predictions)\n",
    "    kappa_score = calculate_cohen_kappa_score(y_actual, y_predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "893a1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data, target = 'domain1_score'):\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89732d2",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "07588fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 1]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3d9ad311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (1426, 10)\n",
      "The shape of the input test data: (357, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (1426, 13)\n",
      "The shape of the output test data: (357, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1d372b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c08b213c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_26:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_26:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.9504 - accuracy: 0.3778WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_26:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "45/45 [==============================] - 2s 38ms/step - loss: 1.9530 - accuracy: 0.3759 - val_loss: 1.7729 - val_accuracy: 0.3641\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.6472 - accuracy: 0.4032 - val_loss: 1.7229 - val_accuracy: 0.3697\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.4578 - accuracy: 0.4691 - val_loss: 1.6887 - val_accuracy: 0.3922\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.1898 - accuracy: 0.5743 - val_loss: 1.6686 - val_accuracy: 0.3866\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9309 - accuracy: 0.6725 - val_loss: 1.6663 - val_accuracy: 0.3669\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.7672 - accuracy: 0.7363 - val_loss: 1.7484 - val_accuracy: 0.3754\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5784 - accuracy: 0.8079 - val_loss: 1.8298 - val_accuracy: 0.3725\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.5003 - accuracy: 0.8261 - val_loss: 1.9052 - val_accuracy: 0.3697\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4676 - accuracy: 0.8317 - val_loss: 2.1576 - val_accuracy: 0.3193\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4008 - accuracy: 0.8562 - val_loss: 2.1329 - val_accuracy: 0.3445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5bbdb4730>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "52a0c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_26:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.3445378151260504\n",
      "Precision: 0.1839159439447185\n",
      "Recall: 0.167596345187071\n",
      "F1-Score: 0.150305207126839\n",
      "Cohen Kappa Score: 0.34645857179608586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3445378151260504,\n",
       " 0.1839159439447185,\n",
       " 0.167596345187071,\n",
       " 0.150305207126839,\n",
       " 0.34645857179608586)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57760ec",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1a7944ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 2]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "86a0b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (1440, 10)\n",
      "The shape of the input test data: (360, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (1440, 7)\n",
      "The shape of the output test data: (360, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "44b89fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "81965d44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_27:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (32, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_27:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (32, 758).\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 1.3523 - accuracy: 0.4317WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_27:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 1.3368 - accuracy: 0.4333 - val_loss: 1.1666 - val_accuracy: 0.4639\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 1.0737 - accuracy: 0.5639 - val_loss: 1.1170 - val_accuracy: 0.5111\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.9078 - accuracy: 0.6715 - val_loss: 1.1259 - val_accuracy: 0.5028\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6972 - accuracy: 0.7500 - val_loss: 1.1253 - val_accuracy: 0.5472\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.5006 - accuracy: 0.8222 - val_loss: 1.3227 - val_accuracy: 0.5194\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4324 - accuracy: 0.8542 - val_loss: 1.2892 - val_accuracy: 0.5306\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3442 - accuracy: 0.8826 - val_loss: 1.3360 - val_accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2890 - accuracy: 0.8993 - val_loss: 1.4457 - val_accuracy: 0.5306\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2558 - accuracy: 0.9056 - val_loss: 1.5896 - val_accuracy: 0.5167\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2498 - accuracy: 0.9236 - val_loss: 1.4927 - val_accuracy: 0.5056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5a4ca8370>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5ccd5612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_27:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.5055555555555555\n",
      "Precision: 0.2729098488390213\n",
      "Recall: 0.2901935812531839\n",
      "F1-Score: 0.28066848634424596\n",
      "Cohen Kappa Score: 0.3961397058823529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5055555555555555,\n",
       " 0.2729098488390213,\n",
       " 0.2901935812531839,\n",
       " 0.28066848634424596,\n",
       " 0.3961397058823529)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36401577",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d1c80cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 4]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e87f8c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (1416, 10)\n",
      "The shape of the input test data: (354, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (1416, 4)\n",
      "The shape of the output test data: (354, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9ff91667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a1a28946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_35:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_35:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.2765 - accuracy: 0.4098WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_35:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "45/45 [==============================] - 1s 33ms/step - loss: 1.2754 - accuracy: 0.4110 - val_loss: 1.1037 - val_accuracy: 0.5169\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 1.0183 - accuracy: 0.5360 - val_loss: 0.9445 - val_accuracy: 0.5593\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.8771 - accuracy: 0.6243 - val_loss: 0.9334 - val_accuracy: 0.5537\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.7492 - accuracy: 0.6808 - val_loss: 0.9408 - val_accuracy: 0.5706\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.7033 - accuracy: 0.6935 - val_loss: 1.0079 - val_accuracy: 0.5678\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6367 - accuracy: 0.7288 - val_loss: 1.0080 - val_accuracy: 0.5678\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.5709 - accuracy: 0.7556 - val_loss: 1.1418 - val_accuracy: 0.5621\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.5478 - accuracy: 0.7797 - val_loss: 1.0898 - val_accuracy: 0.5847\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.8121 - val_loss: 1.1264 - val_accuracy: 0.5480\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.4241 - accuracy: 0.8326 - val_loss: 1.2188 - val_accuracy: 0.5932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5c2b79970>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=2, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "198407be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_35:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.5932203389830508\n",
      "Precision: 0.6125039361979661\n",
      "Recall: 0.533907416091646\n",
      "F1-Score: 0.548260722338866\n",
      "Cohen Kappa Score: 0.6454184111505644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5932203389830508,\n",
       " 0.6125039361979661,\n",
       " 0.533907416091646,\n",
       " 0.548260722338866,\n",
       " 0.6454184111505644)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf2832",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "84ddc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 5]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ac9edd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (1444, 10)\n",
      "The shape of the input test data: (361, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (1444, 5)\n",
      "The shape of the output test data: (361, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e1e8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5ca3d807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_36:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_36:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 1.3660 - accuracy: 0.3899WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_36:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.3673 - accuracy: 0.3906 - val_loss: 1.1768 - val_accuracy: 0.4681\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 1.1273 - accuracy: 0.4612 - val_loss: 1.0572 - val_accuracy: 0.5291\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.9394 - accuracy: 0.6046 - val_loss: 0.9982 - val_accuracy: 0.5429\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6773 - val_loss: 1.0462 - val_accuracy: 0.5679\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6440 - accuracy: 0.7292 - val_loss: 1.0593 - val_accuracy: 0.5457\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.5217 - accuracy: 0.7978 - val_loss: 1.1942 - val_accuracy: 0.5097\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4591 - accuracy: 0.8151 - val_loss: 1.2305 - val_accuracy: 0.5402\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4060 - accuracy: 0.8490 - val_loss: 1.3247 - val_accuracy: 0.5180\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3544 - accuracy: 0.8726 - val_loss: 1.4015 - val_accuracy: 0.5263\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3540 - accuracy: 0.8747 - val_loss: 1.4597 - val_accuracy: 0.4931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5bbe6e9d0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "71f9e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_36:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.4930747922437673\n",
      "Precision: 0.3903352650101876\n",
      "Recall: 0.3668858418891784\n",
      "F1-Score: 0.37316175994098716\n",
      "Cohen Kappa Score: 0.5901031608163583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4930747922437673,\n",
       " 0.3903352650101876,\n",
       " 0.3668858418891784,\n",
       " 0.37316175994098716,\n",
       " 0.5901031608163583)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a72089",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b264f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 6]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fe38ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (1440, 10)\n",
      "The shape of the input test data: (360, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (1440, 5)\n",
      "The shape of the output test data: (360, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d583482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "153c18cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_37:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (32, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_37:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (32, 758).\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.4180 - accuracy: 0.3839WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_37:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.4035 - accuracy: 0.3896 - val_loss: 1.1255 - val_accuracy: 0.4972\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 1.1798 - accuracy: 0.4750 - val_loss: 1.0659 - val_accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 1.0425 - accuracy: 0.5333 - val_loss: 0.9829 - val_accuracy: 0.5472\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.8662 - accuracy: 0.6354 - val_loss: 0.9794 - val_accuracy: 0.5361\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.7601 - accuracy: 0.6729 - val_loss: 0.9620 - val_accuracy: 0.5611\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6353 - accuracy: 0.7424 - val_loss: 1.0501 - val_accuracy: 0.5667\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.5144 - accuracy: 0.7889 - val_loss: 1.0203 - val_accuracy: 0.5556\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.4477 - accuracy: 0.8104 - val_loss: 1.1558 - val_accuracy: 0.5556\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.4185 - accuracy: 0.8333 - val_loss: 1.2288 - val_accuracy: 0.5472\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.3827 - accuracy: 0.8479 - val_loss: 1.1700 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5ae054430>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1f642ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_37:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.55\n",
      "Precision: 0.4080289876858707\n",
      "Recall: 0.39879325876435706\n",
      "F1-Score: 0.4019728936534427\n",
      "Cohen Kappa Score: 0.5869056897895557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.55,\n",
       " 0.4080289876858707,\n",
       " 0.39879325876435706,\n",
       " 0.4019728936534427,\n",
       " 0.5869056897895557)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c92b8",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "885e4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 8]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0150aa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input train data: (578, 10)\n",
      "The shape of the input test data: (145, 10)\n",
      "---------------------------------------------------\n",
      "The shape of the output train data: (578, 61)\n",
      "The shape of the output test data: (145, 61)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the input train data: {}\".format(X_train.shape))\n",
    "print(\"The shape of the input test data: {}\".format(X_test.shape))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"The shape of the output train data: {}\".format(y_train.shape))\n",
    "print(\"The shape of the output test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bdb49245",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "762a1b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_39:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_39:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 3.8860 - accuracy: 0.0625WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_39:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 3.8664 - accuracy: 0.0640 - val_loss: 3.4074 - val_accuracy: 0.0483\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 3.0212 - accuracy: 0.2145 - val_loss: 3.0246 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.7470 - accuracy: 0.2318 - val_loss: 3.0007 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.5699 - accuracy: 0.2612 - val_loss: 2.9928 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.3661 - accuracy: 0.3080 - val_loss: 3.0283 - val_accuracy: 0.1448\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.1821 - accuracy: 0.3668 - val_loss: 3.0697 - val_accuracy: 0.1103\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.9499 - accuracy: 0.4239 - val_loss: 3.1275 - val_accuracy: 0.1310\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 1.7689 - accuracy: 0.4896 - val_loss: 3.1206 - val_accuracy: 0.1586\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.5495 - accuracy: 0.5484 - val_loss: 3.2325 - val_accuracy: 0.1034\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 1.4948 - accuracy: 0.5623 - val_loss: 3.2475 - val_accuracy: 0.1448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5ad8c2910>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['preprocessed_text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train['preprocessed_text'])\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test['preprocessed_text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 750\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "X_train_additional_features = X_train[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "X_test_additional_features = X_test[['word_len', 'chars_len', 'avg_word_length', 'avg_sentence_length',\n",
    "       'num_sentences', 'num_paragraphs', 'sentiment_polariy',\n",
    "       'sentiment_subjectivity']].values.astype('int32')\n",
    "\n",
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(text_input)\n",
    "conv_layer = Conv1D(filters=10, kernel_size=5, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "dropout_layer = Dropout(0.2)(pooling_layer)\n",
    "dense_layer1 = Dense(units=16, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(units=y_train.shape[1], activation='softmax')(dense_layer1)\n",
    "model = Model(inputs = text_input, outputs = output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "padded_sequences_train_concat = concatenate([padded_sequences_train, X_train_additional_features])\n",
    "padded_sequences_test_concat = concatenate([padded_sequences_test, X_test_additional_features])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train_concat, y_train, epochs=10, batch_size=32, validation_data=(padded_sequences_test_concat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a223615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 750) for input Tensor(\"input_39:0\", shape=(None, 750), dtype=float32), but it was called on an input with incompatible shape (None, 758).\n",
      "Accuracy: 0.14482758620689656\n",
      "Precision: 0.019693877551020405\n",
      "Recall: 0.04356921813818366\n",
      "F1-Score: 0.025971682336431417\n",
      "Cohen Kappa Score: -0.09739861043787368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14482758620689656,\n",
       " 0.019693877551020405,\n",
       " 0.04356921813818366,\n",
       " 0.025971682336431417,\n",
       " -0.09739861043787368)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = model.predict(padded_sequences_test_concat)\n",
    "y_predictions = np.argmax(y_predictions, axis = 1)\n",
    "print_metrics_function(np.argmax(y_test, axis = 1), y_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
