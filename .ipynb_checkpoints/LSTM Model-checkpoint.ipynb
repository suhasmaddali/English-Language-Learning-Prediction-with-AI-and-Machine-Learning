{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33464672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dd3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108f8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['full_text', 'text_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164ff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute error (MAE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mae\n",
    "\n",
    "def calc_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the root mean squared error (RMSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calc_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute percentage error (MAPE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mape\n",
    "\n",
    "def calc_r2_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the R2 score between the true and predicted values\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6acf621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print MSE\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    # Calculate and print MSE\n",
    "    mse = calc_mse(y_actual, y_predictions)\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    rmse = calc_rmse(y_actual, y_predictions)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    \n",
    "    # Calculate and print MAE\n",
    "    mae = calc_mae(y_actual, y_predictions)\n",
    "    print(\"MAE:\", mae)\n",
    "\n",
    "    # Calculate and print MAPE\n",
    "    mape = calc_mape(y_actual, y_predictions)\n",
    "    print(\"MAPE:\", mape)\n",
    "\n",
    "    # Calculate and print R2 score\n",
    "    r2 = calc_r2_score(y_actual, y_predictions)\n",
    "    print(\"R2 Score:\", r2)\n",
    "    \n",
    "    return mse, rmse, mae, mape, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a6768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohesion = df['cohesion']\n",
    "syntax = df['syntax']\n",
    "vocabulary = df['vocabulary']\n",
    "phraseology = df['phraseology']\n",
    "grammar = df['grammar']\n",
    "conventions = df['conventions']\n",
    "\n",
    "preprocessed_text = df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541d53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_text\n",
    "y_cohesion = cohesion\n",
    "y_syntax = syntax\n",
    "y_vocabulary = vocabulary\n",
    "y_phraseology = phraseology\n",
    "y_grammar = grammar\n",
    "y_conventions = conventions\n",
    "\n",
    "X_train, X_test, y_train_cohesion, y_test_cohesion = train_test_split(X, y_cohesion, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_syntax, y_test_syntax = train_test_split(X, y_syntax, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_vocabulary, y_test_vocabulary = train_test_split(X, y_vocabulary, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_phraseology, y_test_phraseology = train_test_split(X, y_phraseology, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_grammar, y_test_grammar = train_test_split(X, y_grammar, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_conventions, y_test_conventions = train_test_split(X, y_conventions, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f357db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfdbd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e010b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
