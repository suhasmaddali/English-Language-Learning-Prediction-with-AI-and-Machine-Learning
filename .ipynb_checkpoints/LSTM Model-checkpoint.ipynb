{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5815cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2816c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f662f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95780a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['full_text', 'text_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e72f40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calc_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute error (MAE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mae\n",
    "\n",
    "def calc_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the root mean squared error (RMSE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calc_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute percentage error (MAPE) between the true and predicted values\n",
    "    \"\"\"\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mape\n",
    "\n",
    "def calc_r2_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the R2 score between the true and predicted values\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57dc354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print MSE\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    # Calculate and print MSE\n",
    "    mse = calc_mse(y_actual, y_predictions)\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    rmse = calc_rmse(y_actual, y_predictions)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    \n",
    "    # Calculate and print MAE\n",
    "    mae = calc_mae(y_actual, y_predictions)\n",
    "    print(\"MAE:\", mae)\n",
    "\n",
    "    # Calculate and print MAPE\n",
    "    mape = calc_mape(y_actual, y_predictions)\n",
    "    print(\"MAPE:\", mape)\n",
    "\n",
    "    # Calculate and print R2 score\n",
    "    r2 = calc_r2_score(y_actual, y_predictions)\n",
    "    print(\"R2 Score:\", r2)\n",
    "    \n",
    "    return mse, rmse, mae, mape, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a763325",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohesion = df['cohesion']\n",
    "syntax = df['syntax']\n",
    "vocabulary = df['vocabulary']\n",
    "phraseology = df['phraseology']\n",
    "grammar = df['grammar']\n",
    "conventions = df['conventions']\n",
    "\n",
    "preprocessed_text = df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_text\n",
    "y_cohesion = cohesion\n",
    "y_syntax = syntax\n",
    "y_vocabulary = vocabulary\n",
    "y_phraseology = phraseology\n",
    "y_grammar = grammar\n",
    "y_conventions = conventions\n",
    "\n",
    "X_train, X_test, y_train_cohesion, y_test_cohesion = train_test_split(X, y_cohesion, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_syntax, y_test_syntax = train_test_split(X, y_syntax, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_vocabulary, y_test_vocabulary = train_test_split(X, y_vocabulary, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_phraseology, y_test_phraseology = train_test_split(X, y_phraseology, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_grammar, y_test_grammar = train_test_split(X, y_grammar, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train_conventions, y_test_conventions = train_test_split(X, y_conventions, \n",
    "                                                                     shuffle = True, \n",
    "                                                                     random_state = 101, \n",
    "                                                                     test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cec1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b54299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64a8c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = 1000\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen = max_sequence_len,\n",
    "                                      padding = 'post',\n",
    "                                      truncating = 'post')\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen = max_sequence_len,\n",
    "                                     padding = 'post', \n",
    "                                     truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "765ace24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e83186",
   "metadata": {},
   "source": [
    "### Cohesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9f95d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 49s 924ms/step - loss: 1.0905 - mean_absolute_error: 1.0905 - val_loss: 0.5419 - val_mean_absolute_error: 0.5419\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 45s 911ms/step - loss: 0.5380 - mean_absolute_error: 0.5380 - val_loss: 0.5303 - val_mean_absolute_error: 0.5303\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 47s 959ms/step - loss: 0.5312 - mean_absolute_error: 0.5312 - val_loss: 0.5307 - val_mean_absolute_error: 0.5307\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 49s 1s/step - loss: 0.5263 - mean_absolute_error: 0.5263 - val_loss: 0.5326 - val_mean_absolute_error: 0.5326\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 50s 1s/step - loss: 0.5252 - mean_absolute_error: 0.5252 - val_loss: 0.5305 - val_mean_absolute_error: 0.5305\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.5227 - mean_absolute_error: 0.5227 - val_loss: 0.5309 - val_mean_absolute_error: 0.5309\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.5221 - mean_absolute_error: 0.5221 - val_loss: 0.5298 - val_mean_absolute_error: 0.5298\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.5226 - mean_absolute_error: 0.5226 - val_loss: 0.5292 - val_mean_absolute_error: 0.5292\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 55s 1s/step - loss: 0.5235 - mean_absolute_error: 0.5235 - val_loss: 0.5265 - val_mean_absolute_error: 0.5265\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 56s 1s/step - loss: 0.5242 - mean_absolute_error: 0.5242 - val_loss: 0.5274 - val_mean_absolute_error: 0.5274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19929c1b0a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "lstm_units = 32\n",
    "\n",
    "model = Sequential([Embedding(vocab_size, embedding_dim, input_length = max_sequence_len),\n",
    "                   LSTM(lstm_units, return_sequences = True),\n",
    "                   Dropout(0.5),\n",
    "                   LSTM(lstm_units),\n",
    "                   Dense(1)])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "model.fit(padded_sequences_train, y_train_cohesion, batch_size = batch_size, validation_data = (padded_sequences_test, y_test_cohesion),\n",
    "         epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b27f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "lstm_units = 32\n",
    "\n",
    "model = Sequential([Embedding(vocab_size, embedding_dim, input_length=max_sequence_len),\n",
    "                    LSTM(lstm_units, return_sequences=True),\n",
    "                    Dropout(0.5),\n",
    "                    LSTM(lstm_units),\n",
    "                    Dense(1)])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "model.fit(padded_sequences_train, y_train_syntax, batch_size=batch_size, validation_data=(padded_sequences_test, y_test_syntax),\n",
    "          epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
