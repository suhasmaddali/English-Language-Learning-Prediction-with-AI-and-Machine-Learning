{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f19d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from transformers import TFGPT2Model, GPT2Tokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d8f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ASAP Dataset/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa2f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any missing values from the data\n",
    "df = df.dropna(axis = 1, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4e8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['essay_id', 'pos_ratios', 'essay', 'rater1_domain1', 'rater2_domain1']\n",
    "df.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d62ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the precision score between the true and predicted values\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    return precision\n",
    "\n",
    "def calc_recall(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the recall score between the true and predicted values\n",
    "    \"\"\"\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return recall\n",
    "\n",
    "def calc_f1_score(y_true, y_pred, average='macro'):\n",
    "    \"\"\"\n",
    "    Calculates the f1-score between the true and predicted values\n",
    "    \"\"\"\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    return f1\n",
    "\n",
    "def calc_cohen_kappa_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the cohen kappa score between the true and predicted values\n",
    "    \"\"\"\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "    return kappa_score\n",
    "\n",
    "def calc_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy score between the true and predicted values\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dccb2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    # Calculate and print accuracy\n",
    "    accuracy = calc_accuracy(y_actual, y_predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Calculate and print precision\n",
    "    precision = calc_precision(y_actual, y_predictions)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculate and print recall\n",
    "    recall = calc_recall(y_actual, y_predictions)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Calculate and print f1-score\n",
    "    f1 = calc_f1_score(y_actual, y_predictions)\n",
    "    print(\"F1-Score:\", f1)\n",
    "\n",
    "    # Calculate and print Cohen Kappa Score\n",
    "    kappa_score = calc_cohen_kappa_score(y_actual, y_predictions)\n",
    "    print(\"Cohen Kappa Score:\", kappa_score)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc48d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data, target = 'domain1_score'):\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa2fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_classifiers(classifier_name = \"logistic_regression\"):\n",
    "    \"\"\"\n",
    "    Takes a regressor as input and returns a corresponding classifier object\n",
    "    \"\"\"\n",
    "    \n",
    "    if classifier_name == 'logistic_regression':\n",
    "        return LogisticRegression()\n",
    "    elif classifier_name == 'decision_tree_classifier':\n",
    "        return DecisionTreeClassifier()\n",
    "    elif classifier_name == 'random_forest_classifier':\n",
    "        return RandomForestClassifier()\n",
    "    elif classifier_name == 'gradient_boosting_classifier':\n",
    "        return GradientBoostingClassifier()\n",
    "    elif classifier_name == 'adaboost_classifier':\n",
    "        return AdaBoostClassifier()\n",
    "    elif classifier_name == 'k_neighbors_classifier':\n",
    "        return KNeighborsClassifier()\n",
    "    elif classifier_name == 'support_vector_classifier':\n",
    "        return SVC()\n",
    "    elif classifier_name == 'xgboost_classifier':\n",
    "        return XGBClassifier()\n",
    "    elif classifier_name == 'gaussian_naive_bayes_classifier':\n",
    "        return GaussianNB()\n",
    "    else:\n",
    "        raise ValueError(f\"Classifier {classifier_name} not supported for this problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c66657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_corrector(text):\n",
    "    spell_checker = SpellChecker()\n",
    "    correct_tokens = []\n",
    "    for token in tqdm(text.split()):\n",
    "        if spell_checker.correction(token.lower()):\n",
    "            correct_tokens.append(spell_checker.correction(token.lower()))\n",
    "        else:\n",
    "            correct_tokens.append(token.lower())\n",
    "    \n",
    "    return ' '.join(correct_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bc841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 1]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6eb5038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953d1a9281a640ff9ee2bc10d946d687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0007b0d8ff40ffbc6d7448615c8393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c8bb8231a048bf822564809da5da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bbfea62031445fa619399fca7baeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38df42f96fa4ac9adc21a4bca688298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/475M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 124439808\n"
     ]
    }
   ],
   "source": [
    "# This downloads the pre-trained weights from the huggingface website \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "gpt_model = TFGPT2Model.from_pretrained('gpt2')\n",
    "print(f\"Total number of parameters: {gpt_model.count_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b1f50",
   "metadata": {},
   "source": [
    "### GPT-2 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bbd3d",
   "metadata": {},
   "source": [
    "#### Extracting GPT - 2 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6810143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:32<00:00,  2.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ca145b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6721a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.5014005602240896\n",
      "Precision: 0.2227152479611077\n",
      "Recall: 0.21855667517965904\n",
      "F1-Score: 0.21256798059618895\n",
      "Cohen Kappa Score: 0.7042866017809071\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5266106442577031\n",
      "Precision: 0.49137386476945044\n",
      "Recall: 0.4176711292739518\n",
      "F1-Score: 0.4336629093855165\n",
      "Cohen Kappa Score: 0.7908329120069797\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.46218487394957986\n",
      "Precision: 0.18874293785310733\n",
      "Recall: 0.2134375\n",
      "F1-Score: 0.18168804941791397\n",
      "Cohen Kappa Score: 0.5567525128495394\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.453781512605042\n",
      "Precision: 0.27413076560744953\n",
      "Recall: 0.25999773412071797\n",
      "F1-Score: 0.261224280112592\n",
      "Cohen Kappa Score: 0.6812457156682215\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.3641456582633053\n",
      "Precision: 0.03641456582633053\n",
      "Recall: 0.1\n",
      "F1-Score: 0.05338809034907597\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb9b4f",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00fd2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 2]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfeccfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [01:00<00:00,  1.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:47<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "849f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc610a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.6555555555555556\n",
      "Precision: 0.4364506172839506\n",
      "Recall: 0.34369006443771166\n",
      "F1-Score: 0.36128145108871235\n",
      "Cohen Kappa Score: 0.5928899082568808\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.6388888888888888\n",
      "Precision: 0.626152957243408\n",
      "Recall: 0.47007123003637463\n",
      "F1-Score: 0.4890214890381218\n",
      "Cohen Kappa Score: 0.6206836414370422\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.6\n",
      "Precision: 0.41165107971860415\n",
      "Recall: 0.3218745028643948\n",
      "F1-Score: 0.32709890668700736\n",
      "Cohen Kappa Score: 0.37589285714285714\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.6194444444444445\n",
      "Precision: 0.5651763539765404\n",
      "Recall: 0.3979640006792325\n",
      "F1-Score: 0.4310766116750022\n",
      "Cohen Kappa Score: 0.5799769850402763\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.43333333333333335\n",
      "Precision: 0.08666666666666667\n",
      "Recall: 0.2\n",
      "F1-Score: 0.12093023255813953\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0111f",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3ecd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 3]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0381ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:52<00:00,  1.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:15<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4553c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2246b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.6127167630057804\n",
      "Precision: 0.4550178294618904\n",
      "Recall: 0.4924148103281962\n",
      "F1-Score: 0.45755161206285255\n",
      "Cohen Kappa Score: 0.6599764145489861\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.37283236994219654\n",
      "Precision: 0.32003496503496504\n",
      "Recall: 0.2727342575767773\n",
      "F1-Score: 0.22219892386128387\n",
      "Cohen Kappa Score: 0.16649503493931594\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.3901734104046243\n",
      "Precision: 0.32205524399912766\n",
      "Recall: 0.32918367842908525\n",
      "F1-Score: 0.2955242794003201\n",
      "Cohen Kappa Score: 0.22189448140245183\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.569364161849711\n",
      "Precision: 0.43162078007210747\n",
      "Recall: 0.4534442275912092\n",
      "F1-Score: 0.43456003090891526\n",
      "Cohen Kappa Score: 0.6086668166798916\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.37572254335260113\n",
      "Precision: 0.09393063583815028\n",
      "Recall: 0.25\n",
      "F1-Score: 0.13655462184873948\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71087c46",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dfbd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 4]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8ddf703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:58<00:00,  1.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac12215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35bdbcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.6016949152542372\n",
      "Precision: 0.6019688644688646\n",
      "Recall: 0.5596967910497755\n",
      "F1-Score: 0.5635968359161194\n",
      "Cohen Kappa Score: 0.6996803851162057\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.576271186440678\n",
      "Precision: 0.559556229899367\n",
      "Recall: 0.5887492463321498\n",
      "F1-Score: 0.5678512272251756\n",
      "Cohen Kappa Score: 0.7127724637326613\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.423728813559322\n",
      "Precision: 0.4123209018120523\n",
      "Recall: 0.41730635760702084\n",
      "F1-Score: 0.36096740486061957\n",
      "Cohen Kappa Score: 0.45484058936152505\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.536723163841808\n",
      "Precision: 0.5219082598731972\n",
      "Recall: 0.5099888792121658\n",
      "F1-Score: 0.5130650202788021\n",
      "Cohen Kappa Score: 0.6871262552183234\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.3531073446327684\n",
      "Precision: 0.0882768361581921\n",
      "Recall: 0.25\n",
      "F1-Score: 0.1304801670146138\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4e70e",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bae6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 5]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1b79613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [01:02<00:00,  1.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2db5651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acf27c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.5152354570637119\n",
      "Precision: 0.39821699134199134\n",
      "Recall: 0.43371538303474777\n",
      "F1-Score: 0.3948481439820023\n",
      "Cohen Kappa Score: 0.630763714593044\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.47645429362880887\n",
      "Precision: 0.43426953362965637\n",
      "Recall: 0.4140006670968902\n",
      "F1-Score: 0.3808317906759421\n",
      "Cohen Kappa Score: 0.5978692410956556\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.5512465373961218\n",
      "Precision: 0.4206883732457635\n",
      "Recall: 0.31760632193703053\n",
      "F1-Score: 0.2675042866210059\n",
      "Cohen Kappa Score: 0.5608184918529746\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5789473684210527\n",
      "Precision: 0.4549963029797657\n",
      "Recall: 0.4759278549349283\n",
      "F1-Score: 0.4573422371852284\n",
      "Cohen Kappa Score: 0.7108790909281506\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.37950138504155123\n",
      "Precision: 0.1664441147378833\n",
      "Recall: 0.21732283464566932\n",
      "F1-Score: 0.13799436442435598\n",
      "Cohen Kappa Score: 0.1412029407128219\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce85418",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3267402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 6]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da3cc5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:38<00:00,  2.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:16<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d501fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fcdf740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.4361111111111111\n",
      "Precision: 0.3455551257253385\n",
      "Recall: 0.4158831919525561\n",
      "F1-Score: 0.3339150739401052\n",
      "Cohen Kappa Score: 0.6247270742358078\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5333333333333333\n",
      "Precision: 0.48719435620118795\n",
      "Recall: 0.4369306608612967\n",
      "F1-Score: 0.45178402681176005\n",
      "Cohen Kappa Score: 0.6368383574649894\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.46944444444444444\n",
      "Precision: 0.35729850727162493\n",
      "Recall: 0.3583254510422141\n",
      "F1-Score: 0.29201296800455134\n",
      "Cohen Kappa Score: 0.5024104683195592\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.46111111111111114\n",
      "Precision: 0.4513650793650793\n",
      "Recall: 0.38669306608612974\n",
      "F1-Score: 0.38514875540066995\n",
      "Cohen Kappa Score: 0.5807978363759296\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.48055555555555557\n",
      "Precision: 0.09611111111111112\n",
      "Recall: 0.2\n",
      "F1-Score: 0.12983114446529082\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf78695",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4277b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 7]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64d55069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:30<00:00,  2.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:08<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3cb2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc39b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.06687898089171974\n",
      "Precision: 0.03162646177352059\n",
      "Recall: 0.07357444598823909\n",
      "F1-Score: 0.04012977472003719\n",
      "Cohen Kappa Score: 0.2772760195289655\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.1337579617834395\n",
      "Precision: 0.09476721874868912\n",
      "Recall: 0.0933560349683897\n",
      "F1-Score: 0.05422766137625575\n",
      "Cohen Kappa Score: 0.5457254745261748\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.08917197452229299\n",
      "Precision: 0.026130129471143296\n",
      "Recall: 0.09947089947089947\n",
      "F1-Score: 0.035690645052347175\n",
      "Cohen Kappa Score: 0.5523339479130822\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.09872611464968153\n",
      "Precision: 0.03708636307375803\n",
      "Recall: 0.09200163447430058\n",
      "F1-Score: 0.04340937144275889\n",
      "Cohen Kappa Score: 0.45644499435968633\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.09235668789808917\n",
      "Precision: 0.004397937518956627\n",
      "Recall: 0.047619047619047616\n",
      "F1-Score: 0.008052200472025543\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff6893",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27d74039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 8]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe490151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:33<00:00,  1.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55350366",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['preprocessed_text'], axis = 1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['preprocessed_text'], axis = 1))\n",
    "X_train_features = tf.constant(X_train_scaled.astype('float32'))\n",
    "X_test_features = tf.constant(X_test_scaled.astype('float32'))\n",
    "\n",
    "embeddings_train = tf.concat([embeddings_train, X_train_features], axis = 1)\n",
    "embeddings_test = tf.concat([embeddings_test, X_test_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22986baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.20689655172413793\n",
      "Precision: 0.01488095238095238\n",
      "Recall: 0.04566912972085386\n",
      "F1-Score: 0.022254797441364604\n",
      "Cohen Kappa Score: 0.4812920592193809\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.20689655172413793\n",
      "Precision: 0.036631054131054136\n",
      "Recall: 0.04844532861774241\n",
      "F1-Score: 0.03554677940642852\n",
      "Cohen Kappa Score: 0.42210084398544057\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.21379310344827587\n",
      "Precision: 0.013543599257884972\n",
      "Recall: 0.04690065681444992\n",
      "F1-Score: 0.02095952417397389\n",
      "Cohen Kappa Score: 0.5182635829662261\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.1310344827586207\n",
      "Precision: 0.059889974798696906\n",
      "Recall: 0.052569946238198315\n",
      "F1-Score: 0.052500188936505494\n",
      "Cohen Kappa Score: 0.33855411176924355\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.2\n",
      "Precision: 0.0071428571428571435\n",
      "Recall: 0.03571428571428571\n",
      "F1-Score: 0.011904761904761906\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
