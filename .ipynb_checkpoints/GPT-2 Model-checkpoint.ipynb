{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f19d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from transformers import TFGPT2Model, GPT2Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d8f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ASAP Dataset/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa2f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 1, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4e8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['essay_id', 'pos_ratios', 'essay', 'rater1_domain1', 'rater2_domain1']\n",
    "df.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d62ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, average='macro'):\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return recall\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average='macro'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    return f1\n",
    "\n",
    "def calculate_cohen_kappa_score(y_true, y_pred):\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "    return kappa_score\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    accuracy = calculate_accuracy(y_actual, y_predictions)\n",
    "    precision = calculate_precision(y_actual, y_predictions)\n",
    "    recall = calculate_recall(y_actual, y_predictions)\n",
    "    f1 = calculate_f1_score(y_actual, y_predictions)\n",
    "    kappa_score = calculate_cohen_kappa_score(y_actual, y_predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc48d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data, target = 'domain1_score'):\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa2fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_classifiers(classifier_name = \"logistic_regression\"):\n",
    "    \n",
    "    if classifier_name == 'logistic_regression':\n",
    "        return LogisticRegression()\n",
    "    elif classifier_name == 'random_forest_classifier':\n",
    "        return RandomForestClassifier()\n",
    "    elif classifier_name == 'adaboost_classifier':\n",
    "        return AdaBoostClassifier()\n",
    "    elif classifier_name == 'k_neighbors_classifier':\n",
    "        return KNeighborsClassifier()\n",
    "    elif classifier_name == 'support_vector_classifier':\n",
    "        return SVC()\n",
    "    else:\n",
    "        raise ValueError(f\"Classifier {classifier_name} not supported for this problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bc841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 1]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6eb5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 124439808\n"
     ]
    }
   ],
   "source": [
    "# This downloads the pre-trained weights from the huggingface website \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "gpt_model = TFGPT2Model.from_pretrained('gpt2')\n",
    "print(f\"Total number of parameters: {gpt_model.count_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b1f50",
   "metadata": {},
   "source": [
    "### GPT-2 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bbd3d",
   "metadata": {},
   "source": [
    "#### Extracting GPT - 2 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6810143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:31<00:00,  2.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:08<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6721a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.49299719887955185\n",
      "Precision: 0.23054102996944667\n",
      "Recall: 0.2082108315072025\n",
      "F1-Score: 0.20492996525170745\n",
      "Cohen Kappa Score: 0.6590213968822238\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5126050420168067\n",
      "Precision: 0.4506009842682005\n",
      "Recall: 0.3833604701749863\n",
      "F1-Score: 0.3921587458782141\n",
      "Cohen Kappa Score: 0.7765472144800646\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.45938375350140054\n",
      "Precision: 0.2185760539183296\n",
      "Recall: 0.3278125\n",
      "F1-Score: 0.25365074963488804\n",
      "Cohen Kappa Score: 0.6326407276805726\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.47619047619047616\n",
      "Precision: 0.26849220112242855\n",
      "Recall: 0.26487336252457216\n",
      "F1-Score: 0.2603777231685342\n",
      "Cohen Kappa Score: 0.7124564050804945\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.3641456582633053\n",
      "Precision: 0.03641456582633053\n",
      "Recall: 0.1\n",
      "F1-Score: 0.05338809034907597\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb9b4f",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00fd2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 2]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfeccfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:40<00:00,  2.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc610a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.6194444444444445\n",
      "Precision: 0.41094814241486066\n",
      "Recall: 0.36667658703559713\n",
      "F1-Score: 0.37984665961887876\n",
      "Cohen Kappa Score: 0.5450316337923334\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.6694444444444444\n",
      "Precision: 0.5061645779563455\n",
      "Recall: 0.4837492738468689\n",
      "F1-Score: 0.4685032399312341\n",
      "Cohen Kappa Score: 0.6926229508196722\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.6\n",
      "Precision: 0.41165107971860415\n",
      "Recall: 0.3218745028643948\n",
      "F1-Score: 0.32709890668700736\n",
      "Cohen Kappa Score: 0.37589285714285714\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5777777777777777\n",
      "Precision: 0.34395278167367926\n",
      "Recall: 0.36121922227882497\n",
      "F1-Score: 0.34850386276522294\n",
      "Cohen Kappa Score: 0.5543478260869565\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.43333333333333335\n",
      "Precision: 0.08666666666666667\n",
      "Recall: 0.2\n",
      "F1-Score: 0.12093023255813953\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0111f",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ecd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 3]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0381ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:16<00:00,  5.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:03<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2246b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.43641618497109824\n",
      "Precision: 0.37673337438423643\n",
      "Recall: 0.37037280062214445\n",
      "F1-Score: 0.3330595090183158\n",
      "Cohen Kappa Score: 0.4345963792930363\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.3872832369942196\n",
      "Precision: 0.3157647871634095\n",
      "Recall: 0.27538734474430016\n",
      "F1-Score: 0.2596099368499933\n",
      "Cohen Kappa Score: 0.23280317428561903\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.407514450867052\n",
      "Precision: 0.33401437853128707\n",
      "Recall: 0.3434983287345492\n",
      "F1-Score: 0.30227710337222224\n",
      "Cohen Kappa Score: 0.2941236775198883\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5086705202312138\n",
      "Precision: 0.4049070847851336\n",
      "Recall: 0.4052164419618488\n",
      "F1-Score: 0.3918480470338056\n",
      "Cohen Kappa Score: 0.5226543479617953\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.37572254335260113\n",
      "Precision: 0.09393063583815028\n",
      "Recall: 0.25\n",
      "F1-Score: 0.13655462184873948\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71087c46",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfbd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 4]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8ddf703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:16<00:00,  5.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35bdbcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.556497175141243\n",
      "Precision: 0.5724331759425006\n",
      "Recall: 0.5359502914182354\n",
      "F1-Score: 0.5263625256090638\n",
      "Cohen Kappa Score: 0.6405354947406767\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5254237288135594\n",
      "Precision: 0.4816507465963987\n",
      "Recall: 0.5017769143163395\n",
      "F1-Score: 0.46883739608454017\n",
      "Cohen Kappa Score: 0.6446624411540384\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.3785310734463277\n",
      "Precision: 0.41673526917128173\n",
      "Recall: 0.39499778924097273\n",
      "F1-Score: 0.3289425000781391\n",
      "Cohen Kappa Score: 0.33141457055576073\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.519774011299435\n",
      "Precision: 0.5154162439981065\n",
      "Recall: 0.49972800964694847\n",
      "F1-Score: 0.5001461660123753\n",
      "Cohen Kappa Score: 0.623744309417209\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.3531073446327684\n",
      "Precision: 0.0882768361581921\n",
      "Recall: 0.25\n",
      "F1-Score: 0.1304801670146138\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4e70e",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bae6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 5]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b79613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:20<00:00,  4.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:04<00:00,  5.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acf27c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.4404432132963989\n",
      "Precision: 0.4194384832593788\n",
      "Recall: 0.38678125557879994\n",
      "F1-Score: 0.3484857873247363\n",
      "Cohen Kappa Score: 0.5515029948847507\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5373961218836565\n",
      "Precision: 0.4398766930743675\n",
      "Recall: 0.44080553104975906\n",
      "F1-Score: 0.4043604655992235\n",
      "Cohen Kappa Score: 0.6872329329430369\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.3961218836565097\n",
      "Precision: 0.2828282828282828\n",
      "Recall: 0.2431957368965243\n",
      "F1-Score: 0.19296081277213353\n",
      "Cohen Kappa Score: 0.259543185599758\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.49584487534626037\n",
      "Precision: 0.6141106389161309\n",
      "Recall: 0.44044296273443473\n",
      "F1-Score: 0.4437849682170759\n",
      "Cohen Kappa Score: 0.6353022034894793\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.3656509695290859\n",
      "Precision: 0.15283236994219654\n",
      "Recall: 0.20944881889763778\n",
      "F1-Score: 0.12368106946765338\n",
      "Cohen Kappa Score: 0.09319331783470197\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce85418",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3267402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 6]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da3cc5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:23<00:00,  3.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fcdf740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.325\n",
      "Precision: 0.31789825840246005\n",
      "Recall: 0.34965930986162197\n",
      "F1-Score: 0.2508616525070798\n",
      "Cohen Kappa Score: 0.4982526210683974\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.5277777777777778\n",
      "Precision: 0.3860048093838232\n",
      "Recall: 0.41225746315341694\n",
      "F1-Score: 0.3937333161177591\n",
      "Cohen Kappa Score: 0.6431919381298337\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.3\n",
      "Precision: 0.21571137508168992\n",
      "Recall: 0.277430373095113\n",
      "F1-Score: 0.17919703832329753\n",
      "Cohen Kappa Score: 0.38911613017961943\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.39166666666666666\n",
      "Precision: 0.3215442880097593\n",
      "Recall: 0.33740172159247306\n",
      "F1-Score: 0.3048868533924695\n",
      "Cohen Kappa Score: 0.5017269402681837\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.48055555555555557\n",
      "Precision: 0.09611111111111112\n",
      "Recall: 0.2\n",
      "F1-Score: 0.12983114446529082\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf78695",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4277b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 7]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64d55069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:27<00:00,  2.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc39b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.054140127388535034\n",
      "Precision: 0.016046205227196127\n",
      "Recall: 0.07114367114367115\n",
      "F1-Score: 0.022080132946922564\n",
      "Cohen Kappa Score: 0.14571914799797436\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.14012738853503184\n",
      "Precision: 0.06272694039694061\n",
      "Recall: 0.10255954332043979\n",
      "F1-Score: 0.06288810719561673\n",
      "Cohen Kappa Score: 0.5675649674665229\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.14331210191082802\n",
      "Precision: 0.028508753963247285\n",
      "Recall: 0.13197492163009403\n",
      "F1-Score: 0.04677015286315846\n",
      "Cohen Kappa Score: 0.6142216068810089\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.08280254777070063\n",
      "Precision: 0.017302274445131587\n",
      "Recall: 0.07261997261997262\n",
      "F1-Score: 0.02749636476192022\n",
      "Cohen Kappa Score: 0.36737588539623656\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.09235668789808917\n",
      "Precision: 0.004397937518956627\n",
      "Recall: 0.047619047619047616\n",
      "F1-Score: 0.008052200472025543\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff6893",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27d74039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 8]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe490151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:25<00:00,  1.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(gpt_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22986baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.18620689655172415\n",
      "Precision: 0.011843270365997638\n",
      "Recall: 0.036740558292282434\n",
      "F1-Score: 0.017006802721088437\n",
      "Cohen Kappa Score: 0.26708986312239635\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.18620689655172415\n",
      "Precision: 0.02910135841170324\n",
      "Recall: 0.0432063477545047\n",
      "F1-Score: 0.030471743295019157\n",
      "Cohen Kappa Score: 0.4567809978816424\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.19310344827586207\n",
      "Precision: 0.0097985347985348\n",
      "Recall: 0.03622742200328407\n",
      "F1-Score: 0.014774882699411001\n",
      "Cohen Kappa Score: 0.3125753314584171\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.11724137931034483\n",
      "Precision: 0.04152399324813118\n",
      "Recall: 0.04279983129566959\n",
      "F1-Score: 0.04066094510119073\n",
      "Cohen Kappa Score: 0.3170703293097833\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.2\n",
      "Precision: 0.0071428571428571435\n",
      "Recall: 0.03571428571428571\n",
      "F1-Score: 0.011904761904761906\n",
      "Cohen Kappa Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
