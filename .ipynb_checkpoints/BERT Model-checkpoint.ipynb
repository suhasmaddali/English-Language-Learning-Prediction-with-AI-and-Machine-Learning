{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "40756fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1471d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ASAP Dataset/Preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67ad8f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>word_len</th>\n",
       "      <th>chars_len</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>pos_ratios</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>sentiment_polariy</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>1875</td>\n",
       "      <td>3.984456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.031088082901554404, 'JJ': 0.05181347...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>2288</td>\n",
       "      <td>4.030172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.03879310344827586, ',': 0.0258620689...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.613167</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>1541</td>\n",
       "      <td>4.035144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.04153354632587859, ',': 0.0287539936...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340393</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>dear people use computer everyone agrees benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>611</td>\n",
       "      <td>3165</td>\n",
       "      <td>4.328969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.11620294599018004, ',': 0.0212765957...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266828</td>\n",
       "      <td>0.441795</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>517</td>\n",
       "      <td>2569</td>\n",
       "      <td>4.071567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'NNP': 0.017408123791102514, ',': 0.025145067...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199684</td>\n",
       "      <td>0.485814</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  word_len  chars_len  \\\n",
       "0             NaN             NaN            NaN  ...       386       1875   \n",
       "1             NaN             NaN            NaN  ...       464       2288   \n",
       "2             NaN             NaN            NaN  ...       313       1541   \n",
       "3             NaN             NaN            NaN  ...       611       3165   \n",
       "4             NaN             NaN            NaN  ...       517       2569   \n",
       "\n",
       "   avg_word_length  avg_sentence_length  \\\n",
       "0         3.984456                  1.0   \n",
       "1         4.030172                  1.0   \n",
       "2         4.035144                  1.0   \n",
       "3         4.328969                  1.0   \n",
       "4         4.071567                  1.0   \n",
       "\n",
       "                                          pos_ratios  num_sentences  \\\n",
       "0  {'NNP': 0.031088082901554404, 'JJ': 0.05181347...             16   \n",
       "1  {'NNP': 0.03879310344827586, ',': 0.0258620689...             20   \n",
       "2  {'NNP': 0.04153354632587859, ',': 0.0287539936...             14   \n",
       "3  {'NNP': 0.11620294599018004, ',': 0.0212765957...             27   \n",
       "4  {'NNP': 0.017408123791102514, ',': 0.025145067...             30   \n",
       "\n",
       "   num_paragraphs  sentiment_polariy  sentiment_subjectivity  \\\n",
       "0               1           0.310471                0.385613   \n",
       "1               1           0.274000                0.613167   \n",
       "2               1           0.340393                0.498657   \n",
       "3               1           0.266828                0.441795   \n",
       "4               1           0.199684                0.485814   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  dear local newspaper think effect computer peo...  \n",
       "1  dear believe using computer benefit u many way...  \n",
       "2  dear people use computer everyone agrees benef...  \n",
       "3  dear local newspaper found many expert say com...  \n",
       "4  dear know computer positive effect people comp...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fefb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 1, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2793a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['essay_id', 'pos_ratios', 'essay', 'rater1_domain1', 'rater2_domain1']\n",
    "df.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b76790d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, average='macro'):\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return recall\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average='macro'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    return f1\n",
    "\n",
    "def calculate_cohen_kappa_score(y_true, y_pred):\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "    return kappa_score\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def print_metrics_function(y_actual, y_predictions):\n",
    "    \n",
    "    accuracy = calculate_accuracy(y_actual, y_predictions)\n",
    "    precision = calculate_precision(y_actual, y_predictions)\n",
    "    recall = calculate_recall(y_actual, y_predictions)\n",
    "    f1 = calculate_f1_score(y_actual, y_predictions)\n",
    "    kappa_score = calculate_cohen_kappa_score(y_actual, y_predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "173c38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data, target = 'domain1_score'):\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9abcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_classifiers(classifier_name = \"logistic_regression\"):\n",
    "    \n",
    "    if classifier_name == 'logistic_regression':\n",
    "        return LogisticRegression()\n",
    "    elif classifier_name == 'random_forest_classifier':\n",
    "        return RandomForestClassifier()\n",
    "    elif classifier_name == 'adaboost_classifier':\n",
    "        return AdaBoostClassifier()\n",
    "    elif classifier_name == 'k_neighbors_classifier':\n",
    "        return KNeighborsClassifier()\n",
    "    elif classifier_name == 'support_vector_classifier':\n",
    "        return SVC()\n",
    "    else:\n",
    "        raise ValueError(f\"Classifier {classifier_name} not supported for this problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1395cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 1]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a55d5cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>word_len</th>\n",
       "      <th>chars_len</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>sentiment_polariy</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1</td>\n",
       "      <td>431</td>\n",
       "      <td>1993</td>\n",
       "      <td>3.781903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096094</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>dear local people using computer year good hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>1498</td>\n",
       "      <td>4.283737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066142</td>\n",
       "      <td>0.514918</td>\n",
       "      <td>dear newspaper believe computer positive affec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>2724</td>\n",
       "      <td>4.037770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262030</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>people agree computer make life le complicated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>2259</td>\n",
       "      <td>3.837838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.426994</td>\n",
       "      <td>dear world changed much better technology beco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1</td>\n",
       "      <td>488</td>\n",
       "      <td>2369</td>\n",
       "      <td>3.954918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053060</td>\n",
       "      <td>0.429295</td>\n",
       "      <td>technology growing changing rapidly look apple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_set  word_len  chars_len  avg_word_length  avg_sentence_length  \\\n",
       "1346          1       431       1993         3.781903                  1.0   \n",
       "1349          1       289       1498         4.283737                  1.0   \n",
       "7             1       556       2724         4.037770                  1.0   \n",
       "1251          1       481       2259         3.837838                  1.0   \n",
       "661           1       488       2369         3.954918                  1.0   \n",
       "\n",
       "      num_sentences  num_paragraphs  sentiment_polariy  \\\n",
       "1346             37               1           0.096094   \n",
       "1349             15               1           0.066142   \n",
       "7                39               1           0.262030   \n",
       "1251             31               1           0.099660   \n",
       "661              26               1           0.053060   \n",
       "\n",
       "      sentiment_subjectivity  \\\n",
       "1346                0.511334   \n",
       "1349                0.514918   \n",
       "7                   0.574500   \n",
       "1251                0.426994   \n",
       "661                 0.429295   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "1346  dear local people using computer year good hea...  \n",
       "1349  dear newspaper believe computer positive affec...  \n",
       "7     people agree computer make life le complicated...  \n",
       "1251  dear world changed much better technology beco...  \n",
       "661   technology growing changing rapidly look apple...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eca450",
   "metadata": {},
   "source": [
    "### BERT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3cb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1681f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:17<00:00,  5.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:04<00:00,  5.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c179e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.49299719887955185\n",
      "Precision: 0.45533181503295356\n",
      "Recall: 0.3956398138152171\n",
      "F1-Score: 0.4067064480252336\n",
      "Cohen Kappa Score: 0.7600234186959256\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.4957983193277311\n",
      "Precision: 0.37482340247594814\n",
      "Recall: 0.34147088798298475\n",
      "F1-Score: 0.34264786410998804\n",
      "Cohen Kappa Score: 0.7613818654037124\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.45098039215686275\n",
      "Precision: 0.18534132324081862\n",
      "Recall: 0.25721153846153844\n",
      "F1-Score: 0.21059473513162175\n",
      "Cohen Kappa Score: 0.4784022809355206\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.42296918767507\n",
      "Precision: 0.36327345632906727\n",
      "Recall: 0.34329037897586284\n",
      "F1-Score: 0.3473650692439548\n",
      "Cohen Kappa Score: 0.7201422088748054\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.4649859943977591\n",
      "Precision: 0.18513239294489295\n",
      "Recall: 0.17685315692372144\n",
      "F1-Score: 0.15664556967414806\n",
      "Cohen Kappa Score: 0.5993546445295275\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0639c",
   "metadata": {},
   "source": [
    "### Models with Metrics (Essay Set - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85f03a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 2]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bfabcbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:17<00:00,  5.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:04<00:00,  5.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "235d47dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.7027777777777777\n",
      "Precision: 0.7181916650784576\n",
      "Recall: 0.5241956904487404\n",
      "F1-Score: 0.5666182333470807\n",
      "Cohen Kappa Score: 0.7054623348803999\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.6833333333333333\n",
      "Precision: 0.5371069182389937\n",
      "Recall: 0.47642214297843444\n",
      "F1-Score: 0.4960660367111981\n",
      "Cohen Kappa Score: 0.6664195700518902\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.625\n",
      "Precision: 0.2535378180550715\n",
      "Recall: 0.293598233995585\n",
      "F1-Score: 0.2699493304379298\n",
      "Cohen Kappa Score: 0.4868067978533095\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.6861111111111111\n",
      "Precision: 0.4379179728317659\n",
      "Recall: 0.41825946680251314\n",
      "F1-Score: 0.42418306238241926\n",
      "Cohen Kappa Score: 0.6495071193866374\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.6722222222222223\n",
      "Precision: 0.4250769888793841\n",
      "Recall: 0.4226608931906945\n",
      "F1-Score: 0.4221007987421993\n",
      "Cohen Kappa Score: 0.6425826287471176\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9eb79",
   "metadata": {},
   "source": [
    "### Models with Metrics (Essay Set - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d330fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 3]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8fc6c7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:12<00:00,  6.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00, 10.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f0c9387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.569364161849711\n",
      "Precision: 0.47765368198989355\n",
      "Recall: 0.45865263102795917\n",
      "F1-Score: 0.4325135474091313\n",
      "Cohen Kappa Score: 0.5739561119900942\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.3786127167630058\n",
      "Precision: 0.20210375816993464\n",
      "Recall: 0.2891500474833808\n",
      "F1-Score: 0.22770949175690175\n",
      "Cohen Kappa Score: 0.19784528314752314\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.3901734104046243\n",
      "Precision: 0.33749071861389957\n",
      "Recall: 0.34141910813498744\n",
      "F1-Score: 0.3222904806538743\n",
      "Cohen Kappa Score: 0.1717181834572007\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5433526011560693\n",
      "Precision: 0.43167284738174794\n",
      "Recall: 0.4506971083742737\n",
      "F1-Score: 0.4148213447710894\n",
      "Cohen Kappa Score: 0.5651325107501499\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.6098265895953757\n",
      "Precision: 0.4564311237399402\n",
      "Recall: 0.49701752024586676\n",
      "F1-Score: 0.45845424225035747\n",
      "Cohen Kappa Score: 0.645378763722498\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce2b3d",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a23d9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 4]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a56cbd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26d77d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.4067796610169492\n",
      "Precision: 0.2965592743196747\n",
      "Recall: 0.389455349366919\n",
      "F1-Score: 0.30859260555097456\n",
      "Cohen Kappa Score: 0.3349513577187887\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.4661016949152542\n",
      "Precision: 0.5026577095075547\n",
      "Recall: 0.3815031821531453\n",
      "F1-Score: 0.36915040231841406\n",
      "Cohen Kappa Score: 0.45741647260111207\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.16101694915254236\n",
      "Precision: 0.040482954545454544\n",
      "Recall: 0.24152542372881355\n",
      "F1-Score: 0.06934306569343066\n",
      "Cohen Kappa Score: -0.010829255335451426\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5423728813559322\n",
      "Precision: 0.6052335726709686\n",
      "Recall: 0.5223032089502244\n",
      "F1-Score: 0.5242415763156372\n",
      "Cohen Kappa Score: 0.6540629933097797\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.5536723163841808\n",
      "Precision: 0.49081999604445425\n",
      "Recall: 0.44377302873986735\n",
      "F1-Score: 0.4194208832992103\n",
      "Cohen Kappa Score: 0.6026631973674141\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83407c6e",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a9eb5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 5]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "19e93b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:13<00:00,  6.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  9.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d9a98239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.5373961218836565\n",
      "Precision: 0.4462748763027962\n",
      "Recall: 0.38951564991201987\n",
      "F1-Score: 0.37321240098364505\n",
      "Cohen Kappa Score: 0.599176083595347\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.4903047091412742\n",
      "Precision: 0.4161904761904762\n",
      "Recall: 0.2937471125046195\n",
      "F1-Score: 0.2607502792906019\n",
      "Cohen Kappa Score: 0.42941335032346595\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.2409972299168975\n",
      "Precision: 0.16483180138733605\n",
      "Recall: 0.21431980093397418\n",
      "F1-Score: 0.1482550290823389\n",
      "Cohen Kappa Score: 0.08428641359975086\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5041551246537396\n",
      "Precision: 0.40130244755244754\n",
      "Recall: 0.43824454531781365\n",
      "F1-Score: 0.4137729465232775\n",
      "Cohen Kappa Score: 0.6496107331976394\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.5124653739612188\n",
      "Precision: 0.45164710533131586\n",
      "Recall: 0.4463520546064254\n",
      "F1-Score: 0.40952892712212474\n",
      "Cohen Kappa Score: 0.6186131386861314\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa82a8",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6ba1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 6]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c5825397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:16<00:00,  5.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44a956ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.3277777777777778\n",
      "Precision: 0.3804725767506037\n",
      "Recall: 0.2826852338413032\n",
      "F1-Score: 0.20669242677346827\n",
      "Cohen Kappa Score: 0.35446482563999193\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.49166666666666664\n",
      "Precision: 0.34674763832658567\n",
      "Recall: 0.26396817055776595\n",
      "F1-Score: 0.25886046995217304\n",
      "Cohen Kappa Score: 0.3638850889192886\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.525\n",
      "Precision: 0.38295105394783846\n",
      "Recall: 0.27791206866351376\n",
      "F1-Score: 0.2597084761447591\n",
      "Cohen Kappa Score: 0.43887775551102215\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.5222222222222223\n",
      "Precision: 0.47682225063938616\n",
      "Recall: 0.4478536396166454\n",
      "F1-Score: 0.43614228778296676\n",
      "Cohen Kappa Score: 0.5764345656611476\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.5777777777777777\n",
      "Precision: 0.40319088319088314\n",
      "Recall: 0.35494382303630856\n",
      "F1-Score: 0.3501372169820043\n",
      "Cohen Kappa Score: 0.5411663807890223\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ecc18",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "583c0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 7]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c96f3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:15<00:00,  5.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a23121d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.11146496815286625\n",
      "Precision: 0.12309198737770168\n",
      "Recall: 0.1661694845042196\n",
      "F1-Score: 0.12621901354459494\n",
      "Cohen Kappa Score: 0.4538913561784721\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.08917197452229299\n",
      "Precision: 0.04071799807372537\n",
      "Recall: 0.062466041075722956\n",
      "F1-Score: 0.03639028357820315\n",
      "Cohen Kappa Score: 0.07682021422201868\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.05732484076433121\n",
      "Precision: 0.014542284150127286\n",
      "Recall: 0.0872747941713459\n",
      "F1-Score: 0.019590335322704218\n",
      "Cohen Kappa Score: 0.2912675487859818\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.12420382165605096\n",
      "Precision: 0.0964082473851989\n",
      "Recall: 0.09350511158349216\n",
      "F1-Score: 0.08308797338477233\n",
      "Cohen Kappa Score: 0.5008810868535032\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.1337579617834395\n",
      "Precision: 0.014634454352936603\n",
      "Recall: 0.07784743991640543\n",
      "F1-Score: 0.024255587809414007\n",
      "Cohen Kappa Score: 0.40618140917669276\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15c125",
   "metadata": {},
   "source": [
    "### Model with Metrics (Essay Set - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8309ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essay_set = df[df.essay_set == 8]\n",
    "X, y = dataset_preparation(df_essay_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, \n",
    "                                                    random_state = 101, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a9b3198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:13<00:00,  2.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code can take about 5 - 10 minutes to run depending on the speed of the system\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 500\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "test_encodings = tokenizer(list(X_test['preprocessed_text']), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "embeddings_train = []\n",
    "for batch in tqdm(train_dataset):\n",
    "    embeddings_train.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_train = tf.concat(embeddings_train, axis=0)\n",
    "\n",
    "embeddings_test = []\n",
    "for batch in tqdm(test_dataset):\n",
    "    embeddings_test.append(bert_model(batch[0]['input_ids'])[0][:, -1, :])\n",
    "embeddings_test = tf.concat(embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cf2a701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression-----------------------\n",
      "Accuracy: 0.15172413793103448\n",
      "Precision: 0.08856068743286787\n",
      "Recall: 0.07298850574712644\n",
      "F1-Score: 0.05555905787295279\n",
      "Cohen Kappa Score: 0.36144554217831293\n",
      "\n",
      "\n",
      "-----------------------Random Forest Classifier-----------------------\n",
      "Accuracy: 0.21379310344827587\n",
      "Precision: 0.06153846153846154\n",
      "Recall: 0.05654761904761905\n",
      "F1-Score: 0.04159928122192274\n",
      "Cohen Kappa Score: 0.2156304706135277\n",
      "\n",
      "\n",
      "-----------------------Adaboost Classifier-----------------------\n",
      "Accuracy: 0.09655172413793103\n",
      "Precision: 0.008414952187771661\n",
      "Recall: 0.033491874752279036\n",
      "F1-Score: 0.010373100133563413\n",
      "Cohen Kappa Score: 0.09657320872274133\n",
      "\n",
      "\n",
      "-----------------------K Neibhors Classifier-----------------------\n",
      "Accuracy: 0.12413793103448276\n",
      "Precision: 0.016619919705219158\n",
      "Recall: 0.029577883472057077\n",
      "F1-Score: 0.02114355498949112\n",
      "Cohen Kappa Score: 0.41558142506113305\n",
      "\n",
      "\n",
      "-----------------------Support Vector Classifier-----------------------\n",
      "Accuracy: 0.20689655172413793\n",
      "Precision: 0.04290674603174603\n",
      "Recall: 0.044642857142857144\n",
      "F1-Score: 0.026259289843104876\n",
      "Cohen Kappa Score: 0.03416643314492995\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression-----------------------\")\n",
    "model = choose_classifiers(\"logistic_regression\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_logistic_reg, precision_logistic_reg, recall_logistic_reg, f1_logistic_reg, kappa_score_logistic_reg = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Random Forest Classifier-----------------------\")\n",
    "model = choose_classifiers(\"random_forest_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_random_forest, precision_random_forest, recall_random_forest, f1_random_forest, kappa_score_random_forest = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Adaboost Classifier-----------------------\")\n",
    "model = choose_classifiers(\"adaboost_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_adaboost, precision_adaboost, recall_adaboost, f1_adaboost, kappa_score_adaboost = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------K Neibhors Classifier-----------------------\")\n",
    "model = choose_classifiers(\"k_neighbors_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_k_neighbors, precision_k_neighbors, recall_k_neighbors, f1_k_neighbors, kappa_score_k_neighbors = print_metrics_function(y_test, y_predictions)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------------------Support Vector Classifier-----------------------\")\n",
    "model = choose_classifiers(\"support_vector_classifier\")\n",
    "model.fit(embeddings_train, y_train)\n",
    "y_predictions = model.predict(embeddings_test)\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, kappa_score_svc = print_metrics_function(y_test, y_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
